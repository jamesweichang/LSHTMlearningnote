<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 55 章 貝葉斯多層回歸模型 multilevel models | 醫學統計學</title>
  <meta name="description" content="第 55 章 貝葉斯多層回歸模型 multilevel models | 醫學統計學" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="第 55 章 貝葉斯多層回歸模型 multilevel models | 醫學統計學" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/img/cover.jpg" />
  
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 55 章 貝葉斯多層回歸模型 multilevel models | 醫學統計學" />
  
  
  <meta name="twitter:image" content="/img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2023-09-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"/>
<link rel="next" href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的統計學筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="prob-intro.html"><a href="prob-intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prob-intro.html"><a href="prob-intro.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="prob-intro.html"><a href="prob-intro.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="prob-intro.html"><a href="prob-intro.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="expectation.html"><a href="expectation.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="expectation.html"><a href="expectation.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a>
<ul>
<li class="chapter" data-level="5.1" data-path="binomial.html"><a href="binomial.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="binomial.html"><a href="binomial.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="binomial.html"><a href="binomial.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="binomial.html"><a href="binomial.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="normaldistr.html"><a href="normaldistr.html"><i class="fa fa-check"></i><b>7</b> 正（常）態分佈 Normal Distribution</a>
<ul>
<li class="chapter" data-level="7.1" data-path="normaldistr.html"><a href="normaldistr.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="normaldistr.html"><a href="normaldistr.html#正常態分佈"><i class="fa fa-check"></i><b>7.2</b> 正（常）態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="normaldistr.html"><a href="normaldistr.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正（常）態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#泊松分佈的正常態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正（常）態分佈模擬的校正：continuity corrections</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="CLT.html"><a href="CLT.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="inference-basic.html"><a href="inference-basic.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a>
<ul>
<li class="chapter" data-level="9.1" data-path="inference-basic.html"><a href="inference-basic.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="inference-basic.html"><a href="inference-basic.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="inference-basic.html"><a href="inference-basic.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="inference-basic.html"><a href="inference-basic.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a>
<ul>
<li class="chapter" data-level="10.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a>
<ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#inference-practical-05"><i class="fa fa-check"></i><b>13.5</b> Inference Practical 05</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a>
<ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#inference-practical-06"><i class="fa fa-check"></i><b>14.3</b> Inference Practical 06</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a>
<ul>
<li class="chapter" data-level="15.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="hypothesis-test.html"><a href="hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="hypothesis-test.html"><a href="hypothesis-test.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="hypothesis-test.html"><a href="hypothesis-test.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="hypothesis-test.html"><a href="hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="hypothesis-test.html"><a href="hypothesis-test.html#inference-practical-07"><i class="fa fa-check"></i><b>15.8</b> Inference Practical 07</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a>
<ul>
<li class="chapter" data-level="16.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#練習題"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#inference-practical-08"><i class="fa fa-check"></i><b>16.7</b> Inference Practical 08</a>
<ul>
<li class="chapter" data-level="16.7.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="normal-error-models.html"><a href="normal-error-models.html"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="normal-error-models.html"><a href="normal-error-models.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="normal-error-models.html"><a href="normal-error-models.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="normal-error-models.html"><a href="normal-error-models.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="normal-error-models.html"><a href="normal-error-models.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="normal-error-models.html"><a href="normal-error-models.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="normal-error-models.html"><a href="normal-error-models.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="normal-error-models.html"><a href="normal-error-models.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="normal-error-models.html"><a href="normal-error-models.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
<li class="chapter" data-level="17.7" data-path="normal-error-models.html"><a href="normal-error-models.html#inference-practical-09"><i class="fa fa-check"></i><b>17.7</b> Inference Practical 09</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a>
<ul>
<li class="chapter" data-level="18.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#inference-practical-10"><i class="fa fa-check"></i><b>18.5</b> Inference Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a>
<ul>
<li class="chapter" data-level="19.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#practical0"><i class="fa fa-check"></i><b>19.3</b> Inference Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>20</b> 統計推斷總結</a>
<ul>
<li class="chapter" data-level="20.0.1" data-path="summary.html"><a href="summary.html#快速複習"><i class="fa fa-check"></i><b>20.0.1</b> 快速複習</a></li>
<li class="chapter" data-level="20.0.2" data-path="summary.html"><a href="summary.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>20.0.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="20.0.3" data-path="summary.html"><a href="summary.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>20.0.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="21" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>21</b> 探索數據和簡單描述</a>
<ul>
<li class="chapter" data-level="21.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析的流程"><i class="fa fa-check"></i><b>21.1</b> 數據分析的流程</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#研究設計和實施"><i class="fa fa-check"></i><b>21.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="21.1.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析"><i class="fa fa-check"></i><b>21.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據類型"><i class="fa fa-check"></i><b>21.2</b> 數據類型</a></li>
<li class="chapter" data-level="21.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#如何總結並展示數據"><i class="fa fa-check"></i><b>21.3</b> 如何總結並展示數據</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>21.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="21.3.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#連續型變量"><i class="fa fa-check"></i><b>21.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>21.4</b> 數據總結方案：位置，分散，偏度，和峰度</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#位置"><i class="fa fa-check"></i><b>21.4.1</b> 位置</a></li>
<li class="chapter" data-level="21.4.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#分散"><i class="fa fa-check"></i><b>21.4.2</b> 分散</a></li>
<li class="chapter" data-level="21.4.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#偏度-skewness"><i class="fa fa-check"></i><b>21.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="21.4.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#峯度-kurtosis"><i class="fa fa-check"></i><b>21.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>22</b> 信賴區間 confidence intervals</a>
<ul>
<li class="chapter" data-level="22.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#定義"><i class="fa fa-check"></i><b>22.1</b> 定義</a></li>
<li class="chapter" data-level="22.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>22.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="22.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>22.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CImean"><i class="fa fa-check"></i><b>22.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="22.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#AT2-5"><i class="fa fa-check"></i><b>22.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#varCI"><i class="fa fa-check"></i><b>22.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="22.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>22.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="22.8" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>22.8</b> 情況4：求人羣百分比的信賴區間</a>
<ul>
<li class="chapter" data-level="22.8.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#一般原則"><i class="fa fa-check"></i><b>22.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="22.8.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#exactprop"><i class="fa fa-check"></i><b>22.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="22.8.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>22.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CIrate"><i class="fa fa-check"></i><b>22.9</b> 率的信賴區間</a>
<ul>
<li class="chapter" data-level="22.9.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>22.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="22.9.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用正態近似法計算"><i class="fa fa-check"></i><b>22.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="hypo-tests.html"><a href="hypo-tests.html"><i class="fa fa-check"></i><b>23</b> 假設檢驗</a>
<ul>
<li class="chapter" data-level="23.1" data-path="hypo-tests.html"><a href="hypo-tests.html#拋硬幣的例子"><i class="fa fa-check"></i><b>23.1</b> 拋硬幣的例子</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="hypo-tests.html"><a href="hypo-tests.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>23.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="23.1.2" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值的意義"><i class="fa fa-check"></i><b>23.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="23.1.3" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>23.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>23.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="23.3" data-path="hypo-tests.html"><a href="hypo-tests.html#當樣本量較大"><i class="fa fa-check"></i><b>23.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="23.4" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>23.4</b> 二項分佈的正態近似法假設檢驗</a>
<ul>
<li class="chapter" data-level="23.4.1" data-path="hypo-tests.html"><a href="hypo-tests.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>23.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="hypo-tests.html"><a href="hypo-tests.html#AT3-5"><i class="fa fa-check"></i><b>23.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="23.6" data-path="hypo-tests.html"><a href="hypo-tests.html#OneSampleT"><i class="fa fa-check"></i><b>23.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="23.7" data-path="hypo-tests.html"><a href="hypo-tests.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>23.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="association.html"><a href="association.html"><i class="fa fa-check"></i><b>24</b> 相關 association</a>
<ul>
<li class="chapter" data-level="24.1" data-path="association.html"><a href="association.html#背景介紹"><i class="fa fa-check"></i><b>24.1</b> 背景介紹</a></li>
<li class="chapter" data-level="24.2" data-path="association.html"><a href="association.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>24.2</b> 兩個連續型變量的相關分析</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="association.html"><a href="association.html#相關係數的定義"><i class="fa fa-check"></i><b>24.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="24.2.2" data-path="association.html"><a href="association.html#相關係數的性質"><i class="fa fa-check"></i><b>24.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="24.2.3" data-path="association.html"><a href="association.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>24.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="24.2.4" data-path="association.html"><a href="association.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>24.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="24.2.5" data-path="association.html"><a href="association.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>24.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="24.2.6" data-path="association.html"><a href="association.html#相關係數那些事兒"><i class="fa fa-check"></i><b>24.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="24.2.7" data-path="association.html"><a href="association.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>24.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="association.html"><a href="association.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>24.3</b> 二元變量之間的相關性 association between pairs of binary variables</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="association.html"><a href="association.html#or-的信賴區間"><i class="fa fa-check"></i><b>24.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="24.3.2" data-path="association.html"><a href="association.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>24.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="24.3.3" data-path="association.html"><a href="association.html#chisquaretest"><i class="fa fa-check"></i><b>24.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="24.3.4" data-path="association.html"><a href="association.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>24.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="association.html"><a href="association.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>24.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="comparisons.html"><a href="comparisons.html"><i class="fa fa-check"></i><b>25</b> 比較 Comparisons</a>
<ul>
<li class="chapter" data-level="25.1" data-path="comparisons.html"><a href="comparisons.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>25.1</b> 比較兩個均值 comparing two population means</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="comparisons.html"><a href="comparisons.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>25.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="25.1.2" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>25.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="25.1.3" data-path="comparisons.html"><a href="comparisons.html#練習"><i class="fa fa-check"></i><b>25.1.3</b> 練習</a></li>
<li class="chapter" data-level="25.1.4" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>25.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="comparisons.html"><a href="comparisons.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>25.2</b> 兩個人羣的方差比較</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="comparisons.html"><a href="comparisons.html#Ftest"><i class="fa fa-check"></i><b>25.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="25.2.2" data-path="comparisons.html"><a href="comparisons.html#信賴區間"><i class="fa fa-check"></i><b>25.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="comparisons.html"><a href="comparisons.html#比較兩個百分比"><i class="fa fa-check"></i><b>25.3</b> 比較兩個百分比</a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="comparisons.html"><a href="comparisons.html#proportiontest"><i class="fa fa-check"></i><b>25.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="25.3.2" data-path="comparisons.html"><a href="comparisons.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>25.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>26</b> 前提和數據轉換 Assumptions and transformations</a>
<ul>
<li class="chapter" data-level="26.1" data-path="assumptions.html"><a href="assumptions.html#穩健性"><i class="fa fa-check"></i><b>26.1</b> 穩健性</a></li>
<li class="chapter" data-level="26.2" data-path="assumptions.html"><a href="assumptions.html#正態性"><i class="fa fa-check"></i><b>26.2</b> 正態性</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="assumptions.html"><a href="assumptions.html#normalplot"><i class="fa fa-check"></i><b>26.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="assumptions.html"><a href="assumptions.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>26.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="26.4" data-path="assumptions.html"><a href="assumptions.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>26.4</b> 數學冪轉換 power transformations</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="assumptions.html"><a href="assumptions.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>26.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="26.4.2" data-path="assumptions.html"><a href="assumptions.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>26.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="26.4.3" data-path="assumptions.html"><a href="assumptions.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>26.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="26.4.4" data-path="assumptions.html"><a href="assumptions.html#百分比的轉換"><i class="fa fa-check"></i><b>26.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="27" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>27</b> 簡單線性迴歸 Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="27.1" data-path="lm.html"><a href="lm.html#一些背景和術語"><i class="fa fa-check"></i><b>27.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="27.2" data-path="lm.html"><a href="lm.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>27.2</b> 簡單線性迴歸模型 simple linear regression model</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="lm.html"><a href="lm.html#數據-a"><i class="fa fa-check"></i><b>27.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="27.2.2" data-path="lm.html"><a href="lm.html#數據-b"><i class="fa fa-check"></i><b>27.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="lm.html"><a href="lm.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>27.3</b> 區分因變量和預測變量</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="lm.html"><a href="lm.html#meanfunction"><i class="fa fa-check"></i><b>27.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="27.3.2" data-path="lm.html"><a href="lm.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>27.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="27.3.3" data-path="lm.html"><a href="lm.html#defLM"><i class="fa fa-check"></i><b>27.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="27.3.4" data-path="lm.html"><a href="lm.html#殘差-residuals"><i class="fa fa-check"></i><b>27.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="lm.html"><a href="lm.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>27.4</b> 參數的估計 estimation of parameters</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="lm.html"><a href="lm.html#MLEalphabeta"><i class="fa fa-check"></i><b>27.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="lm.html"><a href="lm.html#ResidualVar"><i class="fa fa-check"></i><b>27.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="27.6" data-path="lm.html"><a href="lm.html#growgam"><i class="fa fa-check"></i><b>27.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="27.7" data-path="lm.html"><a href="lm.html#binarylms"><i class="fa fa-check"></i><b>27.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="27.8" data-path="lm.html"><a href="lm.html#exeChol"><i class="fa fa-check"></i><b>27.8</b> LM practical 01</a>
<ul>
<li class="chapter" data-level="27.8.1" data-path="lm.html"><a href="lm.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>27.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="27.8.2" data-path="lm.html"><a href="lm.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>27.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="27.8.3" data-path="lm.html"><a href="lm.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>27.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="27.8.4" data-path="lm.html"><a href="lm.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>27.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="27.8.5" data-path="lm.html"><a href="lm.html#diagnosis"><i class="fa fa-check"></i><b>27.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="OLS.html"><a href="OLS.html"><i class="fa fa-check"></i><b>28</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a>
<ul>
<li class="chapter" data-level="28.1" data-path="OLS.html"><a href="OLS.html#ols-估計量的性質"><i class="fa fa-check"></i><b>28.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="28.2" data-path="OLS.html"><a href="OLS.html#beta"><i class="fa fa-check"></i><b>28.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="OLS.html"><a href="OLS.html#randbeta"><i class="fa fa-check"></i><b>28.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="28.2.2" data-path="OLS.html"><a href="OLS.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>28.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="OLS.html"><a href="OLS.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>28.3</b> 截距和迴歸係數的方差，協方差</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="OLS.html"><a href="OLS.html#centring"><i class="fa fa-check"></i><b>28.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="OLS.html"><a href="OLS.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>28.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="OLS.html"><a href="OLS.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>28.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="28.4.2" data-path="OLS.html"><a href="OLS.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>28.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="28.4.3" data-path="OLS.html"><a href="OLS.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>28.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="28.4.4" data-path="OLS.html"><a href="OLS.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>28.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="OLS.html"><a href="OLS.html#rsquare"><i class="fa fa-check"></i><b>28.5</b> 線性迴歸模型和 Pearson 相關係數</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="OLS.html"><a href="OLS.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>28.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="OLS.html"><a href="OLS.html#t-r2-F"><i class="fa fa-check"></i><b>28.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="28.7" data-path="OLS.html"><a href="OLS.html#lm-practical-02"><i class="fa fa-check"></i><b>28.7</b> LM practical 02</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>29</b> 方差分析 Introduction to Analysis of Variance</a>
<ul>
<li class="chapter" data-level="29.1" data-path="ANOVA.html"><a href="ANOVA.html#背景"><i class="fa fa-check"></i><b>29.1</b> 背景</a></li>
<li class="chapter" data-level="29.2" data-path="ANOVA.html"><a href="ANOVA.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>29.2</b> 簡單線性迴歸模型的方差分析</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="ANOVA.html"><a href="ANOVA.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>29.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="29.2.2" data-path="ANOVA.html"><a href="ANOVA.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>29.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="29.2.3" data-path="ANOVA.html"><a href="ANOVA.html#Rsquare"><i class="fa fa-check"></i><b>29.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="29.2.4" data-path="ANOVA.html"><a href="ANOVA.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>29.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="29.2.5" data-path="ANOVA.html"><a href="ANOVA.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>29.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="29.2.6" data-path="ANOVA.html"><a href="ANOVA.html#lm-Ftest"><i class="fa fa-check"></i><b>29.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="29.2.7" data-path="ANOVA.html"><a href="ANOVA.html#F-t-same"><i class="fa fa-check"></i><b>29.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="ANOVA.html"><a href="ANOVA.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>29.3</b> 分類變量用作預測變量時的 ANOVA</a>
<ul>
<li class="chapter" data-level="29.3.1" data-path="ANOVA.html"><a href="ANOVA.html#一個二分類預測變量"><i class="fa fa-check"></i><b>29.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="29.3.2" data-path="ANOVA.html"><a href="ANOVA.html#一個模型兩種表述"><i class="fa fa-check"></i><b>29.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="29.3.3" data-path="ANOVA.html"><a href="ANOVA.html#分組變量的平方和"><i class="fa fa-check"></i><b>29.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="29.3.4" data-path="ANOVA.html"><a href="ANOVA.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>29.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="ANOVA.html"><a href="ANOVA.html#lm-practical-03"><i class="fa fa-check"></i><b>29.4</b> LM practical 03</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="multivariable-models.html"><a href="multivariable-models.html"><i class="fa fa-check"></i><b>30</b> 多元模型分析 Multivariable Models</a>
<ul>
<li class="chapter" data-level="30.1" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>30.1</b> 兩個預測變量的線性迴歸模型</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="multivariable-models.html"><a href="multivariable-models.html#數學標記法和解釋"><i class="fa fa-check"></i><b>30.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="30.1.2" data-path="multivariable-models.html"><a href="multivariable-models.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>30.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="multivariable-models.html"><a href="multivariable-models.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>30.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="30.3" data-path="multivariable-models.html"><a href="multivariable-models.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>30.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="30.4" data-path="multivariable-models.html"><a href="multivariable-models.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>30.4</b> 偏回歸係數的變化</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="multivariable-models.html"><a href="multivariable-models.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.2" data-path="multivariable-models.html"><a href="multivariable-models.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>30.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.3" data-path="multivariable-models.html"><a href="multivariable-models.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="multivariable-models.html"><a href="multivariable-models.html#confounding"><i class="fa fa-check"></i><b>30.5</b> 混雜 confounding</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="multivariable-models.html"><a href="multivariable-models.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>30.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="30.5.2" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>30.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="30.5.3" data-path="multivariable-models.html"><a href="multivariable-models.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>30.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="multivariable-models.html"><a href="multivariable-models.html#lm-practical-04"><i class="fa fa-check"></i><b>30.6</b> LM practical 04</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html"><i class="fa fa-check"></i><b>31</b> 多元模型分析：矩陣標記與其意義</a>
<ul>
<li class="chapter" data-level="31.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>31.1</b> 線性回歸模型的矩陣/非矩陣標記法</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#模型標記"><i class="fa fa-check"></i><b>31.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#解讀參數"><i class="fa fa-check"></i><b>31.2</b> 解讀參數</a>
<ul>
<li class="chapter" data-level="31.2.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#最小二乘估計"><i class="fa fa-check"></i><b>31.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="31.2.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>31.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="31.2.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#殘差"><i class="fa fa-check"></i><b>31.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="31.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>31.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a>
<ul>
<li class="chapter" data-level="31.3.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>31.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="31.3.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析表格"><i class="fa fa-check"></i><b>31.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="31.3.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#globalsig"><i class="fa fa-check"></i><b>31.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="31.3.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#partialF"><i class="fa fa-check"></i><b>31.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>31.4</b> 添加新變量對迴歸模型的影響</a>
<ul>
<li class="chapter" data-level="31.4.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>31.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="31.4.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>31.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="31.4.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#擬合值的改變"><i class="fa fa-check"></i><b>31.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="31.4.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#決定係數的改變"><i class="fa fa-check"></i><b>31.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="31.4.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#共線性-collinearity"><i class="fa fa-check"></i><b>31.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#實戰演習"><i class="fa fa-check"></i><b>31.5</b> 實戰演習</a>
<ul>
<li class="chapter" data-level="31.5.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>31.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="31.5.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>31.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#lm-practical-05"><i class="fa fa-check"></i><b>31.6</b> LM practical 05</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="lm-diag.html"><a href="lm-diag.html"><i class="fa fa-check"></i><b>32</b> 線性迴歸的模型診斷</a>
<ul>
<li class="chapter" data-level="32.1" data-path="lm-diag.html"><a href="lm-diag.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>32.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="32.2" data-path="lm-diag.html"><a href="lm-diag.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>32.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="32.3" data-path="lm-diag.html"><a href="lm-diag.html#殘差圖"><i class="fa fa-check"></i><b>32.3</b> 殘差圖</a></li>
<li class="chapter" data-level="32.4" data-path="lm-diag.html"><a href="lm-diag.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>32.4</b> 殘差正態圖 normal plot of residuals</a>
<ul>
<li class="chapter" data-level="32.4.1" data-path="lm-diag.html"><a href="lm-diag.html#模型診斷實例"><i class="fa fa-check"></i><b>32.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="32.5" data-path="lm-diag.html"><a href="lm-diag.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>32.5</b> 前提條件的統計學檢驗</a>
<ul>
<li class="chapter" data-level="32.5.1" data-path="lm-diag.html"><a href="lm-diag.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>32.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="32.5.2" data-path="lm-diag.html"><a href="lm-diag.html#非線性關係模型"><i class="fa fa-check"></i><b>32.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="32.6" data-path="lm-diag.html"><a href="lm-diag.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>32.6</b> 異常值，槓桿值，和庫克距離</a>
<ul>
<li class="chapter" data-level="32.6.1" data-path="lm-diag.html"><a href="lm-diag.html#standardres"><i class="fa fa-check"></i><b>32.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="32.6.2" data-path="lm-diag.html"><a href="lm-diag.html#槓桿值-leverage"><i class="fa fa-check"></i><b>32.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="32.6.3" data-path="lm-diag.html"><a href="lm-diag.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>32.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="32.7" data-path="lm-diag.html"><a href="lm-diag.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>32.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
<li class="chapter" data-level="32.8" data-path="lm-diag.html"><a href="lm-diag.html#lm-practical-06"><i class="fa fa-check"></i><b>32.8</b> LM practical 06</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>33</b> 交互作用 Interactions</a>
<ul>
<li class="chapter" data-level="33.1" data-path="interaction.html"><a href="interaction.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>33.1</b> 兩個預測變量之間的線性模型交互作用</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="interaction.html"><a href="interaction.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>33.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="33.1.2" data-path="interaction.html"><a href="interaction.html#interaction-cont-bin"><i class="fa fa-check"></i><b>33.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.3" data-path="interaction.html"><a href="interaction.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.4" data-path="interaction.html"><a href="interaction.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="interaction.html"><a href="interaction.html#lm-practical-07"><i class="fa fa-check"></i><b>33.2</b> LM practical 07</a></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="34" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>34</b> 樣本量計算問題</a>
<ul>
<li class="chapter" data-level="34.1" data-path="sample-size.html"><a href="sample-size.html#背景-1"><i class="fa fa-check"></i><b>34.1</b> 背景</a></li>
<li class="chapter" data-level="34.2" data-path="sample-size.html"><a href="sample-size.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>34.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="34.3" data-path="sample-size.html"><a href="sample-size.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>34.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="34.4" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>34.4</b> 比較兩組之間的百分比 (percentages or proportions)</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>34.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="34.4.2" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>34.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>34.5</b> 比較兩組之間的均值</a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式"><i class="fa fa-check"></i><b>34.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="sample-size.html"><a href="sample-size.html#樣本量計算的調整"><i class="fa fa-check"></i><b>34.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="baseline-adjustment-using-ancova.html"><a href="baseline-adjustment-using-ancova.html"><i class="fa fa-check"></i><b>35</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="36" data-path="robust-intro.html"><a href="robust-intro.html"><i class="fa fa-check"></i><b>36</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="37" data-path="rank-tests.html"><a href="rank-tests.html"><i class="fa fa-check"></i><b>37</b> 基於秩次的非參數檢驗</a>
<ul>
<li class="chapter" data-level="37.1" data-path="rank-tests.html"><a href="rank-tests.html#sign-test"><i class="fa fa-check"></i><b>37.1</b> 符號檢驗 the Sign test</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="rank-tests.html"><a href="rank-tests.html#符號檢驗的特點"><i class="fa fa-check"></i><b>37.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="rank-tests.html"><a href="rank-tests.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>37.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="37.3" data-path="rank-tests.html"><a href="rank-tests.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>37.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="37.4" data-path="rank-tests.html"><a href="rank-tests.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>37.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="37.5" data-path="rank-tests.html"><a href="rank-tests.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>37.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="permutation.html"><a href="permutation.html"><i class="fa fa-check"></i><b>38</b> 排列置換法 Permutation procedures</a>
<ul>
<li class="chapter" data-level="38.1" data-path="permutation.html"><a href="permutation.html#背景介紹-1"><i class="fa fa-check"></i><b>38.1</b> 背景介紹</a></li>
<li class="chapter" data-level="38.2" data-path="permutation.html"><a href="permutation.html#直接上實例"><i class="fa fa-check"></i><b>38.2</b> 直接上實例</a></li>
<li class="chapter" data-level="38.3" data-path="permutation.html"><a href="permutation.html#排列置換法三板斧"><i class="fa fa-check"></i><b>38.3</b> 排列置換法三板斧</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="permutation.html"><a href="permutation.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>38.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="38.3.2" data-path="permutation.html"><a href="permutation.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>38.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="38.3.3" data-path="permutation.html"><a href="permutation.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>38.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="38.3.4" data-path="permutation.html"><a href="permutation.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>38.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="permutation.html"><a href="permutation.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>38.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="38.5" data-path="permutation.html"><a href="permutation.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>38.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>39</b> 自助重抽法 The bootstrap</a>
<ul>
<li class="chapter" data-level="39.1" data-path="bootstrap.html"><a href="bootstrap.html#定義-1"><i class="fa fa-check"></i><b>39.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="the-sandwich-estimator.html"><a href="the-sandwich-estimator.html"><i class="fa fa-check"></i><b>40</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計 Introduction to Bayesian Statistics</b></span></li>
<li class="chapter" data-level="41" data-path="intro-Bayes.html"><a href="intro-Bayes.html"><i class="fa fa-check"></i><b>41</b> 貝葉斯統計入門</a>
<ul>
<li class="chapter" data-level="41.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>41.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="41.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>41.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>41.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="41.2.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>41.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>41.3</b> 貝葉斯推理的統計學實現</a>
<ul>
<li class="chapter" data-level="41.3.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>41.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="41.3.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>41.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="41.3.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#離散概率分佈實例遺傳學分析"><i class="fa fa-check"></i><b>41.3.3</b> 離散概率分佈實例：遺傳學分析</a></li>
<li class="chapter" data-level="41.3.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>41.3.4</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="41.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#practical-intro-to-bayes-01"><i class="fa fa-check"></i><b>41.4</b> Practical Intro-to-Bayes 01</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="single-para-model.html"><a href="single-para-model.html"><i class="fa fa-check"></i><b>42</b> 貝葉斯定理的應用：單一參數模型 Single-parameter models</a>
<ul>
<li class="chapter" data-level="42.1" data-path="single-para-model.html"><a href="single-para-model.html#從二進制數據中估計概率-estimating-a-probability-from-binomial-data"><i class="fa fa-check"></i><b>42.1</b> 從二進制數據中估計概率 Estimating a probability from binomial data</a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="single-para-model.html"><a href="single-para-model.html#事後概率分佈是數據和先驗概率分佈之間的妥協"><i class="fa fa-check"></i><b>42.1.1</b> 事後概率分佈是數據和先驗概率分佈之間的妥協</a></li>
<li class="chapter" data-level="42.1.2" data-path="single-para-model.html"><a href="single-para-model.html#不同先驗概率分佈對事後概率分佈估計的影響"><i class="fa fa-check"></i><b>42.1.2</b> 不同先驗概率分佈對事後概率分佈估計的影響</a></li>
<li class="chapter" data-level="42.1.3" data-path="single-para-model.html"><a href="single-para-model.html#從已知的事後概率分佈中採樣對採集的事後樣本數據轉換"><i class="fa fa-check"></i><b>42.1.3</b> 從已知的事後概率分佈中採樣，對採集的事後樣本數據轉換</a></li>
<li class="chapter" data-level="42.1.4" data-path="single-para-model.html"><a href="single-para-model.html#使用非共軛先驗概率計算事後概率分佈"><i class="fa fa-check"></i><b>42.1.4</b> 使用非共軛先驗概率計算事後概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="single-para-model.html"><a href="single-para-model.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions-in-binomial-data"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions in binomial data</a></li>
<li class="chapter" data-level="42.3" data-path="single-para-model.html"><a href="single-para-model.html#theta-的先驗概率"><i class="fa fa-check"></i><b>42.3</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="single-para-model.html"><a href="single-para-model.html#beta-distribution-intro"><i class="fa fa-check"></i><b>42.3.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="42.3.2" data-path="single-para-model.html"><a href="single-para-model.html#conjugate"><i class="fa fa-check"></i><b>42.3.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="42.4" data-path="single-para-model.html"><a href="single-para-model.html#附贈加量不加價"><i class="fa fa-check"></i><b>42.4</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="42.5" data-path="single-para-model.html"><a href="single-para-model.html#practical-intro-to-bayes-02"><i class="fa fa-check"></i><b>42.5</b> Practical Intro-to-Bayes 02</a>
<ul>
<li class="chapter" data-level="42.5.1" data-path="single-para-model.html"><a href="single-para-model.html#q1-4"><i class="fa fa-check"></i><b>42.5.1</b> Q1</a></li>
<li class="chapter" data-level="42.5.2" data-path="single-para-model.html"><a href="single-para-model.html#q2-3"><i class="fa fa-check"></i><b>42.5.2</b> Q2</a></li>
<li class="chapter" data-level="42.5.3" data-path="single-para-model.html"><a href="single-para-model.html#q3-2"><i class="fa fa-check"></i><b>42.5.3</b> Q3</a></li>
<li class="chapter" data-level="42.5.4" data-path="single-para-model.html"><a href="single-para-model.html#q4"><i class="fa fa-check"></i><b>42.5.4</b> Q4</a></li>
<li class="chapter" data-level="42.5.5" data-path="single-para-model.html"><a href="single-para-model.html#q5"><i class="fa fa-check"></i><b>42.5.5</b> Q5</a></li>
<li class="chapter" data-level="42.5.6" data-path="single-para-model.html"><a href="single-para-model.html#q6"><i class="fa fa-check"></i><b>42.5.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="normal-distr.html"><a href="normal-distr.html"><i class="fa fa-check"></i><b>43</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a>
<ul>
<li class="chapter" data-level="43.1" data-path="normal-distr.html"><a href="normal-distr.html#事後概率的總結方法"><i class="fa fa-check"></i><b>43.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="43.2" data-path="normal-distr.html"><a href="normal-distr.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>43.2</b> 貝葉斯統計推斷中的正態分布</a>
<ul>
<li class="chapter" data-level="43.2.1" data-path="normal-distr.html"><a href="normal-distr.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>43.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="43.3" data-path="normal-distr.html"><a href="normal-distr.html#事後預測分佈-posterior-predictive-distribution"><i class="fa fa-check"></i><b>43.3</b> 事後預測分佈 Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html"><i class="fa fa-check"></i><b>44</b> 其他典型的單一參數模型 Other standard single-parameter models</a>
<ul>
<li class="chapter" data-level="44.1" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#unknownvarBayes"><i class="fa fa-check"></i><b>44.1</b> 正（常）態分佈僅均值已知（方差未知） Normal distribution with known mean but unknown variance</a></li>
<li class="chapter" data-level="44.2" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#泊松分佈模型的貝葉斯思路-poisson-distribution-model-under-bayesian-framework"><i class="fa fa-check"></i><b>44.2</b> 泊松分佈模型的貝葉斯思路 Poisson distribution model under Bayesian framework</a></li>
<li class="chapter" data-level="44.3" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#泊松模型的其他表達形式-poisson-model-parameterized-in-terms-of-rate-and-exposure"><i class="fa fa-check"></i><b>44.3</b> 泊松模型的其他表達形式 poisson model parameterized in terms of rate and exposure</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html"><i class="fa fa-check"></i><b>45</b> 多參數模型 Introduction to multiparameter models</a>
<ul>
<li class="chapter" data-level="45.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#把不需要的噪音參數平均出去-averaging-over-nuisance-parameters"><i class="fa fa-check"></i><b>45.1</b> 把不需要的噪音參數平均出去 Averaging over ‘nuisance parameters’</a></li>
<li class="chapter" data-level="45.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#未知均值也未知方差的正常態分佈數據-normal-data-with-unknown-mean-and-variance"><i class="fa fa-check"></i><b>45.2</b> 未知均值也未知方差的正（常）態分佈數據 normal data with unknown mean and variance</a>
<ul>
<li class="chapter" data-level="45.2.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#無信息先驗概率分佈-noninformative-prior-distribution"><i class="fa fa-check"></i><b>45.2.1</b> 無信息先驗概率分佈 noninformative prior distribution</a></li>
<li class="chapter" data-level="45.2.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#均值的事後邊際概率分佈-marginal-posterior-distribution-of-mu"><i class="fa fa-check"></i><b>45.2.2</b> 均值的事後邊際概率分佈 marginal posterior distribution of <span class="math inline">\(\mu\)</span></a></li>
</ul></li>
<li class="chapter" data-level="45.3" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#r-演示-正常態數據但均值方差均未知"><i class="fa fa-check"></i><b>45.3</b> R 演示 正常態數據但均值方差均未知</a>
<ul>
<li class="chapter" data-level="45.3.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#繪製聯合事後密度分佈及均值和方差各自的邊際分佈-visualise-the-joint-and-marginal-densities"><i class="fa fa-check"></i><b>45.3.1</b> 繪製聯合事後密度分佈及均值和方差各自的邊際分佈 visualise the joint and marginal densities</a></li>
<li class="chapter" data-level="45.3.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#單獨繪製邊際分佈的每一個部分"><i class="fa fa-check"></i><b>45.3.2</b> 單獨繪製邊際分佈的每一個部分</a></li>
<li class="chapter" data-level="45.3.3" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#繪製事後均值的概率密度分佈"><i class="fa fa-check"></i><b>45.3.3</b> 繪製事後均值的概率密度分佈</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#r-演示-分析二進制數據-bda3-p.74"><i class="fa fa-check"></i><b>45.4</b> R 演示 分析二進制數據 (BDA3 P.74)</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><i class="fa fa-check"></i><b>46</b> 簡單線型回歸模型 - 地心說模型 Linear regression is the geocentric model of applied statistics</a>
<ul>
<li class="chapter" data-level="46.1" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#為什麼正常態分佈是正常的-why-normal-distribution-is-normal"><i class="fa fa-check"></i><b>46.1</b> 為什麼正（常）態分佈是正常的 why normal distribution is normal?</a></li>
<li class="chapter" data-level="46.2" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#身高的高斯模型-gaussian-model-of-height"><i class="fa fa-check"></i><b>46.2</b> 身高的高斯模型 Gaussian model of height</a>
<ul>
<li class="chapter" data-level="46.2.1" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#小方格估計法近似事後概率分佈"><i class="fa fa-check"></i><b>46.2.1</b> 小方格估計法近似事後概率分佈</a></li>
<li class="chapter" data-level="46.2.2" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#從計算獲得的事後概率分佈中採樣"><i class="fa fa-check"></i><b>46.2.2</b> 從計算獲得的事後概率分佈中採樣</a></li>
<li class="chapter" data-level="46.2.3" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#使用二次方程近似法"><i class="fa fa-check"></i><b>46.2.3</b> 使用二次方程近似法</a></li>
<li class="chapter" data-level="46.2.4" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#關於-beta-的先驗概率-priors"><i class="fa fa-check"></i><b>46.2.4</b> 關於 <span class="math inline">\(\beta\)</span> 的先驗概率 Priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html"><i class="fa fa-check"></i><b>47</b> 直線和曲線 curves and lines</a>
<ul>
<li class="chapter" data-level="47.1" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html#多項式回歸模型"><i class="fa fa-check"></i><b>47.1</b> 多項式回歸模型</a></li>
<li class="chapter" data-level="47.2" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html#平滑曲線-splines"><i class="fa fa-check"></i><b>47.2</b> 平滑曲線 Splines</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html"><i class="fa fa-check"></i><b>48</b> 多重線性回歸模型 many more variables</a>
<ul>
<li class="chapter" data-level="48.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#waffle"><i class="fa fa-check"></i><b>48.1</b> 虛假的相關性</a></li>
<li class="chapter" data-level="48.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#繪製輔助我們理解的有向無環圖"><i class="fa fa-check"></i><b>48.2</b> 繪製輔助我們理解的有向無環圖</a></li>
<li class="chapter" data-level="48.3" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#多重線性回歸模型的表達"><i class="fa fa-check"></i><b>48.3</b> 多重線性回歸模型的表達</a>
<ul>
<li class="chapter" data-level="48.3.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#預測變量殘差圖-predictor-residual-plots"><i class="fa fa-check"></i><b>48.3.1</b> 預測變量殘差圖 predictor residual plots</a></li>
<li class="chapter" data-level="48.3.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#事後分佈預測圖-posterior-prediction-plots"><i class="fa fa-check"></i><b>48.3.2</b> 事後分佈預測圖 posterior prediction plots</a></li>
<li class="chapter" data-level="48.3.3" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#反現實圖-counterfactual-plots"><i class="fa fa-check"></i><b>48.3.3</b> 反現實圖 counterfactual plots</a></li>
</ul></li>
<li class="chapter" data-level="48.4" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#被掩蓋起來的關係"><i class="fa fa-check"></i><b>48.4</b> 被掩蓋起來的關係</a></li>
<li class="chapter" data-level="48.5" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#分類型變量-categorical-variables"><i class="fa fa-check"></i><b>48.5</b> 分類型變量 categorical variables</a>
<ul>
<li class="chapter" data-level="48.5.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#二進制型變量"><i class="fa fa-check"></i><b>48.5.1</b> 二進制型變量</a></li>
<li class="chapter" data-level="48.5.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#多於兩個分類的分類變量"><i class="fa fa-check"></i><b>48.5.2</b> 多於兩個分類的分類變量</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html"><i class="fa fa-check"></i><b>49</b> 有向無環圖 DAG &amp; 可怕的因果 Causal Terror</a>
<ul>
<li class="chapter" data-level="49.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#multicollinearity"><i class="fa fa-check"></i><b>49.1</b> 多重共線性問題 multicollinearity</a>
<ul>
<li class="chapter" data-level="49.1.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#哺乳動物奶質量數據中的共線性"><i class="fa fa-check"></i><b>49.1.1</b> 哺乳動物奶質量數據中的共線性</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#posttreatbias"><i class="fa fa-check"></i><b>49.2</b> 治療後偏倚 post-treatment bias</a>
<ul>
<li class="chapter" data-level="49.2.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#設定模型"><i class="fa fa-check"></i><b>49.2.1</b> 設定模型</a></li>
</ul></li>
<li class="chapter" data-level="49.3" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#對撞因子偏倚-collider-bias"><i class="fa fa-check"></i><b>49.3</b> 對撞因子偏倚 collider bias</a>
<ul>
<li class="chapter" data-level="49.3.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#虛假的傷心對撞因子-collider-of-false-sorrow"><i class="fa fa-check"></i><b>49.3.1</b> 虛假的傷心對撞因子 collider of false sorrow</a></li>
<li class="chapter" data-level="49.3.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#對撞因子偏倚另一實例未測量變量造成的碰撞偏倚"><i class="fa fa-check"></i><b>49.3.2</b> 對撞因子偏倚另一實例（未測量變量造成的碰撞偏倚）</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#直面混雜效應"><i class="fa fa-check"></i><b>49.4</b> 直面混雜效應</a>
<ul>
<li class="chapter" data-level="49.4.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#兩條通路"><i class="fa fa-check"></i><b>49.4.1</b> 兩條通路</a></li>
<li class="chapter" data-level="49.4.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#華夫餅的後門"><i class="fa fa-check"></i><b>49.4.2</b> 華夫餅的後門</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="50" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html"><i class="fa fa-check"></i><b>50</b> 模型選擇 model selection</a>
<ul>
<li class="chapter" data-level="50.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#預測變量越多越好嗎"><i class="fa fa-check"></i><b>50.1</b> 預測變量越多越好嗎</a>
<ul>
<li class="chapter" data-level="50.1.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#變量越多總是會提高模型的擬合程度"><i class="fa fa-check"></i><b>50.1.1</b> 變量越多總是會提高模型的擬合程度</a></li>
<li class="chapter" data-level="50.1.2" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#也不是預測變量越少越好"><i class="fa fa-check"></i><b>50.1.2</b> 也不是預測變量越少越好</a></li>
</ul></li>
<li class="chapter" data-level="50.2" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#信息熵-information-entropy"><i class="fa fa-check"></i><b>50.2</b> 信息熵 information entropy</a>
<ul>
<li class="chapter" data-level="50.2.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#從信息熵到精確度-from-entropy-to-accuracy"><i class="fa fa-check"></i><b>50.2.1</b> 從信息熵到精確度 From entropy to accuracy</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#模型之間的比較"><i class="fa fa-check"></i><b>50.3</b> 模型之間的比較</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html"><i class="fa fa-check"></i><b>51</b> 交互作用 it’s all about interaction</a>
<ul>
<li class="chapter" data-level="51.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#設計一個交互作用模型"><i class="fa fa-check"></i><b>51.1</b> 設計一個交互作用模型</a>
<ul>
<li class="chapter" data-level="51.1.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#設計非洲大陸地形的模型"><i class="fa fa-check"></i><b>51.1.1</b> 設計非洲大陸地形的模型</a></li>
<li class="chapter" data-level="51.1.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#加一個指示變量並不是一個好選擇"><i class="fa fa-check"></i><b>51.1.2</b> 加一個指示變量並不是一個好選擇</a></li>
<li class="chapter" data-level="51.1.3" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#增加交互作用項是有幫助的"><i class="fa fa-check"></i><b>51.1.3</b> 增加交互作用項是有幫助的</a></li>
<li class="chapter" data-level="51.1.4" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#繪製交叉作用"><i class="fa fa-check"></i><b>51.1.4</b> 繪製交叉作用</a></li>
</ul></li>
<li class="chapter" data-level="51.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#連續型變量之間的交互作用"><i class="fa fa-check"></i><b>51.2</b> 連續型變量之間的交互作用</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#winter-flower-冬天的花"><i class="fa fa-check"></i><b>51.2.1</b> Winter flower 冬天的花</a></li>
<li class="chapter" data-level="51.2.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#繪製事後預測圖"><i class="fa fa-check"></i><b>51.2.2</b> 繪製事後預測圖</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="52" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html"><i class="fa fa-check"></i><b>52</b> 馬可夫鏈蒙地卡羅 MCMC</a>
<ul>
<li class="chapter" data-level="52.1" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#國王訪問個各島嶼問題"><i class="fa fa-check"></i><b>52.1</b> 國王訪問個各島嶼問題</a></li>
<li class="chapter" data-level="52.2" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#metropolis-演算法"><i class="fa fa-check"></i><b>52.2</b> Metropolis 演算法</a></li>
<li class="chapter" data-level="52.3" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#簡單的-hmc-hamitonian-monte-carlo-ulam"><i class="fa fa-check"></i><b>52.3</b> 簡單的 HMC (Hamitonian Monte Carlo) <code>ulam</code></a></li>
<li class="chapter" data-level="52.4" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#調教你的模型"><i class="fa fa-check"></i><b>52.4</b> 調教你的模型</a>
<ul>
<li class="chapter" data-level="52.4.1" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#無法被確認的參數-non-identifiable-parameters"><i class="fa fa-check"></i><b>52.4.1</b> 無法被確認的參數 non-identifiable parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="53" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html"><i class="fa fa-check"></i><b>53</b> 貝葉斯廣義線性回歸 Bayesian GLM</a>
<ul>
<li class="chapter" data-level="53.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#二項式回歸模型-binomial-regression"><i class="fa fa-check"></i><b>53.1</b> 二項式回歸模型 binomial regression</a>
<ul>
<li class="chapter" data-level="53.1.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#chimpanzees"><i class="fa fa-check"></i><b>53.1.1</b> 邏輯回歸模型數據實例：prosocial chimpanzees</a></li>
<li class="chapter" data-level="53.1.2" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#相對還是絕對"><i class="fa fa-check"></i><b>53.1.2</b> 相對還是絕對？</a></li>
<li class="chapter" data-level="53.1.3" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#歸納後的二進制數據繼續使用黑猩猩數據"><i class="fa fa-check"></i><b>53.1.3</b> 歸納後的二進制數據：繼續使用黑猩猩數據</a></li>
<li class="chapter" data-level="53.1.4" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#彙總型二進制數據大學錄取數據"><i class="fa fa-check"></i><b>53.1.4</b> 彙總型二進制數據：大學錄取數據</a></li>
</ul></li>
<li class="chapter" data-level="53.2" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸模型-poisson-regression"><i class="fa fa-check"></i><b>53.2</b> 泊松回歸模型 Poisson regression</a>
<ul>
<li class="chapter" data-level="53.2.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸實例太平洋島國居民使用的工具"><i class="fa fa-check"></i><b>53.2.1</b> 泊松回歸實例：太平洋島國居民使用的工具</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><i class="fa fa-check"></i><b>54</b> 貝葉斯廣義線性回歸模型的擴展 continuous mixture models</a>
<ul>
<li class="chapter" data-level="54.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#beta-二項分佈模型-beta-binomial-model"><i class="fa fa-check"></i><b>54.1</b> Beta 二項分佈模型 beta-binomial model</a></li>
<li class="chapter" data-level="54.2" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#負二項分佈模型伽馬泊松回歸模型-negative-binomialgamma-poisson"><i class="fa fa-check"></i><b>54.2</b> 負二項分佈模型，伽馬泊松回歸模型 Negative-binomial/gamma-Poisson</a></li>
<li class="chapter" data-level="54.3" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#零膨脹模型-zero-inflated-models"><i class="fa fa-check"></i><b>54.3</b> 零膨脹模型 zero-inflated models</a>
<ul>
<li class="chapter" data-level="54.3.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#零膨脹泊松回歸模型-zero-inflated-poisson"><i class="fa fa-check"></i><b>54.3.1</b> 零膨脹泊松回歸模型 zero-inflated Poisson</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#帶順序含義的多類別結果變量-ordered-categorical-outcomes"><i class="fa fa-check"></i><b>54.4</b> 帶順序含義的多類別結果變量 ordered categorical outcomes</a>
<ul>
<li class="chapter" data-level="54.4.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#用不同的截距來描述一個有順序的分佈-describing-an-ordered-distribution-with-intercepts"><i class="fa fa-check"></i><b>54.4.1</b> 用不同的截距來描述一個有順序的分佈 describing an ordered distribution with intercepts</a></li>
<li class="chapter" data-level="54.4.2" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#增加預測變量"><i class="fa fa-check"></i><b>54.4.2</b> 增加預測變量</a></li>
</ul></li>
<li class="chapter" data-level="54.5" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#帶順序含義的多類別預測型變量-ordered-categorical-predictors"><i class="fa fa-check"></i><b>54.5</b> 帶順序含義的多類別預測型變量 ordered categorical predictors</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html"><i class="fa fa-check"></i><b>55</b> 貝葉斯多層回歸模型 multilevel models</a>
<ul>
<li class="chapter" data-level="55.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#多層數據實例蝌蚪和青蛙數據-multilevel-tadpoles"><i class="fa fa-check"></i><b>55.1</b> 多層數據實例：蝌蚪和青蛙數據 multilevel tadpoles</a></li>
<li class="chapter" data-level="55.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#多層回歸的變化的效應和過度擬合過低擬合之間的交易-varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>55.2</b> 多層回歸的變化的效應和過度擬合/過低擬合之間的交易 varying effects and the underfitting/overfitting trade-off</a>
<ul>
<li class="chapter" data-level="55.2.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#用於產生模擬數據的模型-the-model"><i class="fa fa-check"></i><b>55.2.1</b> 用於產生模擬數據的模型 the model</a></li>
<li class="chapter" data-level="55.2.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#模擬存活概率結果-simulate-survivors"><i class="fa fa-check"></i><b>55.2.2</b> 模擬存活概率結果 simulate survivors</a></li>
<li class="chapter" data-level="55.2.3" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#計算完全不合併策略-no-pooling-estimates"><i class="fa fa-check"></i><b>55.2.3</b> 計算完全不合併策略 no-pooling estimates</a></li>
<li class="chapter" data-level="55.2.4" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#計算部分合併策略的結果-partial-pooling-estimates"><i class="fa fa-check"></i><b>55.2.4</b> 計算部分合併策略的結果 partial-pooling estimates</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#使用多於一個類別作爲多層回歸的隨機變量-more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>55.3</b> 使用多於一個類別作爲多層回歸的隨機變量 more than one type of cluster</a>
<ul>
<li class="chapter" data-level="55.3.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#黑猩猩數據的多層回歸模型-multilevel-chimpanzees"><i class="fa fa-check"></i><b>55.3.1</b> 黑猩猩數據的多層回歸模型 multilevel chimpanzees</a></li>
</ul></li>
<li class="chapter" data-level="55.4" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#分散轉換與非中心型先驗概率-divergent-transition-and-non-centered-priors"><i class="fa fa-check"></i><b>55.4</b> 分散轉換與非中心型先驗概率 divergent transition and non-centered priors</a>
<ul>
<li class="chapter" data-level="55.4.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#魔鬼的漏斗-the-devils-funnel"><i class="fa fa-check"></i><b>55.4.1</b> 魔鬼的漏斗 the devil’s funnel</a></li>
<li class="chapter" data-level="55.4.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#參數非中心化的黑猩猩數據"><i class="fa fa-check"></i><b>55.4.2</b> 參數非中心化的黑猩猩數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="56" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><i class="fa fa-check"></i><b>56</b> 貝葉斯多層回歸模型2 隨機斜率模型 multilevel models – varying slopes models</a>
<ul>
<li class="chapter" data-level="56.1" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#模擬隨機斜率數據"><i class="fa fa-check"></i><b>56.1</b> 模擬隨機斜率數據</a>
<ul>
<li class="chapter" data-level="56.1.1" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#模擬觀察值-simulate-observations"><i class="fa fa-check"></i><b>56.1.1</b> 模擬觀察值 simulate observations</a></li>
<li class="chapter" data-level="56.1.2" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#隨機斜率模型-the-varying-slopes-model"><i class="fa fa-check"></i><b>56.1.2</b> 隨機斜率模型 the varying slopes model</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="57" data-path="revision.html"><a href="revision.html"><i class="fa fa-check"></i><b>57</b> 重要概念複習</a>
<ul>
<li class="chapter" data-level="57.1" data-path="revision.html"><a href="revision.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>57.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="57.2" data-path="revision.html"><a href="revision.html#似然"><i class="fa fa-check"></i><b>57.2</b> 似然</a></li>
<li class="chapter" data-level="57.3" data-path="revision.html"><a href="revision.html#極大似然估計"><i class="fa fa-check"></i><b>57.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="57.4" data-path="revision.html"><a href="revision.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>57.4</b> 關於假設檢驗的複習</a>
<ul>
<li class="chapter" data-level="57.4.1" data-path="revision.html"><a href="revision.html#子集似然函數"><i class="fa fa-check"></i><b>57.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="57.5" data-path="revision.html"><a href="revision.html#線性迴歸複習"><i class="fa fa-check"></i><b>57.5</b> 線性迴歸複習</a>
<ul>
<li class="chapter" data-level="57.5.1" data-path="revision.html"><a href="revision.html#簡單線性迴歸"><i class="fa fa-check"></i><b>57.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="57.5.2" data-path="revision.html"><a href="revision.html#多元線性迴歸"><i class="fa fa-check"></i><b>57.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="57.5.3" data-path="revision.html"><a href="revision.html#score-equations"><i class="fa fa-check"></i><b>57.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="57.6" data-path="revision.html"><a href="revision.html#glm-practical-01"><i class="fa fa-check"></i><b>57.6</b> GLM-Practical 01</a>
<ul>
<li class="chapter" data-level="57.6.1" data-path="revision.html"><a href="revision.html#建立似然方程"><i class="fa fa-check"></i><b>57.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="57.6.2" data-path="revision.html"><a href="revision.html#建立對數似然方程"><i class="fa fa-check"></i><b>57.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="57.6.3" data-path="revision.html"><a href="revision.html#線性回歸模型"><i class="fa fa-check"></i><b>57.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="57.6.4" data-path="revision.html"><a href="revision.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>57.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="58" data-path="intro-GLM.html"><a href="intro-GLM.html"><i class="fa fa-check"></i><b>58</b> 廣義線性迴歸入門</a>
<ul>
<li class="chapter" data-level="58.1" data-path="intro-GLM.html"><a href="intro-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>58.1</b> 指數分佈家族</a>
<ul>
<li class="chapter" data-level="58.1.1" data-path="intro-GLM.html"><a href="intro-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>58.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="58.1.2" data-path="intro-GLM.html"><a href="intro-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>58.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="58.2" data-path="intro-GLM.html"><a href="intro-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>58.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="58.3" data-path="intro-GLM.html"><a href="intro-GLM.html#注意"><i class="fa fa-check"></i><b>58.3</b> 注意</a></li>
<li class="chapter" data-level="58.4" data-path="intro-GLM.html"><a href="intro-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>58.4</b> 如何在 R 裏擬合 “GLM”</a>
<ul>
<li class="chapter" data-level="58.4.1" data-path="intro-GLM.html"><a href="intro-GLM.html#margins-命令"><i class="fa fa-check"></i><b>58.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="58.4.2" data-path="intro-GLM.html"><a href="intro-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>58.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="intro-GLM.html"><a href="intro-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>58.5</b> GLM-Practical 02</a>
<ul>
<li class="chapter" data-level="58.5.1" data-path="intro-GLM.html"><a href="intro-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>58.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="58.5.2" data-path="intro-GLM.html"><a href="intro-GLM.html#r-練習"><i class="fa fa-check"></i><b>58.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>59</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a>
<ul>
<li class="chapter" data-level="59.1" data-path="logistic.html"><a href="logistic.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>59.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="59.2" data-path="logistic.html"><a href="logistic.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>59.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="59.3" data-path="logistic.html"><a href="logistic.html#logit-or-log"><i class="fa fa-check"></i><b>59.3</b> 注</a>
<ul>
<li class="chapter" data-level="59.3.1" data-path="logistic.html"><a href="logistic.html#exercise.-link-functions."><i class="fa fa-check"></i><b>59.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="59.4" data-path="logistic.html"><a href="logistic.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>59.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="59.5" data-path="logistic.html"><a href="logistic.html#BSEinfection"><i class="fa fa-check"></i><b>59.5</b> 邏輯迴歸實際案例</a>
<ul>
<li class="chapter" data-level="59.5.1" data-path="logistic.html"><a href="logistic.html#分析目的"><i class="fa fa-check"></i><b>59.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="59.5.2" data-path="logistic.html"><a href="logistic.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>59.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="59.5.3" data-path="logistic.html"><a href="logistic.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>59.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="59.6" data-path="logistic.html"><a href="logistic.html#glm-practical-03"><i class="fa fa-check"></i><b>59.6</b> GLM-Practical 03</a>
<ul>
<li class="chapter" data-level="59.6.1" data-path="logistic.html"><a href="logistic.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>59.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="59.6.2" data-path="logistic.html"><a href="logistic.html#哮喘門診數據"><i class="fa fa-check"></i><b>59.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>60</b> 模型比較和擬合優度</a>
<ul>
<li class="chapter" data-level="60.1" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>60.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="60.2" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>60.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="60.3" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>60.3</b> 飽和模型，模型的偏差，擬合優度</a>
<ul>
<li class="chapter" data-level="60.3.1" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>60.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="60.3.2" data-path="model-comparison.html"><a href="model-comparison.html#deviance"><i class="fa fa-check"></i><b>60.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="60.3.3" data-path="model-comparison.html"><a href="model-comparison.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>60.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="model-comparison.html"><a href="model-comparison.html#gof"><i class="fa fa-check"></i><b>60.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="60.5" data-path="model-comparison.html"><a href="model-comparison.html#glm-practical-04"><i class="fa fa-check"></i><b>60.5</b> GLM Practical 04</a>
<ul>
<li class="chapter" data-level="60.5.1" data-path="model-comparison.html"><a href="model-comparison.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>60.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="60.5.2" data-path="model-comparison.html"><a href="model-comparison.html#低出生體重數據"><i class="fa fa-check"></i><b>60.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="count-outcomes.html"><a href="count-outcomes.html"><i class="fa fa-check"></i><b>61</b> 計數型因變量 Count outcomes</a>
<ul>
<li class="chapter" data-level="61.1" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松-glm"><i class="fa fa-check"></i><b>61.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="61.2" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松迴歸實例"><i class="fa fa-check"></i><b>61.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="61.3" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>61.3</b> 過度離散 overdispersion</a>
<ul>
<li class="chapter" data-level="61.3.1" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散怎麼查"><i class="fa fa-check"></i><b>61.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="61.3.2" data-path="count-outcomes.html"><a href="count-outcomes.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>61.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
<li class="chapter" data-level="61.4" data-path="count-outcomes.html"><a href="count-outcomes.html#glm-practical-05"><i class="fa fa-check"></i><b>61.4</b> GLM Practical 05</a></li>
</ul></li>
<li class="chapter" data-level="62" data-path="GLM-rates.html"><a href="GLM-rates.html"><i class="fa fa-check"></i><b>62</b> 率的廣義線性迴歸 Poisson GLM for rates</a>
<ul>
<li class="chapter" data-level="62.1" data-path="GLM-rates.html"><a href="GLM-rates.html#醫學中的率"><i class="fa fa-check"></i><b>62.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="62.2" data-path="GLM-rates.html"><a href="GLM-rates.html#泊松過程"><i class="fa fa-check"></i><b>62.2</b> 泊松過程</a></li>
<li class="chapter" data-level="62.3" data-path="GLM-rates.html"><a href="GLM-rates.html#率的模型"><i class="fa fa-check"></i><b>62.3</b> 率的模型</a></li>
<li class="chapter" data-level="62.4" data-path="GLM-rates.html"><a href="GLM-rates.html#率的-glm"><i class="fa fa-check"></i><b>62.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="62.5" data-path="GLM-rates.html"><a href="GLM-rates.html#分析實例-example-british-doctors-study"><i class="fa fa-check"></i><b>62.5</b> 分析實例 Example: British doctors study</a>
<ul>
<li class="chapter" data-level="62.5.1" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-1-吸菸"><i class="fa fa-check"></i><b>62.5.1</b> 模型 1: 吸菸</a></li>
<li class="chapter" data-level="62.5.2" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-2-吸菸-年齡"><i class="fa fa-check"></i><b>62.5.2</b> 模型 2: 吸菸 + 年齡</a></li>
<li class="chapter" data-level="62.5.3" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-3-吸菸-年齡-吸菸與年齡的交互作用項"><i class="fa fa-check"></i><b>62.5.3</b> 模型 3: 吸菸 + 年齡 + 吸菸與年齡的交互作用項</a></li>
</ul></li>
<li class="chapter" data-level="62.6" data-path="GLM-rates.html"><a href="GLM-rates.html#glm-practical-06"><i class="fa fa-check"></i><b>62.6</b> GLM Practical 06</a>
<ul>
<li class="chapter" data-level="62.6.1" data-path="GLM-rates.html"><a href="GLM-rates.html#將數據導入-r-環境中初步計算每個工廠不同年齡組工人的死亡人數和追蹤人年數據"><i class="fa fa-check"></i><b>62.6.1</b> 將數據導入 R 環境中，初步計算每個工廠不同年齡組工人的死亡人數，和追蹤人年數據。</a></li>
<li class="chapter" data-level="62.6.2" data-path="GLM-rates.html"><a href="GLM-rates.html#計算死亡率的對數值繪製其與年齡組的點圖"><i class="fa fa-check"></i><b>62.6.2</b> 計算死亡率的對數值，繪製其與年齡組的點圖。</a></li>
<li class="chapter" data-level="62.6.3" data-path="GLM-rates.html"><a href="GLM-rates.html#請用數學語言描述死亡率和年齡組之間關係的模型"><i class="fa fa-check"></i><b>62.6.3</b> 請用數學語言描述死亡率和年齡組之間關係的模型。</a></li>
<li class="chapter" data-level="62.6.4" data-path="GLM-rates.html"><a href="GLM-rates.html#接下來的模型中在前面的基礎上加入工廠編號你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異計算年齡調整過後的兩工廠之間死亡率之比和95ci"><i class="fa fa-check"></i><b>62.6.4</b> 接下來的模型中在前面的基礎上加入工廠編號，你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異？計算年齡調整過後的兩工廠之間死亡率之比和95%CI。</a></li>
<li class="chapter" data-level="62.6.5" data-path="GLM-rates.html"><a href="GLM-rates.html#現在在前一步加了工廠變量的基礎上重新擬合模型加入工廠和年齡之間的交互作用項"><i class="fa fa-check"></i><b>62.6.5</b> 現在在前一步加了工廠變量的基礎上，重新擬合模型，加入工廠和年齡之間的交互作用項</a></li>
<li class="chapter" data-level="62.6.6" data-path="GLM-rates.html"><a href="GLM-rates.html#現在把年齡當作連續型變量來考慮擬合下列模型"><i class="fa fa-check"></i><b>62.6.6</b> 現在把年齡當作連續型變量來考慮。擬合下列模型</a></li>
<li class="chapter" data-level="62.6.7" data-path="GLM-rates.html"><a href="GLM-rates.html#計算只有年齡連續型和工廠兩個變量模型時的模型偏差-deviance該模型和第一部分中飽和模型之間相比相差幾個參數parameters你有怎樣的推論"><i class="fa fa-check"></i><b>62.6.7</b> 計算只有年齡(連續型)和工廠兩個變量模型時的模型偏差 (deviance)，該模型和第一部分中飽和模型之間相比相差幾個參數(parameters)？你有怎樣的推論？</a></li>
<li class="chapter" data-level="62.6.8" data-path="GLM-rates.html"><a href="GLM-rates.html#對這個數據進行了這一系列的分析之後你從流行病學的角度來說有怎樣的結論"><i class="fa fa-check"></i><b>62.6.8</b> 對這個數據進行了這一系列的分析之後，你從流行病學的角度來說，有怎樣的結論？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="63" data-path="confounding-interaction.html"><a href="confounding-interaction.html"><i class="fa fa-check"></i><b>63</b> 混雜的調整，交互作用，和模型的可壓縮性</a>
<ul>
<li class="chapter" data-level="63.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#混雜因素的調整"><i class="fa fa-check"></i><b>63.1</b> 混雜因素的調整</a>
<ul>
<li class="chapter" data-level="63.1.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>63.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#交互作用"><i class="fa fa-check"></i><b>63.2</b> 交互作用</a></li>
<li class="chapter" data-level="63.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>63.3</b> 可壓縮性 collapsibility</a>
<ul>
<li class="chapter" data-level="63.3.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>63.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="63.3.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#collapsibility"><i class="fa fa-check"></i><b>63.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="63.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#interaction-depend-scale"><i class="fa fa-check"></i><b>63.4</b> 交互作用對尺度的依賴性</a></li>
<li class="chapter" data-level="63.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#glm-practical-07"><i class="fa fa-check"></i><b>63.5</b> GLM Practical 07</a>
<ul>
<li class="chapter" data-level="63.5.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#使用你熟悉的統計學軟件擬合一個由-fupcontrol-作爲結果變量treat-作爲唯一預測變量的廣義線性回歸模型-根據報告的結果寫一段適用於醫學流行病學文獻雜誌的報告"><i class="fa fa-check"></i><b>63.5.1</b> 使用你熟悉的統計學軟件擬合一個由 <code>fupcontrol</code> 作爲結果變量，<code>treat</code> 作爲唯一預測變量的廣義線性回歸模型。 根據報告的結果，寫一段適用於醫學/流行病學文獻雜誌的報告。</a></li>
<li class="chapter" data-level="63.5.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#分析-treat-和-basecontrol-之間的關係結果是否如你的預期那樣"><i class="fa fa-check"></i><b>63.5.2</b> 分析 <code>treat</code> 和 <code>basecontrol</code> 之間的關係，結果是否如你的預期那樣？</a></li>
<li class="chapter" data-level="63.5.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#已知模型中如果增加調整基線變量可能對-fupcontrol-有一定的預測效果-在你的模型中增加基線血壓控制情況的變量與-m0-的結果-治療效果-treatment-effect參數標準誤-standard-error和-p-值重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述"><i class="fa fa-check"></i><b>63.5.3</b> 已知模型中如果增加調整基線變量可能對 <code>fupcontrol</code> 有一定的預測效果。 在你的模型中增加基線血壓控制情況的變量。與 <code>m0</code> 的結果 (治療效果 treatment effect；參數標準誤 standard error；和 p 值)。重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述。</a></li>
<li class="chapter" data-level="63.5.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#你更推薦使用哪個模型作爲最終主要結果的彙報"><i class="fa fa-check"></i><b>63.5.4</b> 你更推薦使用哪個模型作爲最終主要結果的彙報？</a></li>
<li class="chapter" data-level="63.5.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同爲了回答這個問題請擬合對應的廣義線性回歸模型根據結果回答這個問題"><i class="fa fa-check"></i><b>63.5.5</b> 實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同。爲了回答這個問題，請擬合對應的廣義線性回歸模型。根據結果回答這個問題。</a></li>
<li class="chapter" data-level="63.5.6" data-path="confounding-interaction.html"><a href="confounding-interaction.html#換一個模型先不考慮-basecontrol使用危險度比-risk-ratio-來評價不同治療方案之間的療效"><i class="fa fa-check"></i><b>63.5.6</b> 換一個模型，先不考慮 <code>basecontrol</code>，使用危險度比 (risk ratio) 來評價不同治療方案之間的療效。</a></li>
<li class="chapter" data-level="63.5.7" data-path="confounding-interaction.html"><a href="confounding-interaction.html#在前一模型m4中加入-basecontrol與未加入該變量時模型的輸出結果相比有什麼不同"><i class="fa fa-check"></i><b>63.5.7</b> 在前一模型<code>m4</code>中加入 <code>basecontrol</code>，與未加入該變量時模型的輸出結果相比，有什麼不同？</a></li>
<li class="chapter" data-level="63.5.8" data-path="confounding-interaction.html"><a href="confounding-interaction.html#給上述模型增加交互作用項對於危險度比作爲指標時的交互作用分析結果和使用比值比時相比你有怎樣的思考和結論"><i class="fa fa-check"></i><b>63.5.8</b> 給上述模型增加交互作用項。對於危險度比作爲指標時的交互作用分析結果，和使用比值比時相比，你有怎樣的思考和結論？</a></li>
<li class="chapter" data-level="63.5.9" data-path="confounding-interaction.html"><a href="confounding-interaction.html#如果說不考慮一個rct的統計分析不能在收集完數據之後修改這一事實你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢"><i class="fa fa-check"></i><b>63.5.9</b> 如果說不考慮一個RCT的統計分析不能在收集完數據之後修改這一事實，你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢？</a></li>
<li class="chapter" data-level="63.5.10" data-path="confounding-interaction.html"><a href="confounding-interaction.html#證明危險度比模型是可以壓縮的prove-that-the-log-link-models-are-collapsible."><i class="fa fa-check"></i><b>63.5.10</b> 證明危險度比模型是可以壓縮的。Prove that the log-link models are collapsible.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="64" data-path="epi-logistic.html"><a href="epi-logistic.html"><i class="fa fa-check"></i><b>64</b> 流行病學中的邏輯迴歸</a>
<ul>
<li class="chapter" data-level="64.1" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>64.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="64.2" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3"><i class="fa fa-check"></i><b>64.2</b> 以簡單二進制暴露變量爲例</a>
<ul>
<li class="chapter" data-level="64.2.1" data-path="epi-logistic.html"><a href="epi-logistic.html#先決條件"><i class="fa fa-check"></i><b>64.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="64.2.2" data-path="epi-logistic.html"><a href="epi-logistic.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>64.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="64.2.3" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3-4"><i class="fa fa-check"></i><b>64.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="64.3" data-path="epi-logistic.html"><a href="epi-logistic.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>64.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a>
<ul>
<li class="chapter" data-level="64.3.1" data-path="epi-logistic.html"><a href="epi-logistic.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>64.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="64.3.2" data-path="epi-logistic.html"><a href="epi-logistic.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>64.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="64.3.3" data-path="epi-logistic.html"><a href="epi-logistic.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>64.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="64.4" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>64.4</b> 流行病學研究中變量的調整策略</a></li>
<li class="chapter" data-level="64.5" data-path="epi-logistic.html"><a href="epi-logistic.html#glm-practical-08"><i class="fa fa-check"></i><b>64.5</b> GLM Practical 08</a>
<ul>
<li class="chapter" data-level="64.5.1" data-path="epi-logistic.html"><a href="epi-logistic.html#part-1"><i class="fa fa-check"></i><b>64.5.1</b> Part 1</a></li>
<li class="chapter" data-level="64.5.2" data-path="epi-logistic.html"><a href="epi-logistic.html#part-2"><i class="fa fa-check"></i><b>64.5.2</b> Part 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="GLM-strategy.html"><a href="GLM-strategy.html"><i class="fa fa-check"></i><b>65</b> 分析策略</a>
<ul>
<li class="chapter" data-level="65.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#明確分析目的"><i class="fa fa-check"></i><b>65.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="65.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>65.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a>
<ul>
<li class="chapter" data-level="65.2.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>65.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="65.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>65.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a>
<ul>
<li class="chapter" data-level="65.3.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#不成熟的小策略"><i class="fa fa-check"></i><b>65.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="65.3.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#補充"><i class="fa fa-check"></i><b>65.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="65.4" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>65.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
<li class="chapter" data-level="65.5" data-path="GLM-strategy.html"><a href="GLM-strategy.html#glm-practical-09"><i class="fa fa-check"></i><b>65.5</b> GLM practical 09</a>
<ul>
<li class="chapter" data-level="65.5.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-1-1"><i class="fa fa-check"></i><b>65.5.1</b> Part 1</a></li>
<li class="chapter" data-level="65.5.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-2-1"><i class="fa fa-check"></i><b>65.5.2</b> Part 2</a></li>
<li class="chapter" data-level="65.5.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-3"><i class="fa fa-check"></i><b>65.5.3</b> Part 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="66" data-path="checkingGLM.html"><a href="checkingGLM.html"><i class="fa fa-check"></i><b>66</b> 檢查你的模型 Model Checking - GLM</a>
<ul>
<li class="chapter" data-level="66.1" data-path="checkingGLM.html"><a href="checkingGLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>66.1</b> 線性預測方程的定義</a>
<ul>
<li class="chapter" data-level="66.1.1" data-path="checkingGLM.html"><a href="checkingGLM.html#殘差-1"><i class="fa fa-check"></i><b>66.1.1</b> 殘差</a></li>
<li class="chapter" data-level="66.1.2" data-path="checkingGLM.html"><a href="checkingGLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>66.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="66.1.3" data-path="checkingGLM.html"><a href="checkingGLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>66.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="66.2" data-path="checkingGLM.html"><a href="checkingGLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>66.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="66.3" data-path="checkingGLM.html"><a href="checkingGLM.html#鏈接方程"><i class="fa fa-check"></i><b>66.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="66.4" data-path="checkingGLM.html"><a href="checkingGLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>66.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="66.5" data-path="checkingGLM.html"><a href="checkingGLM.html#practical-10"><i class="fa fa-check"></i><b>66.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="67" data-path="assess-perf.html"><a href="assess-perf.html"><i class="fa fa-check"></i><b>67</b> 評價模型的表現 Assessing model performance</a>
<ul>
<li class="chapter" data-level="67.1" data-path="assess-perf.html"><a href="assess-perf.html#calibration"><i class="fa fa-check"></i><b>67.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="67.2" data-path="assess-perf.html"><a href="assess-perf.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>67.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="67.3" data-path="assess-perf.html"><a href="assess-perf.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>67.3</b> 分辨能力 descrimination</a>
<ul>
<li class="chapter" data-level="67.3.1" data-path="assess-perf.html"><a href="assess-perf.html#敏感度和特異度"><i class="fa fa-check"></i><b>67.3.1</b> 敏感度和特異度</a></li>
</ul></li>
<li class="chapter" data-level="67.4" data-path="assess-perf.html"><a href="assess-perf.html#practical-11"><i class="fa fa-check"></i><b>67.4</b> Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="68" data-path="paired-ana.html"><a href="paired-ana.html"><i class="fa fa-check"></i><b>68</b> 配對實驗數據的分析法</a>
<ul>
<li class="chapter" data-level="68.1" data-path="paired-ana.html"><a href="paired-ana.html#配對的原理"><i class="fa fa-check"></i><b>68.1</b> 配對的原理</a>
<ul>
<li class="chapter" data-level="68.1.1" data-path="paired-ana.html"><a href="paired-ana.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>68.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="68.1.2" data-path="paired-ana.html"><a href="paired-ana.html#控制混雜因素"><i class="fa fa-check"></i><b>68.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="68.2" data-path="paired-ana.html"><a href="paired-ana.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>68.2</b> 結果變量爲連續型變量的配對實驗</a>
<ul>
<li class="chapter" data-level="68.2.1" data-path="paired-ana.html"><a href="paired-ana.html#一般檢驗方法"><i class="fa fa-check"></i><b>68.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="68.2.2" data-path="paired-ana.html"><a href="paired-ana.html#用迴歸法分析"><i class="fa fa-check"></i><b>68.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="68.3" data-path="paired-ana.html"><a href="paired-ana.html#結果變量是二進制變量的配對實驗"><i class="fa fa-check"></i><b>68.3</b> 結果變量是二進制變量的配對實驗</a>
<ul>
<li class="chapter" data-level="68.3.1" data-path="paired-ana.html"><a href="paired-ana.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>68.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="68.3.2" data-path="paired-ana.html"><a href="paired-ana.html#mcnemars-test"><i class="fa fa-check"></i><b>68.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="68.3.3" data-path="paired-ana.html"><a href="paired-ana.html#二進制型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>68.3.3</b> 二進制型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="68.3.4" data-path="paired-ana.html"><a href="paired-ana.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>68.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="paired-ana.html"><a href="paired-ana.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>68.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="69" data-path="conditional-logistic.html"><a href="conditional-logistic.html"><i class="fa fa-check"></i><b>69</b> 條件邏輯迴歸 Conditional logistic regression</a>
<ul>
<li class="chapter" data-level="69.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>69.1</b> 配對實驗的邏輯迴歸模型</a>
<ul>
<li class="chapter" data-level="69.1.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對病例對照研究"><i class="fa fa-check"></i><b>69.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="69.1.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對隊列研究"><i class="fa fa-check"></i><b>69.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="69.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸-二進制暴露變量"><i class="fa fa-check"></i><b>69.2</b> 條件邏輯回歸 – 二進制暴露變量</a>
<ul>
<li class="chapter" data-level="69.2.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>69.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="69.2.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>69.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="69.2.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>69.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="69.2.4" data-path="conditional-logistic.html"><a href="conditional-logistic.html#進一步擴展"><i class="fa fa-check"></i><b>69.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="69.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>69.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="70" data-path="multinomial-logistic.html"><a href="multinomial-logistic.html"><i class="fa fa-check"></i><b>70</b> 多項邏輯回歸 Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="71" data-path="ordinal-logistic.html"><a href="ordinal-logistic.html"><i class="fa fa-check"></i><b>71</b> 順序邏輯回歸 Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="72" data-path="Hierarchical.html"><a href="Hierarchical.html"><i class="fa fa-check"></i><b>72</b> 相互依賴數據及簡單的應對方案</a>
<ul>
<li class="chapter" data-level="72.1" data-path="Hierarchical.html"><a href="Hierarchical.html#相互依賴的數據"><i class="fa fa-check"></i><b>72.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="72.2" data-path="Hierarchical.html"><a href="Hierarchical.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>72.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="72.3" data-path="Hierarchical.html"><a href="Hierarchical.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>72.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="72.4" data-path="Hierarchical.html"><a href="Hierarchical.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>72.4</b> 邊際模型和條件模型 marginal and conditional models</a>
<ul>
<li class="chapter" data-level="72.4.1" data-path="Hierarchical.html"><a href="Hierarchical.html#標記法-notation"><i class="fa fa-check"></i><b>72.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="72.4.2" data-path="Hierarchical.html"><a href="Hierarchical.html#合並每個階層"><i class="fa fa-check"></i><b>72.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="72.4.3" data-path="Hierarchical.html"><a href="Hierarchical.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>72.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="72.4.4" data-path="Hierarchical.html"><a href="Hierarchical.html#分解層級數據"><i class="fa fa-check"></i><b>72.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="72.4.5" data-path="Hierarchical.html"><a href="Hierarchical.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>72.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="72.5" data-path="Hierarchical.html"><a href="Hierarchical.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>72.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="72.6" data-path="Hierarchical.html"><a href="Hierarchical.html#practical-hierarchical-01"><i class="fa fa-check"></i><b>72.6</b> Practical Hierarchical 01</a>
<ul>
<li class="chapter" data-level="72.6.1" data-path="Hierarchical.html"><a href="Hierarchical.html#數據"><i class="fa fa-check"></i><b>72.6.1</b> 數據</a></li>
<li class="chapter" data-level="72.6.2" data-path="Hierarchical.html"><a href="Hierarchical.html#問題"><i class="fa fa-check"></i><b>72.6.2</b> 問題</a></li>
<li class="chapter" data-level="72.6.3" data-path="Hierarchical.html"><a href="Hierarchical.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>72.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="72.6.4" data-path="Hierarchical.html"><a href="Hierarchical.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>72.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="72.6.5" data-path="Hierarchical.html"><a href="Hierarchical.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>72.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="72.6.6" data-path="Hierarchical.html"><a href="Hierarchical.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>72.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="72.6.7" data-path="Hierarchical.html"><a href="Hierarchical.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>72.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="72.6.8" data-path="Hierarchical.html"><a href="Hierarchical.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>72.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="72.6.9" data-path="Hierarchical.html"><a href="Hierarchical.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>72.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="72.6.10" data-path="Hierarchical.html"><a href="Hierarchical.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>72.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="72.6.11" data-path="Hierarchical.html"><a href="Hierarchical.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>72.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="72.6.12" data-path="Hierarchical.html"><a href="Hierarchical.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>72.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="72.6.13" data-path="Hierarchical.html"><a href="Hierarchical.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>72.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="72.6.14" data-path="Hierarchical.html"><a href="Hierarchical.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>72.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="72.6.15" data-path="Hierarchical.html"><a href="Hierarchical.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>72.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="72.6.16" data-path="Hierarchical.html"><a href="Hierarchical.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>72.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="73" data-path="random-intercept.html"><a href="random-intercept.html"><i class="fa fa-check"></i><b>73</b> 隨機截距模型 random intercept model</a>
<ul>
<li class="chapter" data-level="73.1" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>73.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="73.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>73.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="73.3" data-path="random-intercept.html"><a href="random-intercept.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>73.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="73.4" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>73.4</b> 隨機截距模型中的統計推斷</a>
<ul>
<li class="chapter" data-level="73.4.1" data-path="random-intercept.html"><a href="random-intercept.html#fixed-inference"><i class="fa fa-check"></i><b>73.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="73.4.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>73.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="73.5" data-path="random-intercept.html"><a href="random-intercept.html#practical-hierarchical-02"><i class="fa fa-check"></i><b>73.5</b> Practical Hierarchical 02</a>
<ul>
<li class="chapter" data-level="73.5.1" data-path="random-intercept.html"><a href="random-intercept.html#數據-1"><i class="fa fa-check"></i><b>73.5.1</b> 數據</a></li>
<li class="chapter" data-level="73.5.2" data-path="random-intercept.html"><a href="random-intercept.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>73.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="73.5.3" data-path="random-intercept.html"><a href="random-intercept.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>73.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="73.5.4" data-path="random-intercept.html"><a href="random-intercept.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>73.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="73.5.5" data-path="random-intercept.html"><a href="random-intercept.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>73.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="73.5.6" data-path="random-intercept.html"><a href="random-intercept.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>73.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="73.5.7" data-path="random-intercept.html"><a href="random-intercept.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>73.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="73.5.8" data-path="random-intercept.html"><a href="random-intercept.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>73.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="73.5.9" data-path="random-intercept.html"><a href="random-intercept.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>73.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="73.5.10" data-path="random-intercept.html"><a href="random-intercept.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>73.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="73.5.11" data-path="random-intercept.html"><a href="random-intercept.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>73.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="74" data-path="random-inter-cov.html"><a href="random-inter-cov.html"><i class="fa fa-check"></i><b>74</b> 隨機截距模型中加入共變量 random intercept model with covariates</a>
<ul>
<li class="chapter" data-level="74.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>74.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="74.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>74.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="74.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>74.3</b> 賦值予隨機效應成分</a>
<ul>
<li class="chapter" data-level="74.3.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>74.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="74.3.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#eb-預測值"><i class="fa fa-check"></i><b>74.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="74.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>74.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="74.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>74.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="74.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#層內層間效應估計"><i class="fa fa-check"></i><b>74.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="74.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>74.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="74.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#practical-hierarchical-03"><i class="fa fa-check"></i><b>74.8</b> Practical Hierarchical 03</a>
<ul>
<li class="chapter" data-level="74.8.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>74.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="74.8.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>74.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="74.8.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>74.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="74.8.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>74.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="74.8.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>74.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="74.8.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>74.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="74.8.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>74.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="74.8.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>74.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="74.8.9" data-path="random-inter-cov.html"><a href="random-inter-cov.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>74.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="74.8.10" data-path="random-inter-cov.html"><a href="random-inter-cov.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>74.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="74.8.11" data-path="random-inter-cov.html"><a href="random-inter-cov.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>74.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="75" data-path="random-coefficient.html"><a href="random-coefficient.html"><i class="fa fa-check"></i><b>75</b> 隨機回歸系數模型 random coefficient model</a>
<ul>
<li class="chapter" data-level="75.1" data-path="random-coefficient.html"><a href="random-coefficient.html#gcse-scores-實例"><i class="fa fa-check"></i><b>75.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="75.2" data-path="random-coefficient.html"><a href="random-coefficient.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>75.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="75.3" data-path="random-coefficient.html"><a href="random-coefficient.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>75.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="75.4" data-path="random-coefficient.html"><a href="random-coefficient.html#使用模型結果推斷"><i class="fa fa-check"></i><b>75.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="75.5" data-path="random-coefficient.html"><a href="random-coefficient.html#random-var"><i class="fa fa-check"></i><b>75.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="75.6" data-path="random-coefficient.html"><a href="random-coefficient.html#模型效果評估"><i class="fa fa-check"></i><b>75.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="75.7" data-path="random-coefficient.html"><a href="random-coefficient.html#practical-hierarchical-04"><i class="fa fa-check"></i><b>75.7</b> Practical Hierarchical 04</a>
<ul>
<li class="chapter" data-level="75.7.1" data-path="random-coefficient.html"><a href="random-coefficient.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>75.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="75.7.2" data-path="random-coefficient.html"><a href="random-coefficient.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>75.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="75.7.3" data-path="random-coefficient.html"><a href="random-coefficient.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>75.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="75.7.4" data-path="random-coefficient.html"><a href="random-coefficient.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>75.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="75.7.5" data-path="random-coefficient.html"><a href="random-coefficient.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>75.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="75.7.6" data-path="random-coefficient.html"><a href="random-coefficient.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>75.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="75.7.7" data-path="random-coefficient.html"><a href="random-coefficient.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>75.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="75.7.8" data-path="random-coefficient.html"><a href="random-coefficient.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>75.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="75.7.9" data-path="random-coefficient.html"><a href="random-coefficient.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>75.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="75.7.10" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>75.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="75.7.11" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>75.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="longitudinal1.html"><a href="longitudinal1.html"><i class="fa fa-check"></i><b>76</b> 縱向研究數據 longitudinal data 1</a>
<ul>
<li class="chapter" data-level="76.1" data-path="longitudinal1.html"><a href="longitudinal1.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>76.1</b> 固定測量時刻 fixed occasions</a>
<ul>
<li class="chapter" data-level="76.1.1" data-path="longitudinal1.html"><a href="longitudinal1.html#缺失值-missing-data"><i class="fa fa-check"></i><b>76.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="longitudinal1.html"><a href="longitudinal1.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>76.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="76.3" data-path="longitudinal1.html"><a href="longitudinal1.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>76.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="76.4" data-path="longitudinal1.html"><a href="longitudinal1.html#practical-05-hier"><i class="fa fa-check"></i><b>76.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="77" data-path="longitudinal2.html"><a href="longitudinal2.html"><i class="fa fa-check"></i><b>77</b> 縱向研究數據 longitudinal data 2</a>
<ul>
<li class="chapter" data-level="77.1" data-path="longitudinal2.html"><a href="longitudinal2.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>77.1</b> 邊際結構 marginal structures</a>
<ul>
<li class="chapter" data-level="77.1.1" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機截距模型"><i class="fa fa-check"></i><b>77.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="77.1.2" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機系數模型"><i class="fa fa-check"></i><b>77.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="77.2" data-path="longitudinal2.html"><a href="longitudinal2.html#矩陣記法"><i class="fa fa-check"></i><b>77.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="77.3" data-path="longitudinal2.html"><a href="longitudinal2.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>77.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="77.4" data-path="longitudinal2.html"><a href="longitudinal2.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>77.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="77.5" data-path="longitudinal2.html"><a href="longitudinal2.html#其他要點評論"><i class="fa fa-check"></i><b>77.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="77.6" data-path="longitudinal2.html"><a href="longitudinal2.html#不平衡數據"><i class="fa fa-check"></i><b>77.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="77.7" data-path="longitudinal2.html"><a href="longitudinal2.html#practical-06-hier"><i class="fa fa-check"></i><b>77.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="78" data-path="longitudinal3.html"><a href="longitudinal3.html"><i class="fa fa-check"></i><b>78</b> 縱向研究數據 longitudinal data 3</a>
<ul>
<li class="chapter" data-level="78.1" data-path="longitudinal3.html"><a href="longitudinal3.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>78.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="78.2" data-path="longitudinal3.html"><a href="longitudinal3.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>78.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="78.3" data-path="longitudinal3.html"><a href="longitudinal3.html#分析策略"><i class="fa fa-check"></i><b>78.3</b> 分析策略</a>
<ul>
<li class="chapter" data-level="78.3.1" data-path="longitudinal3.html"><a href="longitudinal3.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>78.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="longitudinal3.html"><a href="longitudinal3.html#practical-07-hier"><i class="fa fa-check"></i><b>78.4</b> Practical 07-Hier</a></li>
</ul></li>
<li class="chapter" data-level="79" data-path="廣義估計方程式-generalized-estimating-equation.html"><a href="廣義估計方程式-generalized-estimating-equation.html"><i class="fa fa-check"></i><b>79</b> 廣義估計方程式 Generalized Estimating Equation</a>
<ul>
<li class="chapter" data-level="79.1" data-path="廣義估計方程式-generalized-estimating-equation.html"><a href="廣義估計方程式-generalized-estimating-equation.html#practical-08-hier"><i class="fa fa-check"></i><b>79.1</b> Practical 08-Hier</a></li>
</ul></li>
<li class="chapter" data-level="80" data-path="cluster-ana.html"><a href="cluster-ana.html"><i class="fa fa-check"></i><b>80</b> 聚類分析 Cluster analysis/unsupervised learning</a>
<ul>
<li class="chapter" data-level="80.1" data-path="cluster-ana.html"><a href="cluster-ana.html#聚類分析過程"><i class="fa fa-check"></i><b>80.1</b> 聚類分析過程</a>
<ul>
<li class="chapter" data-level="80.1.1" data-path="cluster-ana.html"><a href="cluster-ana.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>80.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="80.1.2" data-path="cluster-ana.html"><a href="cluster-ana.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>80.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="80.1.3" data-path="cluster-ana.html"><a href="cluster-ana.html#定義分類方法"><i class="fa fa-check"></i><b>80.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="PCA.html"><a href="PCA.html"><i class="fa fa-check"></i><b>81</b> 主成分分析 Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="81.1" data-path="PCA.html"><a href="PCA.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>81.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="81.2" data-path="PCA.html"><a href="PCA.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>81.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="81.3" data-path="PCA.html"><a href="PCA.html#數學推導"><i class="fa fa-check"></i><b>81.3</b> 數學推導</a>
<ul>
<li class="chapter" data-level="81.3.1" data-path="PCA.html"><a href="PCA.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>81.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="PCA.html"><a href="PCA.html#主成分分析數據實例"><i class="fa fa-check"></i><b>81.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="81.5" data-path="PCA.html"><a href="PCA.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>81.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a>
<ul>
<li class="chapter" data-level="81.5.1" data-path="PCA.html"><a href="PCA.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>81.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="81.6" data-path="PCA.html"><a href="PCA.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>81.6</b> Cluster analysis/PCA practical</a>
<ul>
<li class="chapter" data-level="81.6.1" data-path="PCA.html"><a href="PCA.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>81.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="82" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html"><i class="fa fa-check"></i><b>82</b> 缺失數據 Missing data 1</a>
<ul>
<li class="chapter" data-level="82.1" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#處理原則建議recommended-principles"><i class="fa fa-check"></i><b>82.1</b> 處理原則（建議）recommended principles</a></li>
<li class="chapter" data-level="82.2" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#缺失數據機制-missingness-mechanisms"><i class="fa fa-check"></i><b>82.2</b> 缺失數據機制 missingness mechanisms</a></li>
<li class="chapter" data-level="82.3" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#臨時解決方案-ad-hoc-approaches"><i class="fa fa-check"></i><b>82.3</b> 臨時解決方案 ad-hoc approaches</a></li>
<li class="chapter" data-level="82.4" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#單一變量的參數多重插補法-parametric-multiple-imputation-of-one-variable"><i class="fa fa-check"></i><b>82.4</b> 單一變量的參數多重插補法 parametric multiple imputation of one variable</a></li>
<li class="chapter" data-level="82.5" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#變量選擇插補次數模型檢查"><i class="fa fa-check"></i><b>82.5</b> 變量選擇，插補次數，模型檢查</a></li>
<li class="chapter" data-level="82.6" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#總結"><i class="fa fa-check"></i><b>82.6</b> 總結</a></li>
<li class="chapter" data-level="82.7" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#practical-10-hier"><i class="fa fa-check"></i><b>82.7</b> Practical 10-Hier</a>
<ul>
<li class="chapter" data-level="82.7.1" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#數據缺失產生的影響缺失機制和多重插補法"><i class="fa fa-check"></i><b>82.7.1</b> 數據缺失產生的影響，缺失機制，和多重插補法</a></li>
<li class="chapter" data-level="82.7.2" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#二進制變量的缺失-class-size-study"><i class="fa fa-check"></i><b>82.7.2</b> 二進制變量的缺失 “class size study”</a></li>
<li class="chapter" data-level="82.7.3" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#完整數據分析結果"><i class="fa fa-check"></i><b>82.7.3</b> 完整數據分析結果</a></li>
<li class="chapter" data-level="82.7.4" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#去除了缺失值的分析結果-complete-case-analysis"><i class="fa fa-check"></i><b>82.7.4</b> 去除了缺失值的分析結果 complete case analysis</a></li>
<li class="chapter" data-level="82.7.5" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#分析-sen_m-的缺失值機制"><i class="fa fa-check"></i><b>82.7.5</b> 分析 <code>sen_m</code> 的缺失值機制</a></li>
<li class="chapter" data-level="82.7.6" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#多重插補-multiple-imputation"><i class="fa fa-check"></i><b>82.7.6</b> 多重插補 multiple imputation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="83" data-path="缺失數據-missing-data-2.html"><a href="缺失數據-missing-data-2.html"><i class="fa fa-check"></i><b>83</b> 缺失數據 Missing data 2</a></li>
<li class="chapter" data-level="84" data-path="further-issues.html"><a href="further-issues.html"><i class="fa fa-check"></i><b>84</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="85" data-path="surv-intro.html"><a href="surv-intro.html"><i class="fa fa-check"></i><b>85</b> 生存分析入門</a>
<ul>
<li class="chapter" data-level="85.1" data-path="surv-intro.html"><a href="surv-intro.html#本章概要"><i class="fa fa-check"></i><b>85.1</b> 本章概要</a></li>
<li class="chapter" data-level="85.2" data-path="surv-intro.html"><a href="surv-intro.html#什麼是生存分析-what-is-survival-analysis"><i class="fa fa-check"></i><b>85.2</b> 什麼是生存分析 What is survival analysis?</a></li>
<li class="chapter" data-level="85.3" data-path="surv-intro.html"><a href="surv-intro.html#生存數據在哪裏"><i class="fa fa-check"></i><b>85.3</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="85.4" data-path="surv-intro.html"><a href="surv-intro.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>85.4</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="85.5" data-path="surv-intro.html"><a href="surv-intro.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>85.5</b> 生存數據的左右截尾</a>
<ul>
<li class="chapter" data-level="85.5.1" data-path="surv-intro.html"><a href="surv-intro.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>85.5.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="85.6" data-path="surv-intro.html"><a href="surv-intro.html#初步分析生存數據"><i class="fa fa-check"></i><b>85.6</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="85.7" data-path="surv-intro.html"><a href="surv-intro.html#初步描述生存數據"><i class="fa fa-check"></i><b>85.7</b> 初步描述生存數據</a>
<ul>
<li class="chapter" data-level="85.7.1" data-path="surv-intro.html"><a href="surv-intro.html#生存方程"><i class="fa fa-check"></i><b>85.7.1</b> 生存方程</a></li>
<li class="chapter" data-level="85.7.2" data-path="surv-intro.html"><a href="surv-intro.html#風險度方程"><i class="fa fa-check"></i><b>85.7.2</b> 風險度方程</a></li>
<li class="chapter" data-level="85.7.3" data-path="surv-intro.html"><a href="surv-intro.html#概率密度方程"><i class="fa fa-check"></i><b>85.7.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="85.7.4" data-path="surv-intro.html"><a href="surv-intro.html#各方程之間的關系"><i class="fa fa-check"></i><b>85.7.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="85.8" data-path="surv-intro.html"><a href="surv-intro.html#生存時間的參數分布"><i class="fa fa-check"></i><b>85.8</b> 生存時間的參數分布</a>
<ul>
<li class="chapter" data-level="85.8.1" data-path="surv-intro.html"><a href="surv-intro.html#exponentialdist"><i class="fa fa-check"></i><b>85.8.1</b> 指數分布</a></li>
<li class="chapter" data-level="85.8.2" data-path="surv-intro.html"><a href="surv-intro.html#weibulldist"><i class="fa fa-check"></i><b>85.8.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="85.9" data-path="surv-intro.html"><a href="surv-intro.html#極大似然法估計"><i class="fa fa-check"></i><b>85.9</b> 極大似然法估計</a></li>
<li class="chapter" data-level="85.10" data-path="surv-intro.html"><a href="surv-intro.html#practical-survival-01"><i class="fa fa-check"></i><b>85.10</b> Practical Survival 01</a>
<ul>
<li class="chapter" data-level="85.10.1" data-path="surv-intro.html"><a href="surv-intro.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>85.10.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="85.10.2" data-path="surv-intro.html"><a href="surv-intro.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>85.10.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="85.10.3" data-path="surv-intro.html"><a href="surv-intro.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>85.10.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="85.10.4" data-path="surv-intro.html"><a href="surv-intro.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>85.10.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="nonparametric.html"><a href="nonparametric.html"><i class="fa fa-check"></i><b>86</b> 非參數法分析生存數據</a>
<ul>
<li class="chapter" data-level="86.1" data-path="nonparametric.html"><a href="nonparametric.html#本章概要-1"><i class="fa fa-check"></i><b>86.1</b> 本章概要</a></li>
<li class="chapter" data-level="86.2" data-path="nonparametric.html"><a href="nonparametric.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>86.2</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="86.3" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>86.3</b> Kaplan-Meier 法分析生存方程</a>
<ul>
<li class="chapter" data-level="86.3.1" data-path="nonparametric.html"><a href="nonparametric.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>86.3.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="86.3.2" data-path="nonparametric.html"><a href="nonparametric.html#當數據中有刪失值"><i class="fa fa-check"></i><b>86.3.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="86.4" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-數據的信賴區間的估計"><i class="fa fa-check"></i><b>86.4</b> Kaplan-Meier 數據的信賴區間的估計</a></li>
<li class="chapter" data-level="86.5" data-path="nonparametric.html"><a href="nonparametric.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>86.5</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="86.6" data-path="nonparametric.html"><a href="nonparametric.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>86.6</b> 兩組之間生存概率的比較</a>
<ul>
<li class="chapter" data-level="86.6.1" data-path="nonparametric.html"><a href="nonparametric.html#the-log-rank-test"><i class="fa fa-check"></i><b>86.6.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="86.7" data-path="nonparametric.html"><a href="nonparametric.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>86.7</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="86.8" data-path="nonparametric.html"><a href="nonparametric.html#關於非參數分析法的一些延伸"><i class="fa fa-check"></i><b>86.8</b> 關於非參數分析法的一些延伸</a></li>
<li class="chapter" data-level="86.9" data-path="nonparametric.html"><a href="nonparametric.html#practical-survival-02"><i class="fa fa-check"></i><b>86.9</b> Practical Survival 02</a>
<ul>
<li class="chapter" data-level="86.9.1" data-path="nonparametric.html"><a href="nonparametric.html#part-1-pbc-數據"><i class="fa fa-check"></i><b>86.9.1</b> Part 1: PBC 數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="87" data-path="surv-reg.html"><a href="surv-reg.html"><i class="fa fa-check"></i><b>87</b> 生存數據中的回歸模型</a>
<ul>
<li class="chapter" data-level="87.1" data-path="surv-reg.html"><a href="surv-reg.html#本章概要-2"><i class="fa fa-check"></i><b>87.1</b> 本章概要</a></li>
<li class="chapter" data-level="87.2" data-path="surv-reg.html"><a href="surv-reg.html#使用參數模型分析生存數據的目的"><i class="fa fa-check"></i><b>87.2</b> 使用參數模型分析生存數據的目的</a></li>
<li class="chapter" data-level="87.3" data-path="surv-reg.html"><a href="surv-reg.html#生存數據的似然方程"><i class="fa fa-check"></i><b>87.3</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="87.4" data-path="surv-reg.html"><a href="surv-reg.html#如何加入解釋變量"><i class="fa fa-check"></i><b>87.4</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="87.5" data-path="surv-reg.html"><a href="surv-reg.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>87.5</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="87.6" data-path="surv-reg.html"><a href="surv-reg.html#weibull-分布"><i class="fa fa-check"></i><b>87.6</b> Weibull 分布</a></li>
<li class="chapter" data-level="87.7" data-path="surv-reg.html"><a href="surv-reg.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>87.7</b> Weibull 和 指數模型的比較</a>
<ul>
<li class="chapter" data-level="87.7.1" data-path="surv-reg.html"><a href="surv-reg.html#繪圖法"><i class="fa fa-check"></i><b>87.7.1</b> 繪圖法</a></li>
<li class="chapter" data-level="87.7.2" data-path="surv-reg.html"><a href="surv-reg.html#統計檢驗法"><i class="fa fa-check"></i><b>87.7.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="87.8" data-path="surv-reg.html"><a href="surv-reg.html#拓展解釋變量類型與個數的參數模型"><i class="fa fa-check"></i><b>87.8</b> 拓展解釋變量（類型與個數）的參數模型</a>
<ul>
<li class="chapter" data-level="87.8.1" data-path="surv-reg.html"><a href="surv-reg.html#當變量是連續型時"><i class="fa fa-check"></i><b>87.8.1</b> 當變量是連續型時</a></li>
<li class="chapter" data-level="87.8.2" data-path="surv-reg.html"><a href="surv-reg.html#多於兩種類型的分類型變量"><i class="fa fa-check"></i><b>87.8.2</b> （多於兩種類型的）分類型變量</a></li>
<li class="chapter" data-level="87.8.3" data-path="surv-reg.html"><a href="surv-reg.html#當你加入了多個解釋變量時"><i class="fa fa-check"></i><b>87.8.3</b> 當你加入了多個解釋變量時</a></li>
</ul></li>
<li class="chapter" data-level="87.9" data-path="surv-reg.html"><a href="surv-reg.html#practical-survival-03"><i class="fa fa-check"></i><b>87.9</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="cox.html"><a href="cox.html"><i class="fa fa-check"></i><b>88</b> Cox 比例風險模型</a>
<ul>
<li class="chapter" data-level="88.1" data-path="cox.html"><a href="cox.html#本章概要-3"><i class="fa fa-check"></i><b>88.1</b> 本章概要</a></li>
<li class="chapter" data-level="88.2" data-path="cox.html"><a href="cox.html#初步介紹-cox-比例風險模型"><i class="fa fa-check"></i><b>88.2</b> 初步介紹 Cox 比例風險模型</a></li>
<li class="chapter" data-level="88.3" data-path="cox.html"><a href="cox.html#偏似然法-partial-likelihood"><i class="fa fa-check"></i><b>88.3</b> 偏似然法 (partial likelihood)</a>
<ul>
<li class="chapter" data-level="88.3.1" data-path="cox.html"><a href="cox.html#爲什麼使用-cox-回歸模型"><i class="fa fa-check"></i><b>88.3.1</b> 爲什麼使用 Cox 回歸模型？</a></li>
</ul></li>
<li class="chapter" data-level="88.4" data-path="cox.html"><a href="cox.html#處理相等的生存時間-handling-tied-survival-times"><i class="fa fa-check"></i><b>88.4</b> 處理相等的生存時間 handling tied survival times</a></li>
<li class="chapter" data-level="88.5" data-path="cox.html"><a href="cox.html#估計生存曲線"><i class="fa fa-check"></i><b>88.5</b> 估計生存曲線</a></li>
<li class="chapter" data-level="88.6" data-path="cox.html"><a href="cox.html#cox回歸模型中包涵的假設"><i class="fa fa-check"></i><b>88.6</b> Cox回歸模型中包涵的假設：</a></li>
<li class="chapter" data-level="88.7" data-path="cox.html"><a href="cox.html#評估比例風險假設-assessing-the-proportional-hazard-assumption"><i class="fa fa-check"></i><b>88.7</b> 評估比例風險假設 assessing the proportional hazard assumption</a></li>
<li class="chapter" data-level="88.8" data-path="cox.html"><a href="cox.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>88.8</b> 該用半參數模型還是用全參數模型</a></li>
<li class="chapter" data-level="88.9" data-path="cox.html"><a href="cox.html#practical-survival-04"><i class="fa fa-check"></i><b>88.9</b> Practical Survival 04</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="surv-check.html"><a href="surv-check.html"><i class="fa fa-check"></i><b>89</b> 分析策略和模型檢查 Model checking-survival analysis</a>
<ul>
<li class="chapter" data-level="89.1" data-path="surv-check.html"><a href="surv-check.html#本章概要-4"><i class="fa fa-check"></i><b>89.1</b> 本章概要</a></li>
<li class="chapter" data-level="89.2" data-path="surv-check.html"><a href="surv-check.html#生存分析策略"><i class="fa fa-check"></i><b>89.2</b> 生存分析策略</a>
<ul>
<li class="chapter" data-level="89.2.1" data-path="surv-check.html"><a href="surv-check.html#關於似然比檢驗-a-note-on-likelihood-ratio-tests"><i class="fa fa-check"></i><b>89.2.1</b> 關於似然比檢驗 A note on likelihood ratio tests</a></li>
</ul></li>
<li class="chapter" data-level="89.3" data-path="surv-check.html"><a href="surv-check.html#針對不同的研究設計不同的分析策略"><i class="fa fa-check"></i><b>89.3</b> 針對不同的研究設計不同的分析策略</a>
<ul>
<li class="chapter" data-level="89.3.1" data-path="surv-check.html"><a href="surv-check.html#針對隨機對照臨牀試驗-rct"><i class="fa fa-check"></i><b>89.3.1</b> 針對隨機對照臨牀試驗 RCT</a></li>
<li class="chapter" data-level="89.3.2" data-path="surv-check.html"><a href="surv-check.html#針對觀察型研究-observational-studies"><i class="fa fa-check"></i><b>89.3.2</b> 針對觀察型研究 observational studies</a></li>
</ul></li>
<li class="chapter" data-level="89.4" data-path="surv-check.html"><a href="surv-check.html#模型檢查的要點"><i class="fa fa-check"></i><b>89.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="89.5" data-path="surv-check.html"><a href="surv-check.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>89.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a>
<ul>
<li class="chapter" data-level="89.5.1" data-path="surv-check.html"><a href="surv-check.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>89.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="89.5.2" data-path="surv-check.html"><a href="surv-check.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>89.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="89.6" data-path="surv-check.html"><a href="surv-check.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>89.6</b> 評價模型擬合的其他有趣方法</a>
<ul>
<li class="chapter" data-level="89.6.1" data-path="surv-check.html"><a href="surv-check.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>89.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="89.6.2" data-path="surv-check.html"><a href="surv-check.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>89.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
<li class="chapter" data-level="89.7" data-path="surv-check.html"><a href="surv-check.html#practical-survival-05"><i class="fa fa-check"></i><b>89.7</b> Practical Survival 05</a>
<ul>
<li class="chapter" data-level="89.7.1" data-path="surv-check.html"><a href="surv-check.html#把數據讀入你最喜歡的-r-的環境中先考慮一個二進制變量-cir0-對生存的影響在建立的模型中加入該-cir0-變量和時間的交互作用項在-r-裏需要用到-tt-命令"><i class="fa fa-check"></i><b>89.7.1</b> 把數據讀入你最喜歡的 R 的環境中，先考慮一個二進制變量 <code>cir0</code> 對生存的影響。在建立的模型中加入該 <code>cir0</code> 變量和時間的交互作用項。在 R 裏需要用到 <code>tt()</code> 命令。</a></li>
<li class="chapter" data-level="89.7.2" data-path="surv-check.html"><a href="surv-check.html#繪製模型中只有-cir0-一個變量的情況下調整後的-scaled-schoenfeld-殘差圖"><i class="fa fa-check"></i><b>89.7.2</b> 繪製模型中只有 <code>cir0</code> 一個變量的情況下，調整後的 scaled Schoenfeld 殘差圖。</a></li>
<li class="chapter" data-level="89.7.3" data-path="surv-check.html"><a href="surv-check.html#另外一種探索變量-cir0-的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段分別估計每個時間段內該暴露變量的風險度比"><i class="fa fa-check"></i><b>89.7.3</b> 另外一種探索變量 <code>cir0</code> 的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段，分別估計每個時間段內該暴露變量的風險度比。</a></li>
<li class="chapter" data-level="89.7.4" data-path="surv-check.html"><a href="surv-check.html#接下來我們來看該數據集中的一個連續型變量-bil0-我們練習使用-martingale-殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式"><i class="fa fa-check"></i><b>89.7.4</b> 接下來我們來看該數據集中的一個連續型變量， <code>bil0</code> 。我們練習使用 Martingale 殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式。</a></li>
<li class="chapter" data-level="89.7.5" data-path="surv-check.html"><a href="surv-check.html#選擇你認爲應該對-bil0-進行的數學函數形式使用-scaled-schoenfeld-殘差檢查它是否違反比例風險假設"><i class="fa fa-check"></i><b>89.7.5</b> 選擇你認爲應該對 <code>bil0</code> 進行的數學函數形式，使用 Scaled Schoenfeld 殘差檢查它是否違反比例風險假設。</a></li>
<li class="chapter" data-level="89.7.6" data-path="surv-check.html"><a href="surv-check.html#建立一個含有如下解釋變量的-cox-比例風險回歸模型轉換過後的bil0-cir0cenc0-age"><i class="fa fa-check"></i><b>89.7.6</b> 建立一個含有如下解釋變量的 Cox 比例風險回歸模型：轉換過後的<code>bil0</code>, <code>cir0</code>，<code>cenc0</code>, <code>Age</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="90" data-path="competing-risk.html"><a href="competing-risk.html"><i class="fa fa-check"></i><b>90</b> 競爭風險模型 competing risk</a>
<ul>
<li class="chapter" data-level="90.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazard"><i class="fa fa-check"></i><b>90.1</b> Cause-specific hazard</a>
<ul>
<li class="chapter" data-level="90.1.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>90.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="90.2" data-path="competing-risk.html"><a href="competing-risk.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>90.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="90.3" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>90.3</b> Subdistribution hazard - Fine and Gray model</a>
<ul>
<li class="chapter" data-level="90.3.1" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>90.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="90.4" data-path="competing-risk.html"><a href="competing-risk.html#multi-state-models"><i class="fa fa-check"></i><b>90.4</b> Multi-state models</a>
<ul>
<li class="chapter" data-level="90.4.1" data-path="competing-risk.html"><a href="competing-risk.html#the-markov-model"><i class="fa fa-check"></i><b>90.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="90.4.2" data-path="competing-risk.html"><a href="competing-risk.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>90.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
<li class="chapter" data-level="90.5" data-path="competing-risk.html"><a href="competing-risk.html#practical-survival-06"><i class="fa fa-check"></i><b>90.5</b> Practical Survival 06</a></li>
</ul></li>
<li class="chapter" data-level="91" data-path="other-surv.html"><a href="other-surv.html"><i class="fa fa-check"></i><b>91</b> 生存分析的其他手段</a>
<ul>
<li class="chapter" data-level="91.1" data-path="other-surv.html"><a href="other-surv.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>91.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="91.2" data-path="other-surv.html"><a href="other-surv.html#加速失效死亡模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>91.2</b> 加速失效(死亡)模型 Accelerated failure time (AFT) model</a>
<ul>
<li class="chapter" data-level="91.2.1" data-path="other-surv.html"><a href="other-surv.html#詳細推導"><i class="fa fa-check"></i><b>91.2.1</b> 詳細推導</a></li>
<li class="chapter" data-level="91.2.2" data-path="other-surv.html"><a href="other-surv.html#再詳細推導"><i class="fa fa-check"></i><b>91.2.2</b> 再詳細推導</a></li>
<li class="chapter" data-level="91.2.3" data-path="other-surv.html"><a href="other-surv.html#風險比例模型ph和加速失效死亡模型aft的比較"><i class="fa fa-check"></i><b>91.2.3</b> 風險比例模型(PH)和加速失效（死亡）模型(AFT)的比較</a></li>
<li class="chapter" data-level="91.2.4" data-path="other-surv.html"><a href="other-surv.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>91.2.4</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
<li class="chapter" data-level="91.3" data-path="other-surv.html"><a href="other-surv.html#practical-survival-07"><i class="fa fa-check"></i><b>91.3</b> Practical Survival 07</a></li>
</ul></li>
<li class="chapter" data-level="92" data-path="time-dep.html"><a href="time-dep.html"><i class="fa fa-check"></i><b>92</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a>
<ul>
<li class="chapter" data-level="92.1" data-path="time-dep.html"><a href="time-dep.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>92.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="92.2" data-path="time-dep.html"><a href="time-dep.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>92.2</b> Extended Cox model 把Cox模型擴展開去</a></li>
<li class="chapter" data-level="92.3" data-path="time-dep.html"><a href="time-dep.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>92.3</b> 時間依存變量數據的結構</a>
<ul>
<li class="chapter" data-level="92.3.1" data-path="time-dep.html"><a href="time-dep.html#值得注意的點"><i class="fa fa-check"></i><b>92.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="time-dep.html"><a href="time-dep.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>92.4</b> Frailty Models (脆弱模型?)</a>
<ul>
<li class="chapter" data-level="92.4.1" data-path="time-dep.html"><a href="time-dep.html#individual-frailty-model"><i class="fa fa-check"></i><b>92.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="92.4.2" data-path="time-dep.html"><a href="time-dep.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>92.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="92.4.3" data-path="time-dep.html"><a href="time-dep.html#shared-frailty-model"><i class="fa fa-check"></i><b>92.4.3</b> Shared frailty model</a></li>
</ul></li>
<li class="chapter" data-level="92.5" data-path="time-dep.html"><a href="time-dep.html#practical-survival-08"><i class="fa fa-check"></i><b>92.5</b> Practical Survival 08</a>
<ul>
<li class="chapter" data-level="92.5.1" data-path="time-dep.html"><a href="time-dep.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>92.5.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="92.5.2" data-path="time-dep.html"><a href="time-dep.html#解答"><i class="fa fa-check"></i><b>92.5.2</b> 解答</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="93" data-path="surv-advance.html"><a href="surv-advance.html"><i class="fa fa-check"></i><b>93</b> 時間事件數據的高級分析法</a></li>
<li class="chapter" data-level="94" data-path="bayes-surv.html"><a href="bayes-surv.html"><i class="fa fa-check"></i><b>94</b> 貝葉斯生存分析 Bayesian Survival Analysis</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="95" data-path="why-bayes.html"><a href="why-bayes.html"><i class="fa fa-check"></i><b>95</b> 爲什麼我們要用貝葉斯統計學方法？</a>
<ul>
<li class="chapter" data-level="95.1" data-path="why-bayes.html"><a href="why-bayes.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>95.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a>
<ul>
<li class="chapter" data-level="95.1.1" data-path="why-bayes.html"><a href="why-bayes.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>95.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="95.1.2" data-path="why-bayes.html"><a href="why-bayes.html#概率論者分析結果"><i class="fa fa-check"></i><b>95.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="95.1.3" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>95.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="95.2" data-path="why-bayes.html"><a href="why-bayes.html#example-the-great-trial"><i class="fa fa-check"></i><b>95.2</b> Example: The GREAT trial</a>
<ul>
<li class="chapter" data-level="95.2.1" data-path="why-bayes.html"><a href="why-bayes.html#background-great-trial"><i class="fa fa-check"></i><b>95.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="95.2.2" data-path="why-bayes.html"><a href="why-bayes.html#試驗結果"><i class="fa fa-check"></i><b>95.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="95.2.3" data-path="why-bayes.html"><a href="why-bayes.html#經典統計學分析方法"><i class="fa fa-check"></i><b>95.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="95.2.4" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>95.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="96" data-path="MC-estimation.html"><a href="MC-estimation.html"><i class="fa fa-check"></i><b>96</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a>
<ul>
<li class="chapter" data-level="96.1" data-path="MC-estimation.html"><a href="MC-estimation.html#起源"><i class="fa fa-check"></i><b>96.1</b> 起源</a></li>
<li class="chapter" data-level="96.2" data-path="MC-estimation.html"><a href="MC-estimation.html#百分比的統計學推斷-inference-on-proportions"><i class="fa fa-check"></i><b>96.2</b> 百分比的統計學推斷 inference on proportions</a>
<ul>
<li class="chapter" data-level="96.2.1" data-path="MC-estimation.html"><a href="MC-estimation.html#example-new-drug"><i class="fa fa-check"></i><b>96.2.1</b> Example: New Drug</a></li>
<li class="chapter" data-level="96.2.2" data-path="MC-estimation.html"><a href="MC-estimation.html#beta-distr"><i class="fa fa-check"></i><b>96.2.2</b> Beta 分布</a></li>
<li class="chapter" data-level="96.2.3" data-path="MC-estimation.html"><a href="MC-estimation.html#作出預測"><i class="fa fa-check"></i><b>96.2.3</b> 作出預測</a></li>
<li class="chapter" data-level="96.2.4" data-path="MC-estimation.html"><a href="MC-estimation.html#example-新藥表現預測"><i class="fa fa-check"></i><b>96.2.4</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="96.3" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>96.3</b> 蒙特卡羅估計</a>
<ul>
<li class="chapter" data-level="96.3.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>96.3.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="96.3.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>96.3.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="96.4" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅法分析軟件-openbugs-jags"><i class="fa fa-check"></i><b>96.4</b> 蒙特卡羅法分析軟件 OpenBUGS / JAGS</a>
<ul>
<li class="chapter" data-level="96.4.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jagsbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>96.4.1</b> 用 JAGS/BUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="96.4.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jags-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>96.4.2</b> 用 JAGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="96.4.3" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>96.4.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="96.5" data-path="MC-estimation.html"><a href="MC-estimation.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>96.5</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="97" data-path="conjugate-priors.html"><a href="conjugate-priors.html"><i class="fa fa-check"></i><b>97</b> 共軛先驗概率 Conjugate priors</a>
<ul>
<li class="chapter" data-level="97.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>97.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="97.2" data-path="conjugate-priors.html"><a href="conjugate-priors.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.2</b> 二項分布(似然)數據的共軛先驗概率</a>
<ul>
<li class="chapter" data-level="97.2.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#事後概率分布預測"><i class="fa fa-check"></i><b>97.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="97.3" data-path="conjugate-priors.html"><a href="conjugate-priors.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="97.4" data-path="conjugate-priors.html"><a href="conjugate-priors.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="97.5" data-path="conjugate-priors.html"><a href="conjugate-priors.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>97.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="97.6" data-path="conjugate-priors.html"><a href="conjugate-priors.html#BayesPrac03"><i class="fa fa-check"></i><b>97.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="98" data-path="MCMC-methods.html"><a href="MCMC-methods.html"><i class="fa fa-check"></i><b>98</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a>
<ul>
<li class="chapter" data-level="98.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>98.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a>
<ul>
<li class="chapter" data-level="98.1.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>98.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="98.1.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#Gibbs-sampling"><i class="fa fa-check"></i><b>98.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="98.1.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#初始值-initial-values"><i class="fa fa-check"></i><b>98.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="98.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>98.2</b> 使用 MCMC 時需要考慮的一些問題</a>
<ul>
<li class="chapter" data-level="98.2.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#收斂時間"><i class="fa fa-check"></i><b>98.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="98.2.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>98.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="98.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-軟件"><i class="fa fa-check"></i><b>98.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="98.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>98.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a>
<ul>
<li class="chapter" data-level="98.4.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>98.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="98.5" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-language"><i class="fa fa-check"></i><b>98.5</b> BUGS language</a>
<ul>
<li class="chapter" data-level="98.5.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>98.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="98.5.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#分布的標記法"><i class="fa fa-check"></i><b>98.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="98.5.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#arrays-and-loops"><i class="fa fa-check"></i><b>98.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="98.5.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#常用的方程"><i class="fa fa-check"></i><b>98.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="98.6" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>98.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="98.7" data-path="MCMC-methods.html"><a href="MCMC-methods.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>98.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="99" data-path="Bayes-check.html"><a href="Bayes-check.html"><i class="fa fa-check"></i><b>99</b> 建模和模型的檢查</a>
<ul>
<li class="chapter" data-level="99.1" data-path="Bayes-check.html"><a href="Bayes-check.html#BayesianLM"><i class="fa fa-check"></i><b>99.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="99.2" data-path="Bayes-check.html"><a href="Bayes-check.html#children-in-the-gambia"><i class="fa fa-check"></i><b>99.2</b> Children in the Gambia</a>
<ul>
<li class="chapter" data-level="99.2.1" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>99.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="99.2.2" data-path="Bayes-check.html"><a href="Bayes-check.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>99.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="99.2.3" data-path="Bayes-check.html"><a href="Bayes-check.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>99.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="99.2.4" data-path="Bayes-check.html"><a href="Bayes-check.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>99.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="99.2.5" data-path="Bayes-check.html"><a href="Bayes-check.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>99.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="99.2.6" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>99.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="99.2.7" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>99.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="99.2.8" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>99.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="99.2.9" data-path="Bayes-check.html"><a href="Bayes-check.html#tdreplacegaussian"><i class="fa fa-check"></i><b>99.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="99.3" data-path="Bayes-check.html"><a href="Bayes-check.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>99.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a>
<ul>
<li class="chapter" data-level="99.3.1" data-path="Bayes-check.html"><a href="Bayes-check.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>99.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="99.3.2" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>99.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="99.4" data-path="Bayes-check.html"><a href="Bayes-check.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>99.4</b> Practical Bayesian Statistics 05</a>
<ul>
<li class="chapter" data-level="99.4.1" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>99.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="99.4.2" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>99.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="100" data-path="Bayes-design.html"><a href="Bayes-design.html"><i class="fa fa-check"></i><b>100</b> 不同實驗/研究設計時適用的貝葉斯模型</a>
<ul>
<li class="chapter" data-level="100.1" data-path="Bayes-design.html"><a href="Bayes-design.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>100.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.2" data-path="Bayes-design.html"><a href="Bayes-design.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>100.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.3" data-path="Bayes-design.html"><a href="Bayes-design.html#bayes-crosssectional"><i class="fa fa-check"></i><b>100.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.4" data-path="Bayes-design.html"><a href="Bayes-design.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>100.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a>
<ul>
<li class="chapter" data-level="100.4.1" data-path="Bayes-design.html"><a href="Bayes-design.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>100.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="100.5" data-path="Bayes-design.html"><a href="Bayes-design.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>100.5</b> Practical Bayesian Statistics 06</a>
<ul>
<li class="chapter" data-level="100.5.1" data-path="Bayes-design.html"><a href="Bayes-design.html#the-great-trial"><i class="fa fa-check"></i><b>100.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="100.5.2" data-path="Bayes-design.html"><a href="Bayes-design.html#吸煙與癌症"><i class="fa fa-check"></i><b>100.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="101" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html"><i class="fa fa-check"></i><b>101</b> 貝葉斯廣義線性回歸</a>
<ul>
<li class="chapter" data-level="101.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>101.1</b> 如何在BUGS語言中描述分類型變量</a>
<ul>
<li class="chapter" data-level="101.1.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>101.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="101.1.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>101.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="101.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>101.2</b> 邏輯回歸 Bayesian Logistic Regression</a>
<ul>
<li class="chapter" data-level="101.2.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#低出生體重數據-1"><i class="fa fa-check"></i><b>101.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="101.3" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>101.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="101.4" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>101.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="101.5" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#Bayesian-practical07"><i class="fa fa-check"></i><b>101.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="102" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html"><i class="fa fa-check"></i><b>102</b> 貝葉斯等級回歸模型</a>
<ul>
<li class="chapter" data-level="102.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>102.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="102.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>102.2</b> 多層數據在模型中可能要用到的前提條件</a>
<ul>
<li class="chapter" data-level="102.2.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>102.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="102.2.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>102.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="102.2.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>102.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="102.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>102.3</b> 抗抑鬱臨牀試驗實例</a>
<ul>
<li class="chapter" data-level="102.3.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#縱向數據"><i class="fa fa-check"></i><b>102.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="102.3.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-example"><i class="fa fa-check"></i><b>102.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="102.3.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>102.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="102.3.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>102.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="102.3.5" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>102.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="102.3.6" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>102.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="102.3.7" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>102.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="102.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>102.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="103" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html"><i class="fa fa-check"></i><b>103</b> 再訪 MCMC</a>
<ul>
<li class="chapter" data-level="103.1" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>103.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="103.2" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>103.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="104" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html"><i class="fa fa-check"></i><b>104</b> 貝葉斯和概率論的比較</a>
<ul>
<li class="chapter" data-level="104.1" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>104.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="104.2" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>104.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="104.3" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>104.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 非參數貝葉斯統計 Bayesian Nonparametric Data Analysis</b></span></li>
<li class="chapter" data-level="105" data-path="nonparaBayes-intro.html"><a href="nonparaBayes-intro.html"><i class="fa fa-check"></i><b>105</b> 非參貝葉斯入門</a></li>
<li class="chapter" data-level="106" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><i class="fa fa-check"></i><b>106</b> 密度估計 Density estimation - 狄雷克雷過程模型 DP models</a>
<ul>
<li class="chapter" data-level="106.1" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#狄雷克雷過程-dirichlet-process"><i class="fa fa-check"></i><b>106.1</b> 狄雷克雷過程 Dirichlet process</a>
<ul>
<li class="chapter" data-level="106.1.1" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#定義-definition"><i class="fa fa-check"></i><b>106.1.1</b> 定義 definition</a></li>
<li class="chapter" data-level="106.1.2" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#推導"><i class="fa fa-check"></i><b>106.1.2</b> 推導</a></li>
<li class="chapter" data-level="106.1.3" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#事後概率分佈和邊際分佈"><i class="fa fa-check"></i><b>106.1.3</b> 事後概率分佈和邊際分佈</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XIII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="107" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html"><i class="fa fa-check"></i><b>107</b> Causal Languages 因果推斷的語法</a>
<ul>
<li class="chapter" data-level="107.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>107.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="107.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>107.2</b> 傳統的統計學方法</a>
<ul>
<li class="chapter" data-level="107.2.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#初步分析"><i class="fa fa-check"></i><b>107.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="107.2.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#混雜"><i class="fa fa-check"></i><b>107.2.2</b> 混雜</a></li>
<li class="chapter" data-level="107.2.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>107.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="107.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>107.3</b> 更加正規的方法</a>
<ul>
<li class="chapter" data-level="107.3.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>107.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="107.3.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>107.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="107.3.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>107.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="107.3.4" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>107.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="108" data-path="graphical-models.html"><a href="graphical-models.html"><i class="fa fa-check"></i><b>108</b> Graphical Models 因果推斷的圖形模型</a>
<ul>
<li class="chapter" data-level="108.1" data-path="graphical-models.html"><a href="graphical-models.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>108.1</b> 統計學中的有向無環圖</a>
<ul>
<li class="chapter" data-level="108.1.1" data-path="graphical-models.html"><a href="graphical-models.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>108.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="108.1.2" data-path="graphical-models.html"><a href="graphical-models.html#dag-圖的術語"><i class="fa fa-check"></i><b>108.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="108.1.3" data-path="graphical-models.html"><a href="graphical-models.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>108.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="108.1.4" data-path="graphical-models.html"><a href="graphical-models.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>108.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="108.2" data-path="graphical-models.html"><a href="graphical-models.html#以非對撞爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>108.2</b> 以非對撞爲條件 conditioning on a non-collider</a>
<ul>
<li class="chapter" data-level="108.2.1" data-path="graphical-models.html"><a href="graphical-models.html#條件的總結"><i class="fa fa-check"></i><b>108.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="108.2.2" data-path="graphical-models.html"><a href="graphical-models.html#d-分離-d-separation"><i class="fa fa-check"></i><b>108.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="109" data-path="reg-cont.html"><a href="reg-cont.html"><i class="fa fa-check"></i><b>109</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a>
<ul>
<li class="chapter" data-level="109.1" data-path="reg-cont.html"><a href="reg-cont.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>109.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="109.2" data-path="reg-cont.html"><a href="reg-cont.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>109.2</b> 鑑定 identification - revision</a>
<ul>
<li class="chapter" data-level="109.2.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>109.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="109.2.2" data-path="reg-cont.html"><a href="reg-cont.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>109.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="109.2.3" data-path="reg-cont.html"><a href="reg-cont.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>109.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="109.3" data-path="reg-cont.html"><a href="reg-cont.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>109.3</b> 通過線性回歸模型來估計 ACE</a>
<ul>
<li class="chapter" data-level="109.3.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均值差"><i class="fa fa-check"></i><b>109.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="109.3.2" data-path="reg-cont.html"><a href="reg-cont.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>109.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="109.3.3" data-path="reg-cont.html"><a href="reg-cont.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>109.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="109.3.4" data-path="reg-cont.html"><a href="reg-cont.html#positivity-非零性"><i class="fa fa-check"></i><b>109.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="109.3.5" data-path="reg-cont.html"><a href="reg-cont.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>109.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="109.4" data-path="reg-cont.html"><a href="reg-cont.html#practical03---causal-inference"><i class="fa fa-check"></i><b>109.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="110" data-path="regre-binary.html"><a href="regre-binary.html"><i class="fa fa-check"></i><b>110</b> Regression Methods with binary outcomes 結果變量爲二進制變量</a>
<ul>
<li class="chapter" data-level="110.1" data-path="regre-binary.html"><a href="regre-binary.html#二進制結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>110.1</b> 二進制結果變量的因果被估計量 (causal estimand):</a>
<ul>
<li class="chapter" data-level="110.1.1" data-path="regre-binary.html"><a href="regre-binary.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>110.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="110.2" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>110.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="110.3" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>110.3</b> 鑑定 identification - marginal effects</a>
<ul>
<li class="chapter" data-level="110.3.1" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>110.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="110.3.2" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>110.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="110.4" data-path="regre-binary.html"><a href="regre-binary.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>110.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="110.5" data-path="regre-binary.html"><a href="regre-binary.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>110.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="110.6" data-path="regre-binary.html"><a href="regre-binary.html#practical04---causal-inference"><i class="fa fa-check"></i><b>110.6</b> Practical04 - causal inference</a>
<ul>
<li class="chapter" data-level="110.6.1" data-path="regre-binary.html"><a href="regre-binary.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>110.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="110.6.2" data-path="regre-binary.html"><a href="regre-binary.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>110.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="110.6.3" data-path="regre-binary.html"><a href="regre-binary.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>110.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="110.6.4" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>110.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="110.6.5" data-path="regre-binary.html"><a href="regre-binary.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>110.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="110.6.6" data-path="regre-binary.html"><a href="regre-binary.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>110.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="110.6.7" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>110.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="110.6.8" data-path="regre-binary.html"><a href="regre-binary.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>110.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="110.6.9" data-path="regre-binary.html"><a href="regre-binary.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>110.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="110.6.10" data-path="regre-binary.html"><a href="regre-binary.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>110.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="110.6.11" data-path="regre-binary.html"><a href="regre-binary.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>110.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="110.6.12" data-path="regre-binary.html"><a href="regre-binary.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>110.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="111" data-path="prop-score.html"><a href="prop-score.html"><i class="fa fa-check"></i><b>111</b> Prospensity Score 傾向性評分</a>
<ul>
<li class="chapter" data-level="111.1" data-path="prop-score.html"><a href="prop-score.html#practical05---causal-inference"><i class="fa fa-check"></i><b>111.1</b> Practical05 - causal inference</a>
<ul>
<li class="chapter" data-level="111.1.1" data-path="prop-score.html"><a href="prop-score.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>111.1.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="111.1.2" data-path="prop-score.html"><a href="prop-score.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>111.1.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="111.1.3" data-path="prop-score.html"><a href="prop-score.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>111.1.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="111.1.4" data-path="prop-score.html"><a href="prop-score.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>111.1.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="111.1.5" data-path="prop-score.html"><a href="prop-score.html#用配對法計算-ace"><i class="fa fa-check"></i><b>111.1.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="111.1.6" data-path="prop-score.html"><a href="prop-score.html#模型校正-ps"><i class="fa fa-check"></i><b>111.1.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="112" data-path="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><a href="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><i class="fa fa-check"></i><b>112</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="113" data-path="causal-mediation-analysis.html"><a href="causal-mediation-analysis.html"><i class="fa fa-check"></i><b>113</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIV 真實世界數據 Real World Data and Real World Evidence</b></span></li>
<li class="chapter" data-level="114" data-path="rationale-behind-and-challenges-to-health-data-analysis.html"><a href="rationale-behind-and-challenges-to-health-data-analysis.html"><i class="fa fa-check"></i><b>114</b> Rationale behind and challenges to health data analysis</a></li>
<li class="part"><span><b>XV 醫療技術評價之成本效益分析模型 Cost effectiveness modelling for health technology assessment</b></span></li>
<li class="chapter" data-level="115" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><i class="fa fa-check"></i><b>115</b> 簡介馬克夫成本效益模型 Introduction to Markov Cost Effectiveness Models</a>
<ul>
<li class="chapter" data-level="115.1" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#入門簡介"><i class="fa fa-check"></i><b>115.1</b> 入門簡介</a></li>
<li class="chapter" data-level="115.2" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#爲什麼要使用馬克夫模型-why-markov-models"><i class="fa fa-check"></i><b>115.2</b> 爲什麼要使用馬克夫模型 why Markov models?</a></li>
<li class="chapter" data-level="115.3" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#健康狀態-health-states"><i class="fa fa-check"></i><b>115.3</b> 健康狀態 health states</a></li>
</ul></li>
<li class="part"><span><b>XVI Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="116" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><i class="fa fa-check"></i><b>116</b> 粗率比和分層率比 Crude and stratified rate ratios</a>
<ul>
<li class="chapter" data-level="116.1" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q1-q3-讀取數據簡單歸納分割年齡計算年齡組的粗死亡率"><i class="fa fa-check"></i><b>116.1</b> Q1-Q3 讀取數據，簡單歸納，分割年齡，計算年齡組的粗死亡率</a></li>
<li class="chapter" data-level="116.2" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q4-計算不同年齡組相對於最年輕的年齡組的死亡率比-rate-ratio-rr"><i class="fa fa-check"></i><b>116.2</b> Q4 計算不同年齡組相對於最年輕的年齡組的死亡率比 Rate ratio, RR</a></li>
<li class="chapter" data-level="116.3" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q5-分析另一個關於職業等級-grade-和死亡之間的關係使用-stata-的-stmh-命令來計算並比較較低等級職業-low-grade-和較高等級職業-high-grade-相比死亡率比是多少你認爲結果是否提供強有力的證據證明這兩種職業等級之間的死亡率存在顯著差異"><i class="fa fa-check"></i><b>116.3</b> Q5 分析另一個關於職業等級 <code>grade</code> 和死亡之間的關係。使用 Stata 的 <code>stmh</code> 命令來計算並比較較低等級職業 (low grade) 和較高等級職業 (high grade) 相比，死亡率比是多少。你認爲結果是否提供強有力的證據證明這兩種職業等級之間的死亡率存在顯著差異？</a></li>
<li class="chapter" data-level="116.4" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q6-q8-試分析上一題中觀察到的職業等級和死亡率之間的關係是否受到年齡的影響先嘗試使用-stmh-by-函數來分析不同年齡層中職業等級之間的死亡率比是否有證據證明職業等級的高低和年齡之間在死亡率比的關係上存在交互作用又或者是否有年齡的混淆因素會對職業等級和死亡之間的關係造成影響"><i class="fa fa-check"></i><b>116.4</b> Q6-Q8 試分析上一題中觀察到的職業等級和死亡率之間的關係，是否受到年齡的影響。先嘗試使用 <code>stmh, by()</code> 函數來分析不同年齡層中職業等級之間的死亡率比。是否有證據證明職業等級的高低和年齡之間在死亡率比的關係上存在交互作用？又或者是否有年齡的混淆因素會對職業等級和死亡之間的關係造成影響？</a></li>
<li class="chapter" data-level="116.5" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q9-試分析職業等級和chd冠心病死亡之間的關係此時在stata需要重新修改你的觀察結果爲-chd職業等級和冠心病死亡之間的關係是否受到吸菸習慣的影響或者有交互作用呢"><i class="fa fa-check"></i><b>116.5</b> Q9 試分析職業等級和CHD，冠心病死亡之間的關係。此時在Stata需要重新修改你的觀察結果爲 <code>chd</code>。職業等級和冠心病死亡之間的關係是否受到吸菸習慣的影響，或者有交互作用呢？</a></li>
<li class="chapter" data-level="116.6" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#further-q1-請分析膽固醇水平和-冠心病死亡之間的關係這一關係是否受到年齡的混雜影響"><i class="fa fa-check"></i><b>116.6</b> Further Q1 請分析膽固醇水平和 冠心病死亡之間的關係。這一關係是否受到年齡的混雜影響？</a></li>
<li class="chapter" data-level="116.7" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#further-q2-你認爲當我們在分析膽固醇和冠心病死亡率之間的關係的時候需要考慮調整收縮期血壓嗎-systolic-blood-pressure如果你不同意爲什麼"><i class="fa fa-check"></i><b>116.7</b> Further Q2 你認爲，當我們在分析膽固醇和冠心病死亡率之間的關係的時候，需要考慮調整收縮期血壓嗎 (systolic blood pressure)？如果你不同意，爲什麼？</a></li>
</ul></li>
<li class="chapter" data-level="117" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><i class="fa fa-check"></i><b>117</b> 從流行病學的角度初步分析生存數據 introduction to survival analysis</a>
<ul>
<li class="chapter" data-level="117.1" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q1-5"><i class="fa fa-check"></i><b>117.1</b> Q1</a></li>
<li class="chapter" data-level="117.2" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q2-4"><i class="fa fa-check"></i><b>117.2</b> Q2</a></li>
<li class="chapter" data-level="117.3" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q3-3"><i class="fa fa-check"></i><b>117.3</b> Q3</a></li>
<li class="chapter" data-level="117.4" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q4-1"><i class="fa fa-check"></i><b>117.4</b> Q4</a></li>
<li class="chapter" data-level="117.5" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q5-1"><i class="fa fa-check"></i><b>117.5</b> Q5</a></li>
<li class="chapter" data-level="117.6" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q6-1"><i class="fa fa-check"></i><b>117.6</b> Q6</a></li>
<li class="chapter" data-level="117.7" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q7"><i class="fa fa-check"></i><b>117.7</b> Q7</a></li>
<li class="chapter" data-level="117.8" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q8"><i class="fa fa-check"></i><b>117.8</b> Q8</a></li>
<li class="chapter" data-level="117.9" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q9"><i class="fa fa-check"></i><b>117.9</b> Q9</a></li>
<li class="chapter" data-level="117.10" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q10"><i class="fa fa-check"></i><b>117.10</b> Q10</a></li>
<li class="chapter" data-level="117.11" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q11"><i class="fa fa-check"></i><b>117.11</b> Q11</a></li>
<li class="chapter" data-level="117.12" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q12-13"><i class="fa fa-check"></i><b>117.12</b> Q12-13</a></li>
<li class="chapter" data-level="117.13" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q14"><i class="fa fa-check"></i><b>117.13</b> Q14</a></li>
<li class="chapter" data-level="117.14" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q15"><i class="fa fa-check"></i><b>117.14</b> Q15</a></li>
<li class="chapter" data-level="117.15" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q16"><i class="fa fa-check"></i><b>117.15</b> Q16</a></li>
<li class="chapter" data-level="117.16" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q17"><i class="fa fa-check"></i><b>117.16</b> Q17</a></li>
<li class="chapter" data-level="117.17" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q18"><i class="fa fa-check"></i><b>117.17</b> Q18</a></li>
<li class="chapter" data-level="117.18" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q19"><i class="fa fa-check"></i><b>117.18</b> Q19</a></li>
</ul></li>
<li class="chapter" data-level="118" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><i class="fa fa-check"></i><b>118</b> （無匹配的）病例對照研究的分析方法 analysis of unmatched case-control studies</a>
<ul>
<li class="chapter" data-level="118.1" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q1-數據讀入"><i class="fa fa-check"></i><b>118.1</b> Q1 數據讀入</a></li>
<li class="chapter" data-level="118.2" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q2-計算粗比值比"><i class="fa fa-check"></i><b>118.2</b> Q2 計算粗比值比</a></li>
<li class="chapter" data-level="118.3" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q3-年齡的混雜或者交互-confounding-or-effect-mnodifier"><i class="fa fa-check"></i><b>118.3</b> Q3 年齡的混雜或者交互 confounding or effect-mnodifier</a></li>
<li class="chapter" data-level="118.4" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q4-宗教信仰-religion-rel-和hiv之間的關係"><i class="fa fa-check"></i><b>118.4</b> Q4 宗教信仰 religion <code>rel</code> 和HIV之間的關係</a></li>
<li class="chapter" data-level="118.5" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q5-性伴侶人數"><i class="fa fa-check"></i><b>118.5</b> Q5 性伴侶人數</a></li>
<li class="chapter" data-level="118.6" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q6-分析劑量-反應關係-dose-response-relationship"><i class="fa fa-check"></i><b>118.6</b> Q6 分析劑量-反應關係 dose-response relationship</a></li>
</ul></li>
<li class="chapter" data-level="119" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html"><i class="fa fa-check"></i><b>119</b> 似然的概念和圖形理解 Likelihood</a>
<ul>
<li class="chapter" data-level="119.1" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q1-二項分佈似然的圖形"><i class="fa fa-check"></i><b>119.1</b> Q1 二項分佈似然的圖形</a></li>
<li class="chapter" data-level="119.2" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q2-修改信賴區間的寬度"><i class="fa fa-check"></i><b>119.2</b> Q2 修改信賴區間的寬度</a></li>
<li class="chapter" data-level="119.3" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q3-嘗試繪製一些極端情況下的似然函數圖"><i class="fa fa-check"></i><b>119.3</b> Q3 嘗試繪製一些極端情況下的似然函數圖</a></li>
<li class="chapter" data-level="119.4" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q4-失敗次數爲-0-會發生什麼"><i class="fa fa-check"></i><b>119.4</b> Q4 失敗次數爲 0 會發生什麼</a></li>
<li class="chapter" data-level="119.5" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q5-泊松分佈參數的似然函數"><i class="fa fa-check"></i><b>119.5</b> Q5 泊松分佈參數的似然函數</a></li>
<li class="chapter" data-level="119.6" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q6-特別少的病例死亡的情況"><i class="fa fa-check"></i><b>119.6</b> Q6 特別少的病例死亡的情況</a></li>
<li class="chapter" data-level="119.7" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q7-25人中15人選a"><i class="fa fa-check"></i><b>119.7</b> Q7 25人中15人選A</a></li>
<li class="chapter" data-level="119.8" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q8-40人中24人選a"><i class="fa fa-check"></i><b>119.8</b> Q8 40人中24人選A</a></li>
<li class="chapter" data-level="119.9" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q9-60人中36人選a"><i class="fa fa-check"></i><b>119.9</b> Q9 60人中36人選A</a></li>
<li class="chapter" data-level="119.10" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q10-繪製精確-exact-和-近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.10</b> Q10 繪製精確 exact 和 近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.11" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q11-繼續繪製精確-exact-和近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.11</b> Q11 繼續繪製精確 exact 和近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.12" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q12-繼續繪製精確-exact-和-近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.12</b> Q12 繼續繪製精確 exact 和 近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.13" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q13-2人死亡18人存活的實驗"><i class="fa fa-check"></i><b>119.13</b> Q13 2人死亡18人存活的實驗</a></li>
<li class="chapter" data-level="119.14" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q14-對數比值-logodds-的對數似然比函數"><i class="fa fa-check"></i><b>119.14</b> Q14 對數比值 logodds 的對數似然比函數</a></li>
<li class="chapter" data-level="119.15" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q15-繪製泊松分佈的對數似然比函數"><i class="fa fa-check"></i><b>119.15</b> Q15 繪製泊松分佈的對數似然比函數</a></li>
<li class="chapter" data-level="119.16" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q16-繪製泊松分佈的對數率的對數似然比函數"><i class="fa fa-check"></i><b>119.16</b> Q16 繪製泊松分佈的對數率的對數似然比函數</a></li>
<li class="chapter" data-level="119.17" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q17-繪製極端情況下的泊松分佈對數似然比函數"><i class="fa fa-check"></i><b>119.17</b> Q17 繪製極端情況下的泊松分佈對數似然比函數</a></li>
<li class="chapter" data-level="119.18" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#關鍵點"><i class="fa fa-check"></i><b>119.18</b> 關鍵點</a></li>
</ul></li>
<li class="chapter" data-level="120" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><i class="fa fa-check"></i><b>120</b> 邏輯回歸模型1 - 單一暴露變量 Logistic regression 1 - effect of a single exposure</a>
<ul>
<li class="chapter" data-level="120.1" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q1-q2-讀入-mortality.dta-數據"><i class="fa fa-check"></i><b>120.1</b> Q1-Q2 讀入 <code>mortality.dta</code> 數據</a></li>
<li class="chapter" data-level="120.2" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q3-結果變量-died"><i class="fa fa-check"></i><b>120.2</b> Q3 結果變量 <code>died</code></a></li>
<li class="chapter" data-level="120.3" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q4-5-第一個簡單邏輯回歸模型"><i class="fa fa-check"></i><b>120.3</b> Q4-5 第一個簡單邏輯回歸模型</a></li>
<li class="chapter" data-level="120.4" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q6-給出-or-值"><i class="fa fa-check"></i><b>120.4</b> Q6 給出 OR 值</a></li>
<li class="chapter" data-level="120.5" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q7-彙總成報告用的表格"><i class="fa fa-check"></i><b>120.5</b> Q7 彙總成報告用的表格</a></li>
<li class="chapter" data-level="120.6" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q8-瞭解微小絲蟲傳染病-microfilarial-infection-和死亡之間的關係"><i class="fa fa-check"></i><b>120.6</b> Q8 瞭解微小絲蟲傳染病 (microfilarial infection) 和死亡之間的關係</a></li>
<li class="chapter" data-level="120.7" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q9-使用指示變量-indicator-variable"><i class="fa fa-check"></i><b>120.7</b> Q9 使用指示變量 indicator variable</a></li>
<li class="chapter" data-level="120.8" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q10-計算比值比"><i class="fa fa-check"></i><b>120.8</b> Q10 計算比值比</a></li>
<li class="chapter" data-level="120.9" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q11-簡單陳述上述分析的結果"><i class="fa fa-check"></i><b>120.9</b> Q11 簡單陳述上述分析的結果</a></li>
<li class="chapter" data-level="120.10" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q12-似然比檢驗用於模型比較"><i class="fa fa-check"></i><b>120.10</b> Q12 似然比檢驗用於模型比較</a></li>
<li class="chapter" data-level="120.11" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q13-分析年齡組和死亡之間的關係"><i class="fa fa-check"></i><b>120.11</b> Q13 分析年齡組和死亡之間的關係</a></li>
<li class="chapter" data-level="120.12" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#分析要點"><i class="fa fa-check"></i><b>120.12</b> 分析要點</a></li>
</ul></li>
<li class="chapter" data-level="121" data-path="邏輯回歸模型2---多於一個預測變量的模型-logistic-regression-2---models-with-more-than-one-variable.html"><a href="邏輯回歸模型2---多於一個預測變量的模型-logistic-regression-2---models-with-more-than-one-variable.html"><i class="fa fa-check"></i><b>121</b> 邏輯回歸模型2 - 多於一個預測變量的模型 Logistic regression 2 - models with more than one variable</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a>
<ul>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html#rsession"><i class="fa fa-check"></i>以下是我的 R 進程信息</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本書由 bookdown 強力驅動</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="貝葉斯多層回歸模型-multilevel-models" class="section level1 hasAnchor" number="55">
<h1><span class="header-section-number">第 55 章</span> 貝葉斯多層回歸模型 multilevel models<a href="貝葉斯多層回歸模型-multilevel-models.html#貝葉斯多層回歸模型-multilevel-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<dl>
<dt>Many statistical models also have anterograde amnesia. As the models move from one cluster - individual, group, location - in the data to another, estimating parameters for each cluster, they forget everything about the previous cluster. … These models implicitly assume that nothing learned about any one category informs estimates for the other categories – the parameters are independent of one another and learn from completely separate proportions of the data. This would be like forgetting you had ever been in a cafe, each time you go to a new cafe. Cafes do differ, but they are also alike.</dt>
<dd>
<p>Richard McElreath</p>
</dd>
</dl>
</blockquote>
<p>其實，當我們開始使用回歸模型時，最推薦的就是從多層回歸模型入手，把它當作一種應該實施的默認選項。當然的確非多層回歸的簡單模型在一些場合下就能夠勝任數據分析的過程給出滿意的結果，但事實上更多時候你會發現多層回歸模型會更加出色的幫助我們理解這個世界。所以最理想的狀態其實或許應該是，我們每次先從多層回歸模型入手分析數據，隨着分析的深入，過程中我們可能發現不再需要多層模型結構就能完成分析任務。這樣其實好過我們從一開始就忽略掉了多層回歸模型的這一關鍵的可能性。</p>
<p>在本章節中，你會切身體會到每一次觀測結果，其實都對其他觀測數據產生影響，由此把模型引入<strong>多層回歸 multilevel models</strong>的範疇。多層回歸模型，與普通的模型不同它們是<strong>有記憶力</strong>的。多層回歸模型在與觀察數據結合並運行之後，它能學習並且記住數據中層級與層級結構之間的特徵。依據數據內部層級結構之間存在的方差與變化 variation，多層回歸模型居然能把數據內部不同層級結構的總體信息給提煉並統合出來 pools information across clusters。而且值得一提的是，這一信息提煉和統合的過程其實通常都傾向於改善模型在每一層數據中對統計參數的估計。簡單總結一下使用多層回歸模型的優點有這麼幾個：</p>
<ol style="list-style-type: decimal">
<li>改善重複採樣 (repeat sampling) 數據的參數估計。當數據特徵之一是從同一對象，同一地理位置身上重複採集觀測值時，傳統的單層簡單模型通常要麼不能理想地擬合 (underfit)，或者出現過度擬合 (overfit) 的現象。</li>
<li>改善採樣不均衡 (imbalance in sampling) 數據的參數估計。當數據中某些層級的樣本相對其它層級的樣本較多時，也就是重複採樣更多的成功採集某些個體，那麼使用多層回歸模型可以有效地避免這些數據佔比例較大的層級錯誤地主導 (unfairly dominating) 所有的參數估計，因爲考慮了數據的層級結構的模型，可以有效地處理不同層級之間存在的差異和不確定性 (uncertainty)。</li>
<li>估計方差的大小 (estimates of variation)。假如你的實驗目的之一就包括了估計個體與個體，甚至組與組之間的差異 (variation，方差)，那麼多層回歸模型對你大有助益，因爲它生來就是爲了估計這樣的方差和變異而設計的。</li>
<li>避免草率地取平均值，保留方差 (avoid averaging, retain variation)。長期一來，分析的學者們常常在預處理數據的時候對數據進行一些取平均值的方法進行“整理”。這當然常常是無心，但對於數據分析來說確實致命的。簡單取平均值的方式會把本來存在的變異給抹去。這一過程常常會造成一些結果看起來似乎太過理想，也就是假自信 (false confidence)，使得數據在進行模型分析之前就帶有人爲（非自然）篡改（或者修改，轉換之後）的痕跡。</li>
</ol>
<div id="多層數據實例蝌蚪和青蛙數據-multilevel-tadpoles" class="section level2 hasAnchor" number="55.1">
<h2><span class="header-section-number">55.1</span> 多層數據實例：蝌蚪和青蛙數據 multilevel tadpoles<a href="貝葉斯多層回歸模型-multilevel-models.html#多層數據實例蝌蚪和青蛙數據-multilevel-tadpoles" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb1025"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1025-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1025-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;reedfrogs&quot;</span>)</span>
<span id="cb1025-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1025-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> reedfrogs</span>
<span id="cb1025-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1025-3" tabindex="-1"></a><span class="fu">str</span>(d)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    48 obs. of  5 variables:
##  $ density : int  10 10 10 10 10 10 10 10 10 10 ...
##  $ pred    : Factor w/ 2 levels &quot;no&quot;,&quot;pred&quot;: 1 1 1 1 1 1 1 1 2 2 ...
##  $ size    : Factor w/ 2 levels &quot;big&quot;,&quot;small&quot;: 1 1 1 1 2 2 2 2 1 1 ...
##  $ surv    : int  9 10 7 10 9 9 10 9 4 9 ...
##  $ propsurv: num  0.9 1 0.7 1 0.9 0.9 1 0.9 0.4 0.9 ...</code></pre>
<p>現在我們只關心上述數據中生存下來的蝌蚪數量 <code>surv</code>，和開始時的蝌蚪數量 <code>density</code>。該數據包涵了很多的變化和不確定性，或者叫做方差 variance。這些變化和不確定性可能來自不同的實驗條件，或者未知的原因。所以，假設每一行數據中的10只蝌蚪，被放在了不同的水池裏，也就是說，上面的數據中我們有48個水池做重複的實驗。於是該數據就可以被理解爲是重複相似的實驗，但是每次的實驗又有一些微妙的不同。每一個水池，就是一個數據的層級 ‘cluster’。如果我們忽略這個層級的概念，我們可能就忽略掉了他們本身在實驗開始之時的基線生存狀況 (baseline survival) 本身可能存在的不確定性 (variation)。這個不確定性，或者叫基線生存狀況的方差可能掩蓋住一些重要的發現。如果我們允許每個水池擁有自己單獨的其實狀態，也就是函數的截距，但是假如僅僅使用啞變量的方法 dummy variable，那其實我們就掉進了進行性健忘症的陷阱裏。因爲雖然他們是不同的水池做的實驗，但是一個水池的結果其實是能提示或者告訴我們其他水池的實驗結果的一些信息的，而不是完全地相互獨立毫無關聯性。</p>
<p>所以我們需要的其實是一個同時能夠允許每個水池的蝌蚪生存擁有自己的起始狀態，也就是函數的截距，且同時考慮到他們之間是有關聯性的，也就是這些截距之間是有一定的方差的。這樣的模型就被叫做隨機截距模型 (varying intercepts models)，這樣的模型是最簡單的多層回歸模型。下面的模型用於預測每個不同的水池中實驗過後蝌蚪的生存狀況 (mortality) ：</p>
<p><span class="math display">\[
\begin{aligned}
S_i  &amp; \sim \text{Binomial}(N_i, p_i) \\
\text{logit}(p_i) &amp; = \alpha_{\text{TANK}[i]}  &amp; [\text{unique log-odds for each tank}] \\
\alpha_j &amp; = \text{Normal}(0, 1.5)  &amp; \text{for } j = 1, \dots, 48
\end{aligned}
\]</span></p>
<p>這個模型很容易可以編碼成爲 Stan 模型：</p>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1027-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-1" tabindex="-1"></a><span class="co"># make the tank cluster variable</span></span>
<span id="cb1027-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-2" tabindex="-1"></a>d<span class="sc">$</span>tank <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(d)</span>
<span id="cb1027-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-3" tabindex="-1"></a></span>
<span id="cb1027-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-4" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb1027-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-5" tabindex="-1"></a>  <span class="at">S =</span> d<span class="sc">$</span>surv, </span>
<span id="cb1027-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-6" tabindex="-1"></a>  <span class="at">N =</span> d<span class="sc">$</span>density, </span>
<span id="cb1027-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-7" tabindex="-1"></a>  <span class="at">tank =</span> d<span class="sc">$</span>tank</span>
<span id="cb1027-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1027-8" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb1028"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1028-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-1" tabindex="-1"></a><span class="co"># approximate posterior</span></span>
<span id="cb1028-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-2" tabindex="-1"></a></span>
<span id="cb1028-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-3" tabindex="-1"></a>m13<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1028-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-4" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1028-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-5" tabindex="-1"></a>    S <span class="sc">~</span> <span class="fu">dbinom</span>( N, p ), </span>
<span id="cb1028-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-6" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[tank], </span>
<span id="cb1028-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-7" tabindex="-1"></a>    a[tank] <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="fl">1.5</span>)</span>
<span id="cb1028-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-8" tabindex="-1"></a>  ), <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span></span>
<span id="cb1028-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-9" tabindex="-1"></a>)</span>
<span id="cb1028-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-10" tabindex="-1"></a></span>
<span id="cb1028-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1028-11" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.1</span>, <span class="st">&quot;../Stanfits/m13_1.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1029-1" tabindex="-1"></a>m13<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_1.rds&quot;</span>)</span>
<span id="cb1029-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1029-2" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.1</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               mean         sd         5.5%        94.5%     n_eff      Rhat4
## a[1]   1.706135516 0.75126999  0.559612202  2.980799190 3565.4398 0.99914084
## a[2]   2.418378688 0.89508779  1.085855358  3.917982001 4098.7241 0.99870974
## a[3]   0.755285062 0.62854994 -0.229874740  1.808953868 5844.2221 0.99874415
## a[4]   2.398939738 0.87583172  1.064463796  3.892148654 3893.4841 0.99826780
## a[5]   1.711930366 0.78109476  0.538386909  3.059664189 4282.7151 1.00000591
## a[6]   1.712400845 0.76663422  0.556389436  2.986639219 3697.2250 0.99865881
## a[7]   2.433901051 0.96823924  0.983975047  4.068994913 3683.5712 0.99851080
## a[8]   1.728234678 0.77691481  0.579123478  3.070141912 2552.7945 1.00061031
## a[9]  -0.378787854 0.63017246 -1.411607834  0.601533811 4502.5692 0.99857748
## a[10]  1.704566280 0.74267187  0.563784136  2.922636900 4936.8884 0.99871181
## a[11]  0.759081120 0.63171344 -0.223449189  1.861229403 4293.1364 0.99840630
## a[12]  0.369263021 0.60895344 -0.575697499  1.317297190 5681.1496 0.99882110
## a[13]  0.770336180 0.64974231 -0.215174796  1.833888814 4366.6278 0.99923073
## a[14] -0.009729068 0.61875932 -0.994355905  1.010911262 5918.5699 0.99849235
## a[15]  1.703282129 0.74387855  0.573729989  2.946188044 4247.8544 0.99910230
## a[16]  1.743809558 0.80544535  0.559255295  3.079851444 4219.7553 0.99904420
## a[17]  2.549011923 0.68607770  1.554237307  3.689000199 4117.3536 0.99855216
## a[18]  2.150779207 0.61378539  1.244894345  3.194931728 4290.9635 0.99873434
## a[19]  1.818262637 0.55673559  0.992956540  2.740192008 6254.5908 0.99845271
## a[20]  3.099216840 0.79046813  1.922768458  4.458605238 3870.3141 0.99860113
## a[21]  2.141388712 0.59123864  1.278037726  3.133666741 3778.8639 0.99947441
## a[22]  2.143619964 0.63146412  1.192457415  3.182062745 3763.2670 0.99863539
## a[23]  2.137536255 0.62219243  1.174864938  3.181079132 4368.0224 0.99870273
## a[24]  1.536828664 0.52728459  0.761942359  2.375794268 4735.8741 0.99837462
## a[25] -1.105415076 0.43496285 -1.851966059 -0.435036245 3482.7299 0.99877398
## a[26]  0.076751268 0.40535395 -0.555377180  0.711271683 4550.4709 0.99868506
## a[27] -1.540868852 0.48401432 -2.359101123 -0.802931346 3882.5694 0.99842876
## a[28] -0.545748574 0.40591978 -1.193630669  0.101944128 4532.7825 0.99856686
## a[29]  0.075142168 0.38799070 -0.520229947  0.696214974 4880.8001 0.99878543
## a[30]  1.325013361 0.48797180  0.579469610  2.140616726 3983.1118 0.99869221
## a[31] -0.726599283 0.41815857 -1.414086716 -0.081095374 4260.4117 0.99865729
## a[32] -0.393374796 0.40388534 -1.026337857  0.233711720 4460.4798 1.00030775
## a[33]  2.851106794 0.66962348  1.863101375  3.976619545 4075.9763 0.99975478
## a[34]  2.439434481 0.53666179  1.636527087  3.330027234 3611.3375 0.99851844
## a[35]  2.462536698 0.58911895  1.585811555  3.493084708 4159.2509 0.99855632
## a[36]  1.894453091 0.47246927  1.166990383  2.700956176 3864.1837 0.99932504
## a[37]  1.897154130 0.47606314  1.193316198  2.690424743 4514.2042 0.99864540
## a[38]  3.371519718 0.80242385  2.209244462  4.757121346 3328.1092 0.99919367
## a[39]  2.466813623 0.56569064  1.614435107  3.428984467 4161.5867 0.99940885
## a[40]  2.164210136 0.52798452  1.379469542  3.097029995 2913.2789 0.99942866
## a[41] -1.901610019 0.47229892 -2.724517479 -1.207876441 4606.9855 0.99941201
## a[42] -0.631228672 0.33261100 -1.175636261 -0.103720359 4309.2499 0.99891339
## a[43] -0.508448320 0.34917306 -1.088393845  0.045662208 4497.9745 0.99878071
## a[44] -0.392124218 0.34118815 -0.948064494  0.143533849 4602.5032 0.99906926
## a[45]  0.507571894 0.34208208 -0.037475944  1.061806146 4501.6383 0.99816571
## a[46] -0.633508160 0.36474922 -1.228174857 -0.061322724 4888.1314 0.99845844
## a[47]  1.912347263 0.48151725  1.209880492  2.741920346 3341.1668 0.99929986
## a[48] -0.051961695 0.34246837 -0.612204797  0.498751869 6207.4457 0.99858292</code></pre>
<p>你會看見模型的運算結果是告訴我們 48 個池塘本身的基線生存狀況，也就是有 48 個截距。但是 <code>m13.1</code> 並不是一個多層回歸模型，下面的模型中關鍵部分的加入才使得這個模型變得更加有意義：</p>
<p><span class="math display">\[
\begin{aligned}
S_i &amp; \sim \text{Binomial}(N_i, p_i)  \\
\text{logit}(p_i) &amp; = \alpha_{\text{TANK}[i]} \\
\alpha_j          &amp; \sim \text{Normal}(\color{blue}{\bar{\alpha}, \sigma}) &amp; [\text{adaptive prior}] \\
\color{blue}{\bar{\alpha}} &amp; \color{blue}{\sim \text{Normal}(0, 1.5)}      &amp; [\text{prior for average tank}] \\
\color{blue}{\sigma}       &amp; \color{blue}{\sim \text{Exponential}(1)}      &amp; [\text{prior for standard deviation of tanks}]
\end{aligned}
\]</span></p>
<p>上述模型中值得注意的是，除了允許不同水池的基線生存狀況，也就是截距可以各不相同，我們還允許這些截距之間存在聯繫。也就是這些截距本身是服從正（常）態分佈的，該正（常）態分佈的均值是 <span class="math inline">\(\bar{\alpha}\)</span>，標準差是 <span class="math inline">\(\sigma\)</span>。這個截距服從的正（常）態分佈的參數，也有自己的先驗概率分佈。我們把這樣的參數叫做超參數 hyperparameters，他們是參數的參數，他們的先驗概率分佈被叫做超先驗 hyperpriors。我們可以用下面的代碼來運行這個模型：</p>
<div class="sourceCode" id="cb1031"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1031-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-1" tabindex="-1"></a>m13<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1031-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-2" tabindex="-1"></a>  <span class="fu">alist</span>(S <span class="sc">~</span> <span class="fu">dbinom</span>( N, p ), </span>
<span id="cb1031-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-3" tabindex="-1"></a>  <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[tank], </span>
<span id="cb1031-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-4" tabindex="-1"></a>  a[tank] <span class="sc">~</span> <span class="fu">dnorm</span>(a_bar, sigma), </span>
<span id="cb1031-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-5" tabindex="-1"></a>  a_bar <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb1031-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-6" tabindex="-1"></a>  sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb1031-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-7" tabindex="-1"></a>  ), <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span></span>
<span id="cb1031-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-8" tabindex="-1"></a>)</span>
<span id="cb1031-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1031-9" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.2</span>, <span class="st">&quot;../Stanfits/m13_2.rds&quot;</span>)</span></code></pre></div>
<p>先比較一下這兩個模型之間的模型信息差別：</p>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1032-1" tabindex="-1"></a>m13<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_2.rds&quot;</span>)</span>
<span id="cb1032-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1032-2" tabindex="-1"></a><span class="fu">compare</span>( m13<span class="fl">.1</span>, m13<span class="fl">.2</span> )</span></code></pre></div>
<pre><code>##            WAIC        SE     dWAIC       dSE     pWAIC       weight
## m13.2 198.87517 7.3372677  0.000000        NA 20.403646 0.9997639405
## m13.1 215.57755 4.5643729 16.702381 4.1259847 26.092822 0.0002360595</code></pre>
<p>從兩個模型之間的比較結果來看，首先，<code>m13.2</code> 只有 21 個有效的參數，比起實際的參數個數 50 個少了很多。這是因爲對這些截距增加了超參數的限制之後，他們受到了更多的約束，更加趨近於彼此。我們可以看看這個模型給出的截距分佈的超參數的事後概率分佈估計：</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1034-1" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.2</span>, <span class="at">depth =</span> <span class="dv">2</span>, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;a_bar&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</span></code></pre></div>
<pre><code>##            mean         sd      5.5%     94.5%     n_eff      Rhat4
## a_bar 1.3393115 0.26442441 0.9230349 1.7758856 3022.9740 0.99984557
## sigma 1.6125652 0.20782693 1.3171320 1.9735443 1846.8192 1.00098472</code></pre>
<p>這裡的截距分佈的超參數的事後估計其實給出了十分精確的估計，其均值在 1.34 左右，標準差是1.62，這說明了不同的水池之間的關係十分近似。也就是說，我們使用這個多層回歸模型，讓模型自己從數據中去學習並獲得截距和截距之間的關係。這比起一開始我們自己給 <code>m13.1</code> 設定的標準差 <code>1.5</code> 還要激進。於是這個多層回歸模型事實上給模型參數的估計增加了更多的限制。</p>
<p>為了加深我們對這個激進的超參數的理解，我們把這兩個模型 <code>m13.1, m13.2</code> 給出的估計結果繪製成圖形來觀察：</p>
<div class="sourceCode" id="cb1036"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1036-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-1" tabindex="-1"></a><span class="co"># extract Stan Samples</span></span>
<span id="cb1036-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m13<span class="fl">.2</span>)</span>
<span id="cb1036-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-3" tabindex="-1"></a><span class="co"># post &lt;- extract.samples(m13.1)</span></span>
<span id="cb1036-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-4" tabindex="-1"></a></span>
<span id="cb1036-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-5" tabindex="-1"></a></span>
<span id="cb1036-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-6" tabindex="-1"></a><span class="co"># compute mean intercept for each tank</span></span>
<span id="cb1036-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-7" tabindex="-1"></a>d<span class="sc">$</span>propsurv.est <span class="ot">&lt;-</span> <span class="fu">logistic</span>( <span class="fu">apply</span>( post<span class="sc">$</span>a, <span class="dv">2</span>, mean ))</span>
<span id="cb1036-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-8" tabindex="-1"></a></span>
<span id="cb1036-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-9" tabindex="-1"></a><span class="co">#  display raw proportions surviving in each tank</span></span>
<span id="cb1036-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-10" tabindex="-1"></a><span class="fu">plot</span>( d<span class="sc">$</span>propsurv, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">xaxt =</span> <span class="st">&#39;n&#39;</span>, </span>
<span id="cb1036-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-11" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&#39;tank&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;proportion survival&#39;</span>, </span>
<span id="cb1036-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-12" tabindex="-1"></a>      <span class="at">col =</span> rangi2, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb1036-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-13" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">48</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">48</span>))</span>
<span id="cb1036-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-14" tabindex="-1"></a></span>
<span id="cb1036-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-15" tabindex="-1"></a></span>
<span id="cb1036-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-16" tabindex="-1"></a><span class="co"># overlay posterior means</span></span>
<span id="cb1036-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-17" tabindex="-1"></a><span class="fu">points</span>( d<span class="sc">$</span>propsurv.est )</span>
<span id="cb1036-18"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-18" tabindex="-1"></a></span>
<span id="cb1036-19"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-19" tabindex="-1"></a><span class="co"># mark posterior mean probability across tanks </span></span>
<span id="cb1036-20"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-20" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h =</span> <span class="fu">mean</span>(<span class="fu">inv_logit</span>(post<span class="sc">$</span>a_bar)), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1036-21"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-21" tabindex="-1"></a></span>
<span id="cb1036-22"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-22" tabindex="-1"></a><span class="co"># draw vertical dividers between tank densities</span></span>
<span id="cb1036-23"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-23" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">16.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1036-24"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-24" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">32.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1036-25"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-25" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">8</span>, <span class="dv">0</span>, <span class="st">&#39;small tanks&#39;</span>)</span>
<span id="cb1036-26"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-26" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">16</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="dv">0</span>, <span class="st">&#39;medium tanks&#39;</span>)</span>
<span id="cb1036-27"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1036-27" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">32</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="dv">0</span>, <span class="st">&#39;large tanks&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig01"></span>
<img src="bookdown_files/figure-html/introBayes15-fig01-1.png" alt="Empirical proportions of surviviors in each tadpolle tank, shown by the filled blue points, plotted with the 48 per-tank parameters from the multilevel model, shown by the black circles. The dashed line locates the average proportion of survivors across all tanks. The vertical lines divide tanks with different initial densities of tadpoles: small tanks (10 tadpoles), medium tanks (25), and large tanks (35). In every tank, the posterior mean from the multilevel model is closer to the dashed line than the empirical proportion is. This reflects the pooling of information across tanks, to help with inference." width="576" />
<p class="caption">
圖 55.1: Empirical proportions of surviviors in each tadpolle tank, shown by the filled blue points, plotted with the 48 per-tank parameters from the multilevel model, shown by the black circles. The dashed line locates the average proportion of survivors across all tanks. The vertical lines divide tanks with different initial densities of tadpoles: small tanks (10 tadpoles), medium tanks (25), and large tanks (35). In every tank, the posterior mean from the multilevel model is closer to the dashed line than the empirical proportion is. This reflects the pooling of information across tanks, to help with inference.
</p>
</div>
<p>圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig01">55.1</a> 中，橫軸是水池的編號，從左往右依次是從 1 到 48 號水池；縱軸是水池中蝌蚪生存下來的比例。圖中藍色的點是原始數據點，也就是實際觀察值 <code>propsurv</code>。黑色的鏤空點則是模型估計的每個水池的截距。水平的橫虛線是估計的所有水池的蝌蚪存活概率的平均值 <span class="math inline">\(\alpha\)</span>。而圖中的縱向的實線是把水池按照實驗開始時的蝌蚪密度計算的不同類型的池子，從小，中，到大三種類型的池子，各16個。不難注意到我們能看見多層回歸模型給出的推測值都相對觀察值更靠近總體平均生存概率。看起來似乎是黑色鏤空的圓點都更加靠近數據分佈的中心，平均值附近。這種現象又被叫做縮水現象 shrinkage，這是由於增加了超參數之後的多層回歸模型的參數估計受到的限制性的調整 regularization。其次，我們也發現在圖左側，也就是起始蝌蚪密度較小的水池裏，多層回歸模型估計的生存概率值更加靠近總體平均值，也就是縮水得更加明顯，距離觀察數據比密度大的水池要遠。也就是說，在小的水池裏，我們更加容易發現模型估計值和觀察值之間的差別，但是在其實密度大的水池中，觀察值和模型估計值更加接近。最後，如果藍色的點離虛線的總體均值越遠，它和黑色點，多層回歸模型估計值之間的差別越大。</p>
<p>上述三種現象其實是在告訴我們一件很重要的事，也就是把信息綜合起來的話，每一個層級的參數估計都會受益得到提升和改善 (pooling information across clusters to improve estimates) 。這裏的綜合信息 pooling information 的意義是，每一個水池的數據，每一個層級的數據，都含有能提高和改善其他層級參數估計信息 each tank provides information that can be used to improve the estimates for all of the other tanks。這是因爲我們假設了每個水池的截距 log-odds 雖有變化但不獨立而是服從某個正（常）態分佈。有了這個分佈的假設，貝葉斯估計就能幫助我們共享信息給不同的數據層級。</p>
<p>那麼，模型估計的這些青蛙的總體生存概率的分佈是怎樣的呢？我們可以從它對應的模型事後概率分佈中獲得結果繪製成圖。我們先繪製事後概率分佈中前100個 <span class="math inline">\(\alpha, \sigma\)</span> 組合的平均存活率的分佈：</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-1" tabindex="-1"></a><span class="co"># show first 100 populations in the posterior </span></span>
<span id="cb1037-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-2" tabindex="-1"></a><span class="fu">plot</span>( <span class="cn">NULL</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">4</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.35</span>), </span>
<span id="cb1037-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-3" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;log-odds survive&quot;</span>, </span>
<span id="cb1037-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-4" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb1037-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-5" tabindex="-1"></a></span>
<span id="cb1037-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-6" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span> ) </span>
<span id="cb1037-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-7" tabindex="-1"></a>  <span class="fu">curve</span>( <span class="fu">dnorm</span>(x, post<span class="sc">$</span>a_bar[i], post<span class="sc">$</span>sigma[i]), <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb1037-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1037-8" tabindex="-1"></a>         <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">&quot;black&quot;</span>, <span class="fl">0.2</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig02"></span>
<img src="bookdown_files/figure-html/introBayes15-fig02-1.png" alt="The inferred population of survival across tanks. 100 Gaussian distributions of the log-odds of survival, sampled from the posteriro of m13.2." width="576" />
<p class="caption">
圖 55.2: The inferred population of survival across tanks. 100 Gaussian distributions of the log-odds of survival, sampled from the posteriro of m13.2.
</p>
</div>
<p>圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig02">55.2</a> 告訴我們，均值 <span class="math inline">\(\alpha\)</span> 和它對應的標準差 <span class="math inline">\(\sigma\)</span> 都是有相當程度不確定性的 (uncertainty)。</p>
<div class="sourceCode" id="cb1038"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1038-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-1" tabindex="-1"></a><span class="co"># sample 8000 imaginary tanks from the posterior distribution </span></span>
<span id="cb1038-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-2" tabindex="-1"></a>sim_tanks <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">80000</span>, post<span class="sc">$</span>a_bar, post<span class="sc">$</span>sigma)</span>
<span id="cb1038-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-3" tabindex="-1"></a></span>
<span id="cb1038-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-4" tabindex="-1"></a><span class="co"># transform to probability and visualize</span></span>
<span id="cb1038-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-5" tabindex="-1"></a><span class="fu">dens</span>( <span class="fu">inv_logit</span>(sim_tanks), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">adj =</span> <span class="fl">0.1</span>, </span>
<span id="cb1038-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1038-6" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;probability survive&quot;</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig03"></span>
<img src="bookdown_files/figure-html/introBayes15-fig03-1.png" alt="Survival probabilities for 8000 new simulated tanks, averaging over the posterior distribution in previous figure." width="576" />
<p class="caption">
圖 55.3: Survival probabilities for 8000 new simulated tanks, averaging over the posterior distribution in previous figure.
</p>
</div>
</div>
<div id="多層回歸的變化的效應和過度擬合過低擬合之間的交易-varying-effects-and-the-underfittingoverfitting-trade-off" class="section level2 hasAnchor" number="55.2">
<h2><span class="header-section-number">55.2</span> 多層回歸的變化的效應和過度擬合/過低擬合之間的交易 varying effects and the underfitting/overfitting trade-off<a href="貝葉斯多層回歸模型-multilevel-models.html#多層回歸的變化的效應和過度擬合過低擬合之間的交易-varying-effects-and-the-underfittingoverfitting-trade-off" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>使用多層回歸模型使得模型可以估計不同（截距或者斜率）的效應，其最大的好處是能夠給出更加準確的估計。其原理就是使用混合效應模型其實使得模型儘量避免了過度/過低擬合。如果建立模型是爲了預測未知池塘中蝌蚪存活概率的話，我們可以有三種策略：</p>
<ol style="list-style-type: decimal">
<li>完全合併策略，complete pooling。這方法其實是把總體的水池蝌蚪生存率這一數據看作是不變的 the population survival probability of ponds is invariant，也就是固定一個截距，適用所有的池塘。</li>
<li>完全不合併策略，no pooling。這方法類似 <code>m13.1</code> 模型的方案，無視水池和水池之間可能存在的相關性，把每個水池都看作的獨立互不影響的。也就是進行性失憶 模型。</li>
<li>部分合併策略，partial pooling。這方法其實是 <code>m13.2</code> 模型的多層回歸模型方案，通過允許水池之間有相關性，使模型自行學習應有的超參數。</li>
</ol>
<p>很顯然，第一個方案其實很不切合實際，雖然把所有的數據都彙總到一個點上，但是指望用這唯一的一個估計結果來適用所有的水池的生存概率，認爲所有的水池都會產生相同的結果是不符合現實情況的，這一方案認爲水池和水池之間生存概率不會有差別，沒有變化和靈活性, all ponds are identical。完全合併策略造成的結果就是，樣本的平均值事實上過低擬合了數據的信息 (unterfits the data)。第二個方案則是另一個極端，認爲每一個水池都給出完全不同的結果，即使相同也是偶然，水池之間毫無關聯。圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig01">55.1</a> 中的藍色實心點就是這樣的模型。用於估計每個點的位置的數據在第二個方案下都會變得很少，所以每一個估計都變得更加不精確。於是，完全不合併策略就是使得模型過度擬合數據 (overfits the data) 。第三個方案就是多層回歸模型增加的混合效應，它的部分合併策略其實是第一個和第二個方案的折衷辦法，使得模型的估計給出更加靈活的結果，也更適合擴展到預測未知數據，同時避免了過度/過低擬合。</p>
<p>爲了展示這個效果，我們可以用計算機模擬一些生存率的蝌蚪水池數據作爲已知的結果，用不同的模型來分析獲得其估計，從而直觀地理解這三種方案的不同思路。</p>
<div id="用於產生模擬數據的模型-the-model" class="section level3 hasAnchor" number="55.2.1">
<h3><span class="header-section-number">55.2.1</span> 用於產生模擬數據的模型 the model<a href="貝葉斯多層回歸模型-multilevel-models.html#用於產生模擬數據的模型-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>第一步是設計我們希望產生數據的模型。我們可以直接使用 <code>m13.2</code> 的模型的主體部分：</p>
<p><span class="math display">\[
\begin{aligned}
S_i &amp; \sim \text{Binomial}(N_i, p_i) \\
\text{logit}(p_i) &amp; = \alpha_{\text{POND}[i]} \\
\alpha_j &amp; \sim \text{Normal}(\bar{\alpha}, \sigma) \\
\bar{\alpha} &amp; \sim \text{Normal}(0, 1.5) \\
\sigma &amp; \sim \text{Exponential}(1)
\end{aligned}
\]</span></p>
<p>為了能順利從這個模型中產生模擬數據，我們需要給模型中賦予真實值的參數有：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\bar{\alpha}\)</span> 是總體池塘蝌蚪存活概率的平均值的對數比值 average log-odds of survival in the entire population of ponds。</li>
<li><span class="math inline">\(\sigma\)</span> 是總體池塘蝌蚪存活概率平均值的對數比值的標準差 the standard deviation of the distribution of log-odds of survival among ponds。</li>
<li><span class="math inline">\(\alpha\)</span> 一系列水池的蝌蚪存過概率的對數比值的真實值，作為模型的變動截距 a vector of individual pond intercepts, one for each pond。</li>
</ol>
<p>此外，我們還需要設定每個水池的蝌蚪起始樣本量 <span class="math inline">\(N_i\)</span>，這些都設定完畢之後，就只剩下每個水池可能存活的蝌蚪數量了，這個可以使用二項分佈的隨機值來設定。</p>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1039-1" tabindex="-1"></a>a_bar <span class="ot">&lt;-</span> <span class="fl">1.5</span> <span class="co"># mean log-odds of survival in the entire population</span></span>
<span id="cb1039-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1039-2" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">1.5</span> <span class="co"># standar deviation of the distribution of log-odds of survival among ponds</span></span>
<span id="cb1039-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1039-3" tabindex="-1"></a>nponds <span class="ot">&lt;-</span> <span class="dv">60</span> <span class="co"># altogether 60 ponds</span></span>
<span id="cb1039-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1039-4" tabindex="-1"></a>Ni <span class="ot">&lt;-</span> <span class="fu">as.integer</span>( <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">35</span>), <span class="at">each =</span> <span class="dv">15</span> )) <span class="co"># 15 ponds with 5, 10, 25, and 35 tadpoles each</span></span></code></pre></div>
<p>我們設定了60個水池，起始蝌蚪的數量分別是 5，10，25，35 的池子各有15個。另外 <span class="math inline">\(\bar{\alpha}, \sigma\)</span> 定義了我們設計下的總體存活率的對數比值 log-odds 的分佈特徵。接下來就是讓計算機生成符合這個分佈條件 <span class="math inline">\(\text{Normal}(\bar{\alpha}, \sigma)\)</span> 的 60 個水池的存活率的對數比值作為各自的截距。</p>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1040-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1040-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5005</span>) </span>
<span id="cb1040-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1040-2" tabindex="-1"></a>a_pond <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( nponds, <span class="at">mean =</span> a_bar, <span class="at">sd =</span> sigma)</span></code></pre></div>
<p>上面的代碼生成了60個符合設定的均值和標準差的數據，作為每個水池的蝌蚪存活率的對數比值。最後，把這些數據合併成為一個數據框：</p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1041-1" tabindex="-1"></a>dsim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">pond =</span> <span class="dv">1</span><span class="sc">:</span>nponds, <span class="at">Ni =</span> Ni, <span class="at">true_a =</span> a_pond)</span>
<span id="cb1041-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1041-2" tabindex="-1"></a><span class="fu">str</span>(dsim)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    60 obs. of  3 variables:
##  $ pond  : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Ni    : int  5 5 5 5 5 5 5 5 5 5 ...
##  $ true_a: num  0.567 1.99 -0.138 1.857 3.912 ...</code></pre>
<p>生成的數據框 <code>dsim</code> 有三個變量，一個是水池編號，一個是水池起始蝌蚪數量，一個是真實的存活概率的對數比值 (log-odds)。</p>
</div>
<div id="模擬存活概率結果-simulate-survivors" class="section level3 hasAnchor" number="55.2.2">
<h3><span class="header-section-number">55.2.2</span> 模擬存活概率結果 simulate survivors<a href="貝葉斯多層回歸模型-multilevel-models.html#模擬存活概率結果-simulate-survivors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>根據我們設定的每個水池的”真實”存活概率的對數比值，我們不難計算每個水池的”真實”存活概率：</p>
<p><span class="math display">\[
p_i = \frac{\exp(\alpha_i)}{1 +\exp(\alpha_i)}
\]</span></p>
<p>使用 <code>logistic</code> 函數可以方便的計算並且讓計算機模擬一系列該水池的蝌蚪存活數量：</p>
<div class="sourceCode" id="cb1043"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1043-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1043-1" tabindex="-1"></a>dsim<span class="sc">$</span>Si <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( nponds, <span class="at">prob =</span> <span class="fu">logistic</span>(dsim<span class="sc">$</span>true_a), <span class="at">size =</span> dsim<span class="sc">$</span>Ni)</span>
<span id="cb1043-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1043-2" tabindex="-1"></a><span class="fu">str</span>(dsim)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    60 obs. of  4 variables:
##  $ pond  : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Ni    : int  5 5 5 5 5 5 5 5 5 5 ...
##  $ true_a: num  0.567 1.99 -0.138 1.857 3.912 ...
##  $ Si    : int  4 5 1 5 5 5 2 5 4 4 ...</code></pre>
</div>
<div id="計算完全不合併策略-no-pooling-estimates" class="section level3 hasAnchor" number="55.2.3">
<h3><span class="header-section-number">55.2.3</span> 計算完全不合併策略 no-pooling estimates<a href="貝葉斯多層回歸模型-multilevel-models.html#計算完全不合併策略-no-pooling-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>在這個模型設定下，最簡單快速的是計算完全不合併策略時的結果。這可以直接從前面計算機生成的實驗數據計算獲得。先計算每個水池中蝌蚪的存活概率：</p>
<div class="sourceCode" id="cb1045"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1045-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1045-1" tabindex="-1"></a>dsim<span class="sc">$</span>p_nopool <span class="ot">&lt;-</span> dsim<span class="sc">$</span>Si <span class="sc">/</span> dsim<span class="sc">$</span>Ni</span>
<span id="cb1045-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1045-2" tabindex="-1"></a><span class="fu">head</span>(dsim)</span></code></pre></div>
<pre><code>##   pond Ni      true_a Si p_nopool
## 1    1  5  0.56673123  4      0.8
## 2    2  5  1.99002317  5      1.0
## 3    3  5 -0.13775688  1      0.2
## 4    4  5  1.85676651  5      1.0
## 5    5  5  3.91208800  5      1.0
## 6    6  5  1.95414869  5      1.0</code></pre>
<p>數據 <code>dsim</code> 的新增一列 <code>p_nopool</code> 就是每個水池實際觀察到的蝌蚪存活概率。這個計算結果等同於我們把每個水池當作一個啞變量互無關聯時給出的模型估計結果。</p>
</div>
<div id="計算部分合併策略的結果-partial-pooling-estimates" class="section level3 hasAnchor" number="55.2.4">
<h3><span class="header-section-number">55.2.4</span> 計算部分合併策略的結果 partial-pooling estimates<a href="貝葉斯多層回歸模型-multilevel-models.html#計算部分合併策略的結果-partial-pooling-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>我們來使用 Stan 運行這個部分合併結果的模型</p>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-1" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb1047-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-2" tabindex="-1"></a>  <span class="at">Si =</span> dsim<span class="sc">$</span>Si, </span>
<span id="cb1047-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-3" tabindex="-1"></a>  <span class="at">Ni =</span> dsim<span class="sc">$</span>Ni, </span>
<span id="cb1047-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-4" tabindex="-1"></a>  <span class="at">pond =</span> dsim<span class="sc">$</span>pond</span>
<span id="cb1047-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-5" tabindex="-1"></a>)</span>
<span id="cb1047-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-6" tabindex="-1"></a>m13<span class="fl">.30</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1047-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-7" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1047-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-8" tabindex="-1"></a>    Si <span class="sc">~</span> <span class="fu">dbinom</span>( Ni, p ), </span>
<span id="cb1047-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-9" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a_pond[pond], </span>
<span id="cb1047-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-10" tabindex="-1"></a>    a_pond[pond] <span class="sc">~</span> <span class="fu">dnorm</span>( a_bar, sigma ), </span>
<span id="cb1047-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-11" tabindex="-1"></a>    a_bar <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb1047-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-12" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb1047-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-13" tabindex="-1"></a>  ), <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span></span>
<span id="cb1047-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-14" tabindex="-1"></a>)</span>
<span id="cb1047-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1047-15" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.30</span>, <span class="st">&quot;../Stanfits/m13_30.rds&quot;</span>)</span></code></pre></div>
<p>上面的模型運行計算的就是最基礎版本的隨機截距模型。我們來看一下它給出的 <span class="math inline">\(\bar{\alpha}, \sigma\)</span> 的事後分佈情況，下面的結果包含了六十個水池的截距，會很長：</p>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1048-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1048-1" tabindex="-1"></a>m13<span class="fl">.30</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_30.rds&quot;</span>)</span>
<span id="cb1048-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1048-2" tabindex="-1"></a><span class="fu">precis</span>( m13<span class="fl">.30</span>, <span class="at">depth =</span> <span class="dv">2</span> )</span></code></pre></div>
<pre><code>##                    mean         sd          5.5%       94.5%     n_eff      Rhat4
## a_pond[1]   1.650407110 0.96904063  0.1840157397  3.21610041 3602.5566 0.99872074
## a_pond[2]   2.834338499 1.24148870  1.0007366114  4.92653420 2882.0704 0.99911023
## a_pond[3]  -0.643249556 0.91047753 -2.1226558797  0.73631508 2442.9210 1.00118607
## a_pond[4]   2.879393705 1.23392475  1.0753994158  5.01899499 2140.7584 0.99862131
## a_pond[5]   2.850206711 1.27463172  0.9832639699  4.99317825 1818.6398 1.00009094
## a_pond[6]   2.875036377 1.27603932  1.0240878520  5.13249706 2580.0892 0.99906937
## a_pond[7]   0.073569339 0.80574369 -1.2100708197  1.33815259 3043.3444 0.99860653
## a_pond[8]   2.845285499 1.24419299  1.0925164731  5.04294899 3061.6630 0.99967991
## a_pond[9]   1.640764609 1.04090309  0.0658312282  3.40013596 3786.2020 0.99898298
## a_pond[10]  1.662719698 1.00690244  0.0942168850  3.33404818 2884.8516 0.99881739
## a_pond[11]  2.854369003 1.27008868  0.9986433001  4.88275188 2595.0291 0.99981048
## a_pond[12]  0.078809355 0.84263594 -1.2662538706  1.46245910 3379.5942 0.99913852
## a_pond[13]  2.841399020 1.23604483  1.0306836717  4.98853447 2082.3706 1.00009111
## a_pond[14]  2.885347058 1.24766958  1.1012827128  4.95147914 2010.1180 1.00160532
## a_pond[15]  2.838645518 1.22543550  1.0330515180  4.94891601 2733.4150 1.00068080
## a_pond[16]  1.575398583 0.75674601  0.4307555558  2.80348477 3558.0680 0.99881879
## a_pond[17] -1.441357255 0.72675686 -2.6746649858 -0.36628831 2295.6003 0.99957747
## a_pond[18]  1.069732355 0.65145174  0.0336161365  2.13106736 3718.5782 0.99905032
## a_pond[19] -0.940599103 0.67353423 -2.0642510405  0.12758493 4180.4317 0.99851252
## a_pond[20]  1.571571268 0.78323302  0.3953309826  2.85302461 3979.0358 0.99827203
## a_pond[21] -0.142395459 0.62805421 -1.1595189249  0.85277506 4230.9275 0.99920164
## a_pond[22]  2.259831678 0.93055697  0.9101710635  3.82472671 2625.5858 1.00019856
## a_pond[23]  3.241016009 1.09565777  1.6854998943  5.17061513 2012.3850 0.99952697
## a_pond[24]  0.606054685 0.63343113 -0.3899463101  1.61247305 5142.2846 0.99837767
## a_pond[25]  3.279252138 1.15974972  1.6087975632  5.29849803 2262.1498 0.99906149
## a_pond[26]  2.218857703 0.90489171  0.8620718729  3.79051487 2577.0982 1.00011192
## a_pond[27]  1.032862125 0.71037078 -0.0514290807  2.22168735 2789.1514 0.99941969
## a_pond[28]  2.247840392 0.89076760  0.9912766740  3.77271073 2158.9564 1.00095656
## a_pond[29]  1.566335229 0.76329714  0.4490445116  2.88024205 2990.4098 0.99957137
## a_pond[30]  1.043066174 0.71390861 -0.0550604298  2.24023090 4217.3874 1.00012562
## a_pond[31]  2.460298686 0.67071150  1.4600395439  3.59187574 2605.1400 0.99919053
## a_pond[32]  2.056988630 0.58082689  1.1738653532  3.03319837 3417.6131 0.99846202
## a_pond[33]  1.719997357 0.52738590  0.9109309041  2.60832973 5587.4489 0.99851302
## a_pond[34]  1.256999633 0.49178056  0.5168072533  2.03843119 3268.9943 0.99924019
## a_pond[35]  0.674469822 0.42408930  0.0064163076  1.36286305 3414.4603 0.99919911
## a_pond[36]  3.835241545 1.11351640  2.3118751443  5.80523282 1615.1664 1.00131024
## a_pond[37] -1.001666846 0.45192860 -1.7457914860 -0.32383094 4309.0830 0.99947060
## a_pond[38] -1.181771717 0.45084523 -1.9246579225 -0.47367188 3350.4592 0.99890768
## a_pond[39]  0.677536497 0.44100771 -0.0185801594  1.39114768 3663.6990 0.99867024
## a_pond[40]  3.860786217 1.12076950  2.2692482127  5.79948052 1667.3130 0.99854679
## a_pond[41]  3.821365313 1.06524390  2.3305627294  5.67578489 1612.7689 1.00105065
## a_pond[42]  2.462269046 0.69314717  1.4258509184  3.61833311 3186.8495 0.99857627
## a_pond[43] -0.128696920 0.40218054 -0.7690797367  0.50362840 3589.9168 0.99902865
## a_pond[44]  0.657109234 0.40292342  0.0236895055  1.29586999 3980.6607 0.99949000
## a_pond[45] -1.186495921 0.46040340 -1.9314086555 -0.48683175 4384.5500 0.99898465
## a_pond[46]  0.010147737 0.33077455 -0.5051117179  0.52945609 3516.9707 0.99883160
## a_pond[47]  4.065550464 1.03658464  2.6073678621  5.79930831 1435.8616 1.00103136
## a_pond[48]  2.079263555 0.50984644  1.3320833116  2.96382734 3284.9157 1.00002749
## a_pond[49]  1.857357020 0.48234328  1.1198986835  2.64213548 3374.6112 0.99971553
## a_pond[50]  2.787020417 0.68170929  1.7895947754  3.96695002 2601.4123 0.99863578
## a_pond[51]  2.406458965 0.58533949  1.5477499282  3.35287318 3604.8986 0.99978555
## a_pond[52]  0.357155211 0.33339316 -0.1620370866  0.88372445 4181.1260 0.99934405
## a_pond[53]  2.106903052 0.50035530  1.3361915299  2.93145339 3158.0118 0.99925148
## a_pond[54]  4.060400285 1.01624187  2.6345088811  5.87636234 1617.3083 1.00044270
## a_pond[55]  1.130150172 0.38675503  0.5261511543  1.78230406 2975.5885 0.99861533
## a_pond[56]  2.779640587 0.66678682  1.8432349230  3.83522304 2634.3398 0.99956022
## a_pond[57]  0.713532057 0.35419243  0.1587824074  1.28652167 3868.9928 0.99843233
## a_pond[58]  4.044509994 1.01564448  2.6091145979  5.84183473 2089.2851 0.99919628
## a_pond[59]  1.648179868 0.44517530  0.9570171345  2.39649263 2929.4914 0.99939655
## a_pond[60]  2.411574826 0.61119724  1.4920258316  3.43769741 2202.5257 0.99918695
## a_bar       1.659983578 0.24579290  1.2777780128  2.05546494 1231.0486 1.00115140
## sigma       1.671424362 0.23676423  1.3222544730  2.08017324  641.1696 1.00665994</code></pre>
<p>很好，接下來就可以運算每個水池的模型預測存活概率，並且添加到我們預先設定好的實驗數據中去。爲了便於比較，先要計算真實的水池中蝌蚪的存活概率。最後一步，就是計算模型預測的存活率，和實際真實存活率之間的差距了，也叫模型估計誤差。然後把這兩個條件下的估計誤差進行繪製在同一張圖上直觀地比較：</p>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-1" tabindex="-1"></a>m13<span class="fl">.30</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_30.rds&quot;</span>)</span>
<span id="cb1050-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m13<span class="fl">.30</span> )</span>
<span id="cb1050-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-3" tabindex="-1"></a>dsim<span class="sc">$</span>p_partpool <span class="ot">&lt;-</span> <span class="fu">apply</span>( <span class="fu">inv_logit</span>(post<span class="sc">$</span>a_pond), <span class="dv">2</span>, mean)</span>
<span id="cb1050-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-4" tabindex="-1"></a></span>
<span id="cb1050-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-5" tabindex="-1"></a>dsim <span class="ot">&lt;-</span> dsim <span class="sc">%&gt;%</span> </span>
<span id="cb1050-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-6" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p_true =</span> <span class="fu">inv_logit</span>(true_a),</span>
<span id="cb1050-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-7" tabindex="-1"></a>         <span class="at">nopool_error =</span> <span class="fu">abs</span>(p_nopool <span class="sc">-</span> p_true), </span>
<span id="cb1050-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-8" tabindex="-1"></a>         <span class="at">partpool_erro =</span> <span class="fu">abs</span>(p_partpool <span class="sc">-</span> p_true))</span>
<span id="cb1050-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-9" tabindex="-1"></a></span>
<span id="cb1050-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-10" tabindex="-1"></a><span class="co"># or similarly you can use basic R command</span></span>
<span id="cb1050-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-11" tabindex="-1"></a><span class="co"># nopool_erro &lt;- abs( dsim$p_nopool - dsim$p_true )</span></span>
<span id="cb1050-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-12" tabindex="-1"></a><span class="co"># partpool_erro &lt;- abs( dsim$p_partpool - dsim$p_true )</span></span>
<span id="cb1050-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-13" tabindex="-1"></a></span>
<span id="cb1050-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-14" tabindex="-1"></a></span>
<span id="cb1050-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-15" tabindex="-1"></a><span class="fu">plot</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>, dsim<span class="sc">$</span>nopool_error,</span>
<span id="cb1050-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-16" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;Pond&quot;</span>, </span>
<span id="cb1050-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-17" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;absolute error&quot;</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb1050-18"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-18" tabindex="-1"></a>      <span class="at">col =</span> rangi2, <span class="at">pch =</span> <span class="dv">16</span>, </span>
<span id="cb1050-19"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-19" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>))</span>
<span id="cb1050-20"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-20" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>, dsim<span class="sc">$</span>partpool_erro )</span>
<span id="cb1050-21"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-21" tabindex="-1"></a></span>
<span id="cb1050-22"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-22" tabindex="-1"></a></span>
<span id="cb1050-23"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-23" tabindex="-1"></a><span class="co"># mark posterior mean probability across tanks </span></span>
<span id="cb1050-24"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-24" tabindex="-1"></a>error_avg <span class="ot">&lt;-</span> dsim <span class="sc">%&gt;%</span></span>
<span id="cb1050-25"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-25" tabindex="-1"></a>  <span class="fu">group_by</span>(Ni) <span class="sc">%&gt;%</span> </span>
<span id="cb1050-26"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-26" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">nopool_avg =</span> <span class="fu">mean</span>(nopool_error), </span>
<span id="cb1050-27"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-27" tabindex="-1"></a>            <span class="at">partpool_avg =</span> <span class="fu">mean</span>(partpool_erro))</span>
<span id="cb1050-28"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-28" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">1</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">1</span>], </span>
<span id="cb1050-29"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-29" tabindex="-1"></a>         <span class="dv">16</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">1</span>], </span>
<span id="cb1050-30"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-30" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1050-31"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-31" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">1</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">1</span>], </span>
<span id="cb1050-32"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-32" tabindex="-1"></a>         <span class="dv">16</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">1</span>], </span>
<span id="cb1050-33"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-33" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1050-34"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-34" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">17</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">2</span>], </span>
<span id="cb1050-35"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-35" tabindex="-1"></a>         <span class="dv">32</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">2</span>], </span>
<span id="cb1050-36"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-36" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1050-37"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-37" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">17</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">2</span>], </span>
<span id="cb1050-38"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-38" tabindex="-1"></a>         <span class="dv">32</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">2</span>], </span>
<span id="cb1050-39"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-39" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1050-40"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-40" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">33</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">3</span>], </span>
<span id="cb1050-41"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-41" tabindex="-1"></a>         <span class="dv">46</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">3</span>], </span>
<span id="cb1050-42"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-42" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1050-43"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-43" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">33</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">3</span>], </span>
<span id="cb1050-44"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-44" tabindex="-1"></a>         <span class="dv">46</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">3</span>], </span>
<span id="cb1050-45"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-45" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1050-46"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-46" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">47</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">4</span>], </span>
<span id="cb1050-47"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-47" tabindex="-1"></a>         <span class="dv">60</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">4</span>], </span>
<span id="cb1050-48"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-48" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1050-49"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-49" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">47</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">4</span>], </span>
<span id="cb1050-50"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-50" tabindex="-1"></a>         <span class="dv">60</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">4</span>], </span>
<span id="cb1050-51"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-51" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1050-52"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-52" tabindex="-1"></a></span>
<span id="cb1050-53"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-53" tabindex="-1"></a><span class="co"># draw vertical dividers between tank densities</span></span>
<span id="cb1050-54"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-54" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">16.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1050-55"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-55" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">32.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1050-56"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-56" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">46.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1050-57"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-57" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Tiny ponds (5)&#39;</span>)</span>
<span id="cb1050-58"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-58" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">16</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Small ponds (10)&#39;</span>)</span>
<span id="cb1050-59"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-59" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">32</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Medium ponds (25)&#39;</span>)</span>
<span id="cb1050-60"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1050-60" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">46</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Large ponds (35)&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig04"></span>
<img src="bookdown_files/figure-html/introBayes15-fig04-1.png" alt="Error of no-pooling and partial pooling estimates, for the simulated tadpole ponds. The horizontal axis displays pond number. The vertical axis measures the absolute error in the predicted proportion of survivors, compared to the true value used in the simulation. The higher the point, the worse the estimate. No-pooling shown in blue. Partial pooling shown in black. The blue and dashed black lines show the average error for each kind of estimate, across each initial density of tadpoles (pond size). Smaller ponds porduce more error, but the partial pooling estimates are better on average, especially in smaller ponds." width="816" />
<p class="caption">
圖 55.4: Error of no-pooling and partial pooling estimates, for the simulated tadpole ponds. The horizontal axis displays pond number. The vertical axis measures the absolute error in the predicted proportion of survivors, compared to the true value used in the simulation. The higher the point, the worse the estimate. No-pooling shown in blue. Partial pooling shown in black. The blue and dashed black lines show the average error for each kind of estimate, across each initial density of tadpoles (pond size). Smaller ponds porduce more error, but the partial pooling estimates are better on average, especially in smaller ponds.
</p>
</div>
<p>從圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig04">55.4</a> 中我們首先能夠直接一眼就觀察到的重要信息就是，這兩種方案，一個是完全不合併方案，一個是部分合併方案，無論是哪一種，其實對樣本量大的水池（圖中靠右側的水池）的存活概率估計誤差都比較低。這主要是因爲樣本量越多，估計得越精確。而樣本量較小的水池，途中靠左側的水池中，由於蝌蚪數量有限，即使是部分合併方案使用的隨機截距模型也給出比較大的誤差。其次，藍色線 (完全不合併方案) 幾乎總是在黑色虛線 (隨機截距模型，部分合併方案) 的上方，或者二者在大樣本時，會十分接近。當然隨機截距並不總是更加優越，只是在許許多多的計算中，從長遠來看 (in the long run) 隨機截距模型給出的結果誤差會平均地比較小。第三，藍色線和黑色虛線之間的差距在樣本量越小時，越明顯。也就是說，同樣因爲小樣本會造成結果有估計誤差，隨機截距模型給出的誤差要相對小一些。</p>
<p>那麼，从計算機的模擬計算結果中，我們學到了什麼？記得圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig01">55.1</a> 中我們見過樣本量越小的池塘的模型結果更加靠近樣本均值的虛線，也就是縮水更加嚴重。但是從計算機模擬的結果來看的話，樣本量越小的池塘的存活概率估計結果是隨機截距模型能給出更加小的誤差估計。這兩個現象並不是偶然發生的。樣本量小的水池，傾向於發生模型的過度擬合 overfitting。由於樣本量較小的水池蘊含的信息量較少，所以它們的模型估計結果更加容易受到樣本均值的影響。也就是被其他樣本量更多的水池的數據的影響。當一個個的水池本身各自的樣本量都相對較多時，你可能會認爲隨機截距或者叫多層回歸模型能給出的估計結果優化就很有限。事實上即便是每個數據層級本身的樣本量也比較大的情況下，使用多層回歸模型來計算也沒有任何壞處。大樣本量的一些層級的估計結果有可能有助於改善較小樣本量層級的結果的預測以及參數的估計結果。所以，平均地看，其實始終應該使用隨機效應模型，也就是部分合併方案的策略，因爲它總是能提供較優的結果估計，而且能夠從數據本身學習獲得應該使用的超參數等用於調節 (regularization) 模型的估計和運行。</p>
<p>下面的代碼有助於我們重複使用已經運行過的模型，減少計算機重複運算的壓力。當你想要重複上述計算機模擬過程的時候，可能會希望讓模型運行其他的模擬數據，採集新的事後分佈樣本：</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-1" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb1051-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-2" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb1051-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-3" tabindex="-1"></a>nponds <span class="ot">&lt;-</span> <span class="dv">60</span></span>
<span id="cb1051-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-4" tabindex="-1"></a>Ni <span class="ot">&lt;-</span> <span class="fu">as.integer</span>( <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">35</span>), <span class="at">each =</span> <span class="dv">15</span> ))</span>
<span id="cb1051-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb1051-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-6" tabindex="-1"></a>a_pond <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( nponds, <span class="at">mean =</span> a, <span class="at">sd =</span> sigma)</span>
<span id="cb1051-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-7" tabindex="-1"></a>dsim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">pond =</span> <span class="dv">1</span><span class="sc">:</span>nponds, </span>
<span id="cb1051-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-8" tabindex="-1"></a>                    <span class="at">Ni =</span> Ni, </span>
<span id="cb1051-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-9" tabindex="-1"></a>                    <span class="at">true_a =</span> a_pond)</span>
<span id="cb1051-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-10" tabindex="-1"></a></span>
<span id="cb1051-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-11" tabindex="-1"></a>dsim<span class="sc">$</span>Si <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( nponds, <span class="at">prob =</span> <span class="fu">inv_logit</span>( dsim<span class="sc">$</span>true_a ), <span class="at">size =</span> dsim<span class="sc">$</span>Ni )</span>
<span id="cb1051-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1051-12" tabindex="-1"></a>dsim<span class="sc">$</span>p_nopool <span class="ot">&lt;-</span>  dsim<span class="sc">$</span>Si <span class="sc">/</span> dsim<span class="sc">$</span>Ni</span></code></pre></div>
<div class="sourceCode" id="cb1052"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1052-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-1" tabindex="-1"></a>newdat <span class="ot">&lt;-</span>  <span class="fu">list</span>(<span class="at">Si =</span> dsim<span class="sc">$</span>Si, </span>
<span id="cb1052-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-2" tabindex="-1"></a>                <span class="at">Ni =</span> dsim<span class="sc">$</span>Ni, </span>
<span id="cb1052-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-3" tabindex="-1"></a>                <span class="at">pond =</span> <span class="dv">1</span><span class="sc">:</span>nponds)</span>
<span id="cb1052-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-4" tabindex="-1"></a></span>
<span id="cb1052-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-5" tabindex="-1"></a>m13<span class="fl">.3</span>new <span class="ot">&lt;-</span> <span class="fu">stan</span>( <span class="at">fit =</span> m13<span class="fl">.30</span><span class="sc">@</span>stanfit, </span>
<span id="cb1052-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-6" tabindex="-1"></a>                  <span class="at">data =</span> newdat, </span>
<span id="cb1052-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-7" tabindex="-1"></a>                  <span class="at">chains =</span> <span class="dv">4</span> )</span>
<span id="cb1052-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1052-8" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.3</span>new, <span class="st">&quot;../Stanfits/m13_3new.rds&quot;</span>)</span></code></pre></div>
<p>一旦你的計算機已經運行好了一個模型，<code>m13.30</code>，那麼假如只需要修改模型的樣本數據，模型結構不需要改變的話，使用上述的方法會大大提升新模型的運行速度，並且保存結果在 <code>m13.3new</code> 裏面。然後你只需要使用類似的方法重新繪製新數據給出的新結果，而不需要每次再重頭運行模型本身。需要重複利用的模型運算結果已經存儲在了每個 stan 模型中的 <code>stanfit</code> 部分。只要給它新的相同變量的數據框，它就能迅速給出新的事後概率分佈結果。這是非常有用的技巧。</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-1" tabindex="-1"></a>m13<span class="fl">.3</span>new <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_3new.rds&quot;</span>)</span>
<span id="cb1053-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-2" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m13<span class="fl">.3</span>new )</span>
<span id="cb1053-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-3" tabindex="-1"></a>dsim<span class="sc">$</span>p_partpool <span class="ot">&lt;-</span> <span class="fu">apply</span>( <span class="fu">inv_logit</span>(post<span class="sc">$</span>a_pond), <span class="dv">2</span>, mean)</span>
<span id="cb1053-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-4" tabindex="-1"></a></span>
<span id="cb1053-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-5" tabindex="-1"></a>dsim <span class="ot">&lt;-</span> dsim <span class="sc">%&gt;%</span> </span>
<span id="cb1053-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-6" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p_true =</span> <span class="fu">inv_logit</span>(true_a),</span>
<span id="cb1053-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-7" tabindex="-1"></a>         <span class="at">nopool_error =</span> <span class="fu">abs</span>(p_nopool <span class="sc">-</span> p_true), </span>
<span id="cb1053-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-8" tabindex="-1"></a>         <span class="at">partpool_erro =</span> <span class="fu">abs</span>(p_partpool <span class="sc">-</span> p_true))</span>
<span id="cb1053-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-9" tabindex="-1"></a></span>
<span id="cb1053-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-10" tabindex="-1"></a><span class="co"># or similarly you can use basic R command</span></span>
<span id="cb1053-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-11" tabindex="-1"></a><span class="co"># nopool_erro &lt;- abs( dsim$p_nopool - dsim$p_true )</span></span>
<span id="cb1053-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-12" tabindex="-1"></a><span class="co"># partpool_erro &lt;- abs( dsim$p_partpool - dsim$p_true )</span></span>
<span id="cb1053-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-13" tabindex="-1"></a></span>
<span id="cb1053-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-14" tabindex="-1"></a></span>
<span id="cb1053-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-15" tabindex="-1"></a><span class="fu">plot</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>, dsim<span class="sc">$</span>nopool_error,</span>
<span id="cb1053-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-16" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;Pond&quot;</span>, </span>
<span id="cb1053-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-17" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;absolute error&quot;</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb1053-18"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-18" tabindex="-1"></a>      <span class="at">col =</span> rangi2, <span class="at">pch =</span> <span class="dv">16</span>, </span>
<span id="cb1053-19"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-19" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>))</span>
<span id="cb1053-20"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-20" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>, dsim<span class="sc">$</span>partpool_erro )</span>
<span id="cb1053-21"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-21" tabindex="-1"></a></span>
<span id="cb1053-22"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-22" tabindex="-1"></a></span>
<span id="cb1053-23"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-23" tabindex="-1"></a><span class="co"># mark posterior mean probability across tanks </span></span>
<span id="cb1053-24"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-24" tabindex="-1"></a>error_avg <span class="ot">&lt;-</span> dsim <span class="sc">%&gt;%</span></span>
<span id="cb1053-25"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-25" tabindex="-1"></a>  <span class="fu">group_by</span>(Ni) <span class="sc">%&gt;%</span> </span>
<span id="cb1053-26"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-26" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">nopool_avg =</span> <span class="fu">mean</span>(nopool_error), </span>
<span id="cb1053-27"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-27" tabindex="-1"></a>            <span class="at">partpool_avg =</span> <span class="fu">mean</span>(partpool_erro))</span>
<span id="cb1053-28"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-28" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">1</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">1</span>], </span>
<span id="cb1053-29"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-29" tabindex="-1"></a>         <span class="dv">16</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">1</span>], </span>
<span id="cb1053-30"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-30" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1053-31"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-31" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">1</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">1</span>], </span>
<span id="cb1053-32"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-32" tabindex="-1"></a>         <span class="dv">16</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">1</span>], </span>
<span id="cb1053-33"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-33" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1053-34"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-34" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">17</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">2</span>], </span>
<span id="cb1053-35"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-35" tabindex="-1"></a>         <span class="dv">32</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">2</span>], </span>
<span id="cb1053-36"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-36" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1053-37"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-37" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">17</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">2</span>], </span>
<span id="cb1053-38"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-38" tabindex="-1"></a>         <span class="dv">32</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">2</span>], </span>
<span id="cb1053-39"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-39" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1053-40"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-40" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">33</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">3</span>], </span>
<span id="cb1053-41"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-41" tabindex="-1"></a>         <span class="dv">46</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">3</span>], </span>
<span id="cb1053-42"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-42" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1053-43"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-43" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">33</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">3</span>], </span>
<span id="cb1053-44"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-44" tabindex="-1"></a>         <span class="dv">46</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">3</span>], </span>
<span id="cb1053-45"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-45" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1053-46"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-46" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">47</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">4</span>], </span>
<span id="cb1053-47"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-47" tabindex="-1"></a>         <span class="dv">60</span>, error_avg<span class="sc">$</span>nopool_avg[<span class="dv">4</span>], </span>
<span id="cb1053-48"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-48" tabindex="-1"></a>         <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1053-49"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-49" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">47</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">4</span>], </span>
<span id="cb1053-50"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-50" tabindex="-1"></a>         <span class="dv">60</span>, error_avg<span class="sc">$</span>partpool_avg[<span class="dv">4</span>], </span>
<span id="cb1053-51"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-51" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb1053-52"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-52" tabindex="-1"></a></span>
<span id="cb1053-53"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-53" tabindex="-1"></a><span class="co"># draw vertical dividers between tank densities</span></span>
<span id="cb1053-54"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-54" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">16.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1053-55"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-55" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">32.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1053-56"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-56" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v =</span> <span class="fl">46.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb1053-57"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-57" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Tiny ponds (5)&#39;</span>)</span>
<span id="cb1053-58"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-58" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">16</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Small ponds (10)&#39;</span>)</span>
<span id="cb1053-59"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-59" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">32</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Medium ponds (25)&#39;</span>)</span>
<span id="cb1053-60"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1053-60" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">46</span> <span class="sc">+</span> <span class="dv">8</span>, <span class="fl">0.6</span>, <span class="st">&#39;Large ponds (35)&#39;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig05"></span>
<img src="bookdown_files/figure-html/introBayes15-fig05-1.png" alt="New data was fed to m13.3 model and generate new posterior estimations." width="816" />
<p class="caption">
圖 55.5: New data was fed to m13.3 model and generate new posterior estimations.
</p>
</div>
</div>
</div>
<div id="使用多於一個類別作爲多層回歸的隨機變量-more-than-one-type-of-cluster" class="section level2 hasAnchor" number="55.3">
<h2><span class="header-section-number">55.3</span> 使用多於一個類別作爲多層回歸的隨機變量 more than one type of cluster<a href="貝葉斯多層回歸模型-multilevel-models.html#使用多於一個類別作爲多層回歸的隨機變量-more-than-one-type-of-cluster" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>我們當然可以在同一個模型中加入更多的 <span class="math inline">\((&gt;1)\)</span> 分層變量。例如我們在 Chapter <a href="貝葉斯廣義線性回歸-bayesian-glm.html#chimpanzees">53.1.1</a> 看到的黑猩猩社會學數據 <code>data(chimpanzees)</code>。</p>
<div class="sourceCode" id="cb1054"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1054-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1054-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;chimpanzees&quot;</span>)</span>
<span id="cb1054-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1054-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> chimpanzees</span>
<span id="cb1054-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1054-3" tabindex="-1"></a><span class="fu">str</span>(d)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    504 obs. of  8 variables:
##  $ actor       : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ recipient   : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ condition   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ block       : int  1 1 1 1 1 1 2 2 2 2 ...
##  $ trial       : int  2 4 6 8 10 12 14 16 18 20 ...
##  $ prosoc_left : int  0 0 1 0 1 1 1 1 0 0 ...
##  $ chose_prosoc: int  1 0 0 1 1 1 0 0 1 1 ...
##  $ pulled_left : int  0 1 0 0 1 1 0 0 0 0 ...</code></pre>
<p>這個數據裏，<code>pulled_left</code> 是從屬於每一頭黑猩猩個體的 (within a cluster of pulls belonging to an individual chimpanzee)。同時呢，這些拉動左側槓桿的行爲其實又是從屬於一個個實驗設計的 <code>block</code> 下的。這些 <code>block</code> 實際標記的是同一天進行的實驗。於是這裏出現了每個觀察數據的結果變量 <code>pulled_left</code> 既從屬於實驗對象 – 黑猩猩個體 (1 to 7)，也從屬於實驗 <code>block</code> (1 to 6) 的現象。所以給黑猩猩個體和實驗 <code>block</code> 同時設置隨機截距也是沒有問題的。這裏我們利用這個特殊的數據來嘗試設計並運行含有兩個隨機截距結構的模型。這樣我們可以使用數據本身蘊含的信息充分學習應有的超參數用於我們已知的部分合併策略 partial pooling，從而提升各個參數的估計結果和效率，並且同時獲得不同的黑猩猩之間的方差，和不同的實驗 <code>block</code> 之間的方差。</p>
<div id="黑猩猩數據的多層回歸模型-multilevel-chimpanzees" class="section level3 hasAnchor" number="55.3.1">
<h3><span class="header-section-number">55.3.1</span> 黑猩猩數據的多層回歸模型 multilevel chimpanzees<a href="貝葉斯多層回歸模型-multilevel-models.html#黑猩猩數據的多層回歸模型-multilevel-chimpanzees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>我們可以直接利用 Chapter <a href="貝葉斯廣義線性回歸-bayesian-glm.html#chimpanzees">53.1.1</a> 一開始設定好的模型，增加 <code>block</code> 的隨機截距：</p>
<p><span class="math display">\[
\begin{aligned}
L_i &amp; \sim \text{Binomial}(1, p_i)  \\
\text{logit}(p_i) &amp; = \alpha_{\text{ACTOR}[i]} + \color{green}{\gamma_{\text{BLOCK}[i]}} + \beta_{\text{TREATMENT}[i]}\\
\beta_j   &amp; \sim \text{Normal}(0, 0.5) \;\;\;\; \text{for } j = 1,\dots, 4\\
\alpha_j  &amp; \sim \text{Normal}(\bar{\alpha}, \sigma_\alpha) \;\;\;\; \text{for } j = 1, \dots, 7 \\
\color{green}{\gamma_j } &amp;\;  \color{green}{\sim \text{Normal}(0, \sigma_\gamma)\;\;\;\;\; \text{for } j = 1, \dots, 6} \\
\bar{\alpha}  &amp; \sim \text{Normal}(0, 1.5) \\
\sigma_\alpha &amp; \sim \text{Exponential} (1) \\
\color{green}{\sigma_\gamma} &amp; \;\color{green}{ \sim \text{Exponential}(1)}
\end{aligned}
\]</span></p>
<p>從模型結構上，我們給不同的分層變量設置了自己的參數向量，對於每隻黑猩猩 <code>actor</code>，我們設定的參數向量是 <span class="math inline">\(\alpha\)</span>，它有7個元素，長度是 7，因爲一共有七隻黑猩猩；實驗的 <code>block</code> 有 6 個，所以它的參數向量長度是 6。這兩個分層變量需要有自己的方差（標準差）參數，也就是 <span class="math inline">\(\sigma_\alpha, \sigma_\gamma\)</span>。要注意的一點是只能給一個總體平均值 <span class="math inline">\(\bar{\alpha}\)</span> 給兩個隨機截距。下面的代碼就可以運行上述模型：</p>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1056-1" tabindex="-1"></a>d <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span> </span>
<span id="cb1056-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1056-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">treatment =</span> <span class="dv">1</span> <span class="sc">+</span> prosoc_left <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>condition)</span>
<span id="cb1056-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1056-3" tabindex="-1"></a><span class="fu">table</span>(d<span class="sc">$</span>treatment)</span></code></pre></div>
<pre><code>## 
##   1   2   3   4 
## 126 126 126 126</code></pre>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1058-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-1" tabindex="-1"></a>dat_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb1058-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-2" tabindex="-1"></a>  <span class="at">pulled_left =</span> d<span class="sc">$</span>pulled_left, </span>
<span id="cb1058-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-3" tabindex="-1"></a>  <span class="at">actor  =</span> d<span class="sc">$</span>actor, </span>
<span id="cb1058-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-4" tabindex="-1"></a>  <span class="at">block_id =</span> d<span class="sc">$</span>block, </span>
<span id="cb1058-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-5" tabindex="-1"></a>  <span class="at">treatment =</span> <span class="fu">as.integer</span>(d<span class="sc">$</span>treatment)</span>
<span id="cb1058-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1058-6" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb1059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1059-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">13</span>) </span>
<span id="cb1059-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-2" tabindex="-1"></a></span>
<span id="cb1059-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-3" tabindex="-1"></a>m13<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1059-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-4" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1059-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-5" tabindex="-1"></a>    pulled_left  <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ) , </span>
<span id="cb1059-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-6" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[actor] <span class="sc">+</span> g[block_id] <span class="sc">+</span> b[treatment], </span>
<span id="cb1059-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-7" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb1059-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-8" tabindex="-1"></a>    <span class="do">## adaptive priors</span></span>
<span id="cb1059-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-9" tabindex="-1"></a>    a[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( a_bar,  sigma_a ), </span>
<span id="cb1059-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-10" tabindex="-1"></a>    g[block_id] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, sigma_g ), </span>
<span id="cb1059-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-11" tabindex="-1"></a>    <span class="do">## hyper-priors </span></span>
<span id="cb1059-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-12" tabindex="-1"></a>    a_bar <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb1059-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-13" tabindex="-1"></a>    sigma_a <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>), </span>
<span id="cb1059-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-14" tabindex="-1"></a>    sigma_g <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb1059-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-15" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span></span>
<span id="cb1059-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-16" tabindex="-1"></a>)</span>
<span id="cb1059-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1059-17" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.4</span>, <span class="st">&quot;../Stanfits/m13_4.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1060-1" tabindex="-1"></a>m13<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_4.rds&quot;</span>)</span>
<span id="cb1060-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1060-2" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.4</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                 mean         sd         5.5%        94.5%     n_eff     Rhat4
## b[1]    -0.127619719 0.30371293 -0.612525116  0.351831861 403.94596 1.0109754
## b[2]     0.408238854 0.30232189 -0.053260952  0.901320472 358.18837 1.0087428
## b[3]    -0.472686499 0.29977648 -0.933074984  0.020725297 325.50478 1.0134452
## b[4]     0.287140550 0.30400142 -0.196915752  0.783449534 314.64426 1.0108916
## a[1]    -0.370040842 0.38111969 -0.956288690  0.250165297 359.95580 1.0120710
## a[2]     4.722208260 1.32508814  3.099312312  6.970585847 441.65568 1.0040650
## a[3]    -0.671017597 0.38087108 -1.286621692 -0.060970107 393.42474 1.0081857
## a[4]    -0.676761827 0.37681820 -1.281970759 -0.079834071 379.66040 1.0108697
## a[5]    -0.362885676 0.37315672 -0.958119173  0.248182788 388.40275 1.0096311
## a[6]     0.572373093 0.37008050 -0.019418355  1.173132021 413.40776 1.0063314
## a[7]     2.109826748 0.45840001  1.380573715  2.851828350 468.89658 1.0065407
## g[1]    -0.156800879 0.22875942 -0.566965710  0.094427404 321.47070 1.0083836
## g[2]     0.038277620 0.19474280 -0.222321524  0.363343586 947.73530 1.0013975
## g[3]     0.055900123 0.19581427 -0.188554858  0.364005505 764.31955 1.0000968
## g[4]     0.011329983 0.17640463 -0.245645460  0.291591789 900.16676 1.0016050
## g[5]    -0.033451700 0.19154418 -0.343860156  0.234539865 821.95378 1.0082556
## g[6]     0.110218541 0.20252666 -0.129571122  0.438377440 760.17843 1.0023356
## a_bar    0.633025847 0.73797175 -0.516031871  1.785298810 700.52766 1.0041607
## sigma_a  2.032605929 0.64825884  1.220010000  3.139888818 570.05539 1.0006796
## sigma_g  0.209456474 0.17425778  0.032948405  0.516423626 252.48113 1.0167476</code></pre>
<p>首先，我們從 <code>n_eff</code> 可以看出各個參數的有效樣本量差別其實較大。這樣的現象在結構複雜的模型進行事後樣本採樣的過程中其實很常見。這可能會有許多不同的原因，其中之一是模型中可能有一個或者幾個在樣本採集時花了較多的時間在某個邊界值附近不停地採集樣本。這裏很顯然就是 <code>sigma_g</code>，它花了很多時間在它的起始值 0 附近不停地採集樣本，它的 <code>Rhat</code> 值也顯然大於 1。這些都是採樣效率低下的信號。</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1062-1" tabindex="-1"></a><span class="fu">precis_plot</span>( <span class="fu">precis</span>(m13<span class="fl">.4</span>, <span class="at">depth =</span> <span class="dv">2</span>) )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig06"></span>
<img src="bookdown_files/figure-html/introBayes15-fig06-1.png" alt="Posterior means and 89% compatibility intervals for m13.4. The greater variation across actors than blocks can be seen immediately in the a and g distributions" width="480" />
<p class="caption">
圖 55.6: Posterior means and 89% compatibility intervals for m13.4. The greater variation across actors than blocks can be seen immediately in the a and g distributions
</p>
</div>
<p>其次，觀察 <code>sigma_a</code> 和 <code>sigma_g</code> 會很容易就發現不同黑猩猩之間的變化顯然比不同天進行實驗的變化要顯著的多。這一現象可以用圖 <a href="貝葉斯多層回歸模型-multilevel-models.html#fig:introBayes15-fig07">55.7</a> 展示得更加清楚。</p>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1063-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m13<span class="fl">.4</span> )</span>
<span id="cb1063-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-2" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>( post<span class="sc">$</span>sigma_a ,</span>
<span id="cb1063-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-3" tabindex="-1"></a>                  <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">4</span>), </span>
<span id="cb1063-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-4" tabindex="-1"></a>                  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">3.8</span>), </span>
<span id="cb1063-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-5" tabindex="-1"></a>                  <span class="at">col =</span> rangi2, </span>
<span id="cb1063-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-6" tabindex="-1"></a>                  <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb1063-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-7" tabindex="-1"></a>                  <span class="at">lwd =</span> <span class="dv">2</span>, </span>
<span id="cb1063-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-8" tabindex="-1"></a>                  <span class="at">xlab =</span> <span class="st">&quot;standard deviation&quot;</span>, </span>
<span id="cb1063-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-9" tabindex="-1"></a>                  <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb1063-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-10" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>( post<span class="sc">$</span>sigma_g , <span class="at">add =</span>  <span class="cn">TRUE</span>, </span>
<span id="cb1063-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-11" tabindex="-1"></a>                  <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb1063-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-12" tabindex="-1"></a></span>
<span id="cb1063-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-13" tabindex="-1"></a><span class="fu">text</span>( <span class="fl">0.8</span>, <span class="fl">02.5</span>, <span class="st">&#39;block&#39;</span>)</span>
<span id="cb1063-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1063-14" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">3</span>, <span class="fl">0.5</span>, <span class="st">&#39;actor&#39;</span>, <span class="at">col =</span> rangi2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig07"></span>
<img src="bookdown_files/figure-html/introBayes15-fig07-1.png" alt="Posterior distributions of the standard deviations of varying intercepts by actor (blue), and block (black)." width="576" />
<p class="caption">
圖 55.7: Posterior distributions of the standard deviations of varying intercepts by actor (blue), and block (black).
</p>
</div>
<p>這也就是說增加不同實驗 <code>block</code> 的隨機截距並沒有讓模型增加的過度擬合的風險。我們來比較一下只有一個黑猩猩隨機截距時的模型和 <code>m13.4</code> 之間的模型信息差別：</p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">14</span>)</span>
<span id="cb1064-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-2" tabindex="-1"></a>m13<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1064-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-3" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1064-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-4" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb1064-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-5" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[actor] <span class="sc">+</span> b[treatment] , </span>
<span id="cb1064-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-6" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb1064-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-7" tabindex="-1"></a>    a[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( a_bar, sigma_a ),</span>
<span id="cb1064-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-8" tabindex="-1"></a>    a_bar <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb1064-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-9" tabindex="-1"></a>    sigma_a <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb1064-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-10" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span></span>
<span id="cb1064-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-11" tabindex="-1"></a>)</span>
<span id="cb1064-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-12" tabindex="-1"></a></span>
<span id="cb1064-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1064-13" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.5</span>, <span class="st">&quot;../Stanfits/m13_5.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1065-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1065-1" tabindex="-1"></a>m13<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_5.rds&quot;</span>)</span>
<span id="cb1065-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1065-2" tabindex="-1"></a><span class="fu">compare</span>(m13<span class="fl">.4</span>, m13<span class="fl">.5</span>)</span></code></pre></div>
<pre><code>##            WAIC        SE      dWAIC       dSE      pWAIC     weight
## m13.5 531.37616 19.126297 0.00000000        NA  8.5921361 0.60655949
## m13.4 532.24191 19.421569 0.86574585 1.6294066 10.6837879 0.39344051</code></pre>
<p>從 <code>m13.4</code> 和 <code>m13.5</code> 兩個模型之間的比較結果來看，即便 <code>m13.4</code> 中多增加了 7 個未知參數，但是 <code>pWAIC</code> 的比較，也就是實際有效參數個數之間的差只有 2。這主要是因爲 <code>block</code> 的事後分佈的方差其實十分接近 0，所以表示這個 <code>block</code> 部分的隨機截距部分增加的參數的實際結果都接近 0。我們的多層回歸模型雖然可以做到增加實驗 <code>block</code> 的隨機截距，但是增加這個隨機截距對模型並沒有顯著的改善，可以說沒有太多幫助。</p>
</div>
</div>
<div id="分散轉換與非中心型先驗概率-divergent-transition-and-non-centered-priors" class="section level2 hasAnchor" number="55.4">
<h2><span class="header-section-number">55.4</span> 分散轉換與非中心型先驗概率 divergent transition and non-centered priors<a href="貝葉斯多層回歸模型-multilevel-models.html#分散轉換與非中心型先驗概率-divergent-transition-and-non-centered-priors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>使用並運行多層回歸模型時，Stan 經常可能送給你一個莫名其妙的警告，類似：</p>
<pre><code>There were 15 divergent transitions after warmup.</code></pre>
<p>具體原因可能有很多，有主要兩種方式來克服這個警告。第一種是使用更多的 burn-in 或者叫做 warm-up，並且調整 Stan 裏的設置採樣跳躍幅度的變量 <code>adapt_delta</code>，它默認是 0.8，把它改成0.9以上（只能是小於1的數值）的數字之後跳躍採集樣本的幅度會縮小一些，從而改善事後樣本採集的代表性，一定程度上可以避免看見上述警告。但是有些多層回歸模型不論你怎麼調整這個跳躍幅度，增加採樣的 burn-in 過程，它始終都無法給出合適的事後樣本分佈。這時候需要使用的技巧是重新改寫你的模型。很多統計學模型你可以轉換思路用別的方式來表達在數學上涵義相同的模型。這個方法又被叫做再參數化 (reparameterize)。</p>
<p>下面是兩個簡單的實例。</p>
<div id="魔鬼的漏斗-the-devils-funnel" class="section level3 hasAnchor" number="55.4.1">
<h3><span class="header-section-number">55.4.1</span> 魔鬼的漏斗 the devil’s funnel<a href="貝葉斯多層回歸模型-multilevel-models.html#魔鬼的漏斗-the-devils-funnel" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>我們不需要用複雜的模型就能體驗到 Stan 給出的分散轉換 divergent transition 警告。假如有兩個簡單的變量 <span class="math inline">\(v, x\)</span> 他們之間的關係是：</p>
<p><span class="math display">\[
\begin{aligned}
v &amp; \sim \text{Normal}(0, 3) \\
x &amp; \sim \text{Normal}(0, \exp(v))
\end{aligned}
\]</span></p>
<p>沒有特別的數據，只有這樣兩個互相有聯繫的聯合分佈需要我們嘗試去採集樣本。這是典型的多層回歸結構模型，因爲變量 <span class="math inline">\(x\)</span> 的方差由另一個變量 <span class="math inline">\(v\)</span> 來決定。這個模型的運行程序如下：</p>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-1" tabindex="-1"></a>m13<span class="fl">.7</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1068-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-2" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1068-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-3" tabindex="-1"></a>    v <span class="sc">~</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">3</span>), </span>
<span id="cb1068-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-4" tabindex="-1"></a>    x <span class="sc">~</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="fu">exp</span>(v))</span>
<span id="cb1068-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-5" tabindex="-1"></a>  ), <span class="at">data =</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="dv">1</span>), <span class="at">chains =</span> <span class="dv">4</span></span>
<span id="cb1068-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-6" tabindex="-1"></a>)</span>
<span id="cb1068-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1068-7" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.7</span>, <span class="st">&quot;../Stanfits/m13_7.rds&quot;</span>)</span></code></pre></div>
<p>你會很顯然看見一連串的警告，叫你去看這個看那個求助啥的：</p>
<pre><code>There were 78 divergent transitions after warmup. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
to find out why this is a problem and how to eliminate them.There were 2 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceededThere were 2 chains where the estimated Bayesian Fraction of Missing Information was low. See
http://mc-stan.org/misc/warnings.html#bfmi-lowExamine the pairs() plot to diagnose sampling problems
The largest R-hat is 1.15, indicating chains have not mixed.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#r-hatBulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#bulk-essTail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<p>這個只有兩個參數需要估計的模型運行給出的事後概率分佈也十分地糟糕，上面的警告中給出了相當多的分散轉換 (divergent transitions) ，下面的模型運行結果總結也給出了特別差勁的 <code>n_eff, Rhat</code>：</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1070-1" tabindex="-1"></a>m13<span class="fl">.7</span> <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_7.rds&quot;</span>)</span>
<span id="cb1070-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1070-2" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.7</span>)</span></code></pre></div>
<pre><code>##          mean          sd         5.5%      94.5%     n_eff     Rhat4
## v   1.7154855   2.3068647   -1.4054807  5.9914017 17.287243 1.1557813
## x -41.8446286 311.2534143 -271.8156635 47.4611106 92.111681 1.0141386</code></pre>
<p>看一下它可憐的採樣軌跡圖 trace plot ：</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1072-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1072-1" tabindex="-1"></a><span class="fu">traceplot_ulam</span>(m13<span class="fl">.7</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig08"></span>
<img src="bookdown_files/figure-html/introBayes15-fig08-1.png" alt="`traceplot(m13.7)`" width="576" />
<p class="caption">
圖 55.8: <code>traceplot(m13.7)</code>
</p>
</div>
<p>我們可以簡單地通過修改模型的構建模式來克服這個問題。因爲變量 <span class="math inline">\(x\)</span> 的方差取決於 <span class="math inline">\(v\)</span>：</p>
<p><span class="math display">\[
x \sim \text{Normal}(0, \exp(v))
\]</span></p>
<p>變量 <span class="math inline">\(v\)</span> 決定了 <span class="math inline">\(x\)</span> 的方差大小，上面的這種模型結構被叫做參數中心化 (centered parameterization)，其涵義就是一個參數的分佈由另一個參數或者多個參數來決定。參數中心化之外的另一種選擇是參數非中心化 (non-centered parameterization)。這個非中心化就是把參數之間的依賴關係保留，但是在寫成模型的時候儘量避免在指定分佈的那行中加入兩個參數。例如可以把 <code>m13.7</code> 的表達式改寫成：</p>
<p><span class="math display">\[
\begin{aligned}
v &amp; \sim \text{Normal}(0, 3) \\
z &amp; \sim \text{Normal}(0, 1) \\
x &amp; = z \exp(v)
\end{aligned}
\]</span></p>
<p>很多人可能一開始不理解爲什麼要這樣寫。但是仔細想想應該不難理解，這其實是我們平時在把觀察值標準化的一個逆向過程。我們在把某個變量標準化的過程是怎樣的？通常是把它減去自己的平均值，然後除以自己的標準差。新產生的變量就是一個均值爲0，標準差是1的標準正（常）態分佈。也就是說，上面的表達式裏，我們通過 <span class="math inline">\(z\)</span>，一個標準正（常）態分佈變量，把 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(v\)</span> 之間的關係串聯起來。<span class="math inline">\(x\)</span> 本身的均值是零，它除以自己的標準差 <span class="math inline">\(\frac{x}{\exp(v)}\)</span> 就成爲了一個標準正（常）態的變量 <span class="math inline">\(z\)</span>。經過這一番等價轉換之後模型變得可以順利在 Stan 裏被運行和採樣了。</p>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-1" tabindex="-1"></a>m13<span class="fl">.7</span>nc <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1073-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-2" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1073-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-3" tabindex="-1"></a>    v <span class="sc">~</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">3</span>), </span>
<span id="cb1073-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-4" tabindex="-1"></a>    z <span class="sc">~</span> <span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1073-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-5" tabindex="-1"></a>    gq<span class="sc">&gt;</span> real[<span class="dv">1</span>]<span class="sc">:</span> x <span class="ot">&lt;&lt;-</span> z<span class="sc">*</span><span class="fu">exp</span>(v)</span>
<span id="cb1073-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-6" tabindex="-1"></a>  ), <span class="at">data =</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="dv">1</span>), <span class="at">chains =</span> <span class="dv">4</span></span>
<span id="cb1073-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-7" tabindex="-1"></a>)</span>
<span id="cb1073-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1073-8" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.7</span>nc, <span class="st">&quot;../Stanfits/m13_7nc.rds&quot;</span>)</span></code></pre></div>
<p>整個世界恢復了安靜。你看模型運行的結果也是正常的了：</p>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1074-1" tabindex="-1"></a>m13<span class="fl">.7</span>nc <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_7nc.rds&quot;</span>)</span>
<span id="cb1074-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1074-2" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.7</span>nc)</span></code></pre></div>
<pre><code>##            mean           sd        5.5%      94.5%     n_eff     Rhat4
## v -0.0287545661   2.95017093  -4.6421334  4.6942797 1267.2926 1.0028912
## z -0.0093817719   0.97405443  -1.5831453  1.4929941 1459.2957 1.0004412
## x  2.5224882198 197.04808870 -22.7731384 20.7557186 1787.5479 1.0006452</code></pre>
<div class="sourceCode" id="cb1076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1076-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1076-1" tabindex="-1"></a><span class="fu">traceplot_ulam</span>(m13<span class="fl">.7</span>nc)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig09"></span>
<img src="bookdown_files/figure-html/introBayes15-fig09-1.png" alt="`traceplot(m13.7nc)`" width="576" />
<p class="caption">
圖 55.9: <code>traceplot(m13.7nc)</code>
</p>
</div>
<p>如果我們把此時採樣成功的 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(v\)</span> 之間繪製散點圖，你就會直觀的看見這個像魔鬼一樣的漏斗的真實形狀：</p>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-1" tabindex="-1"></a>dat.sam <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m13<span class="fl">.7</span>nc)</span>
<span id="cb1077-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-2" tabindex="-1"></a><span class="fu">plot</span>(dat.sam<span class="sc">$</span>x, </span>
<span id="cb1077-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-3" tabindex="-1"></a>     dat.sam<span class="sc">$</span>v, </span>
<span id="cb1077-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-4" tabindex="-1"></a>     <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb1077-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-5" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb1077-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1077-6" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;v&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig10"></span>
<img src="bookdown_files/figure-html/introBayes15-fig10-1.png" alt="The devil's funnel." width="576" />
<p class="caption">
圖 55.10: The devil’s funnel.
</p>
</div>
<p>我們成功地對這樣的近乎畸形的變量實施了轉換數據之後的事後樣本採集。</p>
</div>
<div id="參數非中心化的黑猩猩數據" class="section level3 hasAnchor" number="55.4.2">
<h3><span class="header-section-number">55.4.2</span> 參數非中心化的黑猩猩數據<a href="貝葉斯多層回歸模型-multilevel-models.html#參數非中心化的黑猩猩數據" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>接下來我們來試圖解決黑猩猩數據中使用多層回歸模型時出現的分散轉移 divergent transition 問題。當時我們的 <code>m13.4</code> 試圖給 <code>block</code> 增加隨機效應，當時在設定參數的先驗概率分佈時，設定了兩個參數在相同的行裏，他們也是導致模型運行報警的原因。現在我們可以來試着解決它。</p>
<p><span class="math display">\[
\begin{aligned}
L_i &amp; \sim \text{Binomial}(1, p_i)  \\
\text{logit}(p_i) &amp; = \alpha_{\text{ACTOR}[i]} + \color{green}{\gamma_{\text{BLOCK}[i]}} + \beta_{\text{TREATMENT}[i]}\\
\beta_j   &amp; \sim \text{Normal}(0, 0.5) \;\;\;\; \text{for } j = 1,\dots, 4\\
\alpha_j  &amp; \sim \text{Normal}(\bar{\alpha}, \sigma_\alpha) \;\;\;\; \text{for } j = 1, \dots, 7 \\
\color{green}{\gamma_j } &amp;\;  \color{green}{\sim \text{Normal}(0, \sigma_\gamma)\;\;\;\;\; \text{for } j = 1, \dots, 6} \\
\bar{\alpha}  &amp; \sim \text{Normal}(0, 1.5) \\
\sigma_\alpha &amp; \sim \text{Exponential} (1) \\
\color{green}{\sigma_\gamma} &amp; \;\color{green}{ \sim \text{Exponential}(1)}
\end{aligned}
\]</span></p>
<p>在對模型進行重新參數化之前，我們可以先試着在 Stan 內部嘗試調整 <code>adapt_delta</code> ，它原本默認的大小是 0.95：</p>
<div class="sourceCode" id="cb1078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1078-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1078-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb1078-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1078-2" tabindex="-1"></a>m13<span class="fl">.4</span>b <span class="ot">&lt;-</span> <span class="fu">ulam</span>(m13<span class="fl">.4</span>, <span class="at">chains =</span> <span class="dv">4</span>, </span>
<span id="cb1078-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1078-3" tabindex="-1"></a>               <span class="at">cores =</span> <span class="dv">4</span>, </span>
<span id="cb1078-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1078-4" tabindex="-1"></a>               <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> <span class="fl">0.99</span>))</span>
<span id="cb1078-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1078-5" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.4</span>b, <span class="st">&quot;../Stanfits/m13_4b.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1079-1" tabindex="-1"></a>m13<span class="fl">.4</span>b <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_4b.rds&quot;</span>)</span>
<span id="cb1079-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1079-2" tabindex="-1"></a><span class="fu">divergent</span>(m13<span class="fl">.4</span>b)</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>可見修改這個 <code>adapt_delta</code> 也沒有辦法提升太多，它依然在報錯。當然偶爾也能真的解決問題，實在是在看你的運氣。而且很多時候，即使它不再通過電腦系統警告，它實際採集的事後樣本也是十分低效的。你可以觀察 <code>precis(m13.4b)</code> 給出的 <code>n_eff</code>，也就是有效樣本量其實很多都還是小於500的。實際使用4条獨立採集鏈每條500個獨立樣本的總樣本量應該在2000左右。</p>
<div class="sourceCode" id="cb1081"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1081-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1081-1" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.4</span>b, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                  mean         sd         5.5%        94.5%      n_eff     Rhat4
## b[1]    -0.1572102900 0.30678784 -0.639271495  0.343564769  402.50898 1.0133566
## b[2]     0.3760131051 0.29844899 -0.097009535  0.852948659  438.79219 1.0067294
## b[3]    -0.4949120780 0.30808988 -1.001918025 -0.017546887  418.26237 1.0100785
## b[4]     0.2581843386 0.30676503 -0.246029052  0.754586625  414.13612 1.0107870
## a[1]    -0.3475363401 0.36432862 -0.926144369  0.200724744  437.14385 1.0091803
## a[2]     4.5946727777 1.21993398  3.006558784  6.800638368  619.43260 1.0103146
## a[3]    -0.6335415787 0.36505148 -1.198982995 -0.042148804  389.82795 1.0122092
## a[4]    -0.6393672456 0.36432523 -1.227955826 -0.078705404  464.07412 1.0089550
## a[5]    -0.3338642974 0.37663905 -0.946543034  0.275166346  473.68551 1.0118031
## a[6]     0.5991703820 0.37498622  0.026426968  1.186117279  457.28046 1.0091865
## a[7]     2.1471699790 0.45691772  1.450735749  2.914264702  533.10034 1.0133078
## g[1]    -0.1428730829 0.20044449 -0.525017505  0.070405136  471.73005 1.0111776
## g[2]     0.0387465222 0.15132335 -0.168327269  0.306505379  682.87717 1.0038622
## g[3]     0.0505496597 0.15814008 -0.155178555  0.328932444  767.76580 1.0058225
## g[4]     0.0089953387 0.15486352 -0.230211915  0.257745757 1082.25766 1.0003697
## g[5]    -0.0225651857 0.16089717 -0.292705183  0.227528171 1291.59183 1.0018525
## g[6]     0.0996398014 0.18231717 -0.116919531  0.447152911  506.41514 1.0121506
## a_bar    0.5884998301 0.74455413 -0.641517611  1.727670676  572.43485 1.0061693
## sigma_a  1.9687830785 0.63396246  1.175349730  3.176123372  897.43947 1.0017410
## sigma_g  0.1856985870 0.16517592  0.012759445  0.499172450  233.36486 1.0295059</code></pre>
<p>如果通過修改參數的形式使之去中心化，則能夠大大改善模型的運行。這個模型裏需要修改參數化的主要是這兩行：</p>
<p><span class="math display">\[
\begin{aligned}
\alpha_j &amp; \sim \text{Normal}(\bar\alpha, \sigma_\alpha) &amp; \text{[intercepts for actors]}\\
\gamma_j &amp; \sim \text{Normal}(0, \sigma_\gamma)&amp; \text{[intercepts for blocks]}
\end{aligned}
\]</span></p>
<p>這裏面其實有三個“中心化”的參數：<span class="math inline">\(\bar\alpha, \sigma_\alpha, \sigma_\gamma\)</span>。使用類似 <code>m13.7nc</code> 的方法，我們需要爲他們設定標準化的替代參數：</p>
<p><span class="math display">\[
\begin{aligned}
L_i &amp; \sim \text{Binomial}(1, p_i) \\
\text{logit}(p_i) &amp; = \color{lightblue}{\underbrace{\bar\alpha + z_{\text{ACTOR[i]}}\sigma_\alpha}_{\alpha_\text{ACTOR[i]}}} + \color{lightblue}{\underbrace{x_{\text{BLOCK}[i]}\sigma_\gamma}_{\gamma_\text{BLOCK[i]}}} + \beta_{\text{TREATMENT}[i]} \\
\beta_j &amp; \sim \text{Normal}(0, 0.5), \text{ for } j = 1,\dots,4 \\
\color{lightblue}{z_j} &amp; \color{lightblue}{\; \sim \text{Normal}(0,1)} &amp; \text{[Standardized actor intercepts]} \\
\color{lightblue}{x_j} &amp; \color{lightblue}{\; \sim \text{Normal}(0,1)} &amp; \text{[Standardized block intercepts]} \\
\bar{\alpha} &amp; \sim \text{Normal}(0, 1.5) \\
\sigma_\alpha &amp; \sim \text{Exponential}(1) \\
\sigma_\gamma &amp; \sim \text{Exponential}(1)
\end{aligned}
\]</span></p>
<p>不難發現經過修改厚的模型中向量 <span class="math inline">\(z\)</span> 提供了標準化的 actor 隨機截距，<span class="math inline">\(x\)</span> 提供了標準化的 block 隨機截距。每頭大猩猩 actor 的隨機截距實際被定義爲：</p>
<p><span class="math display">\[
\alpha_j = \bar\alpha + z_j \sigma_\alpha
\]</span></p>
<p>每個實驗區塊 block 的隨機截距被定義爲：</p>
<p><span class="math display">\[
\gamma_j = x_j\sigma_\gamma
\]</span></p>
<p>現在我們來運行這個被重新改寫過的 <code>m13.4</code> 模型：</p>
<div class="sourceCode" id="cb1083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1083-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">13</span>)</span>
<span id="cb1083-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-2" tabindex="-1"></a>m13<span class="fl">.4</span>nc <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb1083-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-3" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb1083-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-4" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>(<span class="dv">1</span>, p), </span>
<span id="cb1083-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-5" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span>  a_bar <span class="sc">+</span> z[actor]<span class="sc">*</span>sigma_a <span class="sc">+</span>    <span class="co"># actor intercepts</span></span>
<span id="cb1083-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-6" tabindex="-1"></a>                x[block_id]<span class="sc">*</span>sigma_g <span class="sc">+</span>        <span class="co"># block intercepts</span></span>
<span id="cb1083-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-7" tabindex="-1"></a>                b[treatment] ,</span>
<span id="cb1083-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-8" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb1083-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-9" tabindex="-1"></a>    z[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="dv">1</span> ),</span>
<span id="cb1083-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-10" tabindex="-1"></a>    x[block_id] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="dv">1</span> ), </span>
<span id="cb1083-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-11" tabindex="-1"></a>    a_bar <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb1083-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-12" tabindex="-1"></a>    sigma_a <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>), </span>
<span id="cb1083-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-13" tabindex="-1"></a>    sigma_g <span class="sc">~</span> <span class="fu">dexp</span>(<span class="dv">1</span>), </span>
<span id="cb1083-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-14" tabindex="-1"></a>    gq<span class="sc">&gt;</span> vector[actor]<span class="sc">:</span> a <span class="ot">&lt;&lt;-</span> a_bar <span class="sc">+</span> z<span class="sc">*</span>sigma_a, </span>
<span id="cb1083-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-15" tabindex="-1"></a>    gq<span class="sc">&gt;</span> vector[block_id]<span class="sc">:</span> g<span class="ot">&lt;&lt;-</span> x<span class="sc">*</span>sigma_g</span>
<span id="cb1083-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-16" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span></span>
<span id="cb1083-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-17" tabindex="-1"></a>)</span>
<span id="cb1083-18"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-18" tabindex="-1"></a></span>
<span id="cb1083-19"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1083-19" tabindex="-1"></a><span class="fu">saveRDS</span>(m13<span class="fl">.4</span>nc, <span class="st">&quot;../Stanfits/m13_4nc.rds&quot;</span>)</span></code></pre></div>
<p><code>m13.4nc</code> 的 <code>n_eff</code> 顯然比 <code>m13.4</code> 改善很多，而且也沒有報錯：</p>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1084-1" tabindex="-1"></a>m13<span class="fl">.4</span>nc <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m13_4nc.rds&quot;</span>)</span>
<span id="cb1084-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1084-2" tabindex="-1"></a><span class="fu">precis</span>(m13<span class="fl">.4</span>nc, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                  mean         sd          5.5%         94.5%      n_eff      Rhat4
## b[1]    -0.1373449475 0.30100329 -0.6152752117  0.3434728833 1109.20149 1.00595881
## b[2]     0.3888674543 0.31027407 -0.0889388119  0.8914549736 1126.93533 1.00365251
## b[3]    -0.4870408411 0.30935145 -0.9839392550  0.0070806699 1149.30896 1.00403385
## b[4]     0.2675311406 0.29608590 -0.2053236335  0.7265043819 1139.59722 1.00422956
## z[1]    -0.5139834523 0.39675770 -1.1678480395  0.0977745452  570.20117 1.01007561
## z[2]     2.1279913179 0.64805501  1.1422861675  3.2224402595  834.76934 1.00325956
## z[3]    -0.6837229179 0.41584942 -1.3577540963 -0.0245178170  569.57612 1.00789383
## z[4]    -0.6869211727 0.40944901 -1.3445954812 -0.0236560772  568.85572 1.00689660
## z[5]    -0.5172173982 0.39191673 -1.1403129550  0.1034563609  590.52189 1.00843504
## z[6]    -0.0016439012 0.36846295 -0.5776370019  0.5809683677  556.94923 1.00899136
## z[7]     0.8286856465 0.45469306  0.1351884604  1.5921906220  577.79040 1.00723877
## x[1]    -0.6899484779 0.92017834 -2.1405682214  0.7927252571 1879.62650 1.00020587
## x[2]     0.1683882817 0.82967260 -1.2074554330  1.4459472568 1988.35621 0.99902014
## x[3]     0.1883825661 0.88729551 -1.3445548516  1.5454719722 1599.57387 0.99934747
## x[4]     0.0736859911 0.87573225 -1.3284010857  1.5004526253 1872.59855 0.99969896
## x[5]    -0.1579854442 0.86476793 -1.5691453644  1.1965664548 1965.01018 1.00022145
## x[6]     0.4404814966 0.83099134 -0.9035996548  1.7467719731 2034.08888 1.00044538
## a_bar    0.5966686669 0.72455365 -0.5512172079  1.7547745106  457.50619 1.01001900
## sigma_a  1.9868039280 0.62475020  1.1935664496  3.0806919070  548.75222 1.01023381
## sigma_g  0.2055282086 0.16780483  0.0170035585  0.5116821942 1035.04896 1.00196218
## g[1]    -0.1659934915 0.21774107 -0.5702435381  0.0761933321 1360.43058 1.00156195
## g[2]     0.0426012678 0.17846856 -0.2168633003  0.3449450507 2239.18753 1.00002541
## g[3]     0.0505519252 0.17811492 -0.1941666909  0.3582976624 1811.46328 0.99948636
## g[4]     0.0143612958 0.17667352 -0.2641923950  0.2970075014 1916.45293 0.99928424
## g[5]    -0.0349256905 0.17496328 -0.3471585015  0.2205464443 1695.10486 1.00045918
## g[6]     0.1072076540 0.19605102 -0.1279119869  0.4622580054 1506.23216 1.00111282
## a[1]    -0.3404283451 0.36533335 -0.9132766082  0.2629761164 1281.86213 1.00166555
## a[2]     4.6517792446 1.26372873  3.0195252176  6.7913091202 1291.08110 1.00269334
## a[3]    -0.6469904859 0.36686590 -1.2332357909 -0.0507023244 1220.56241 1.00349456
## a[4]    -0.6567906671 0.37266026 -1.2479210814 -0.0427601862 1359.97407 1.00534633
## a[5]    -0.3469747466 0.37267807 -0.9282008426  0.2647662951 1230.41847 1.00636946
## a[6]     0.5924776232 0.37474838  0.0034196068  1.2016656784 1213.69242 1.00800165
## a[7]     2.1128718972 0.47064296  1.3943355597  2.8918979665 1700.68726 1.00210149</code></pre>
<p>用圖形來比較 <code>m13.4</code> 和 <code>m13.4nc</code> 二者之間的 <code>n_eff</code> 更加直觀：</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-1" tabindex="-1"></a>precis_c <span class="ot">&lt;-</span> <span class="fu">precis</span>( m13<span class="fl">.4</span>, <span class="at">depth =</span> <span class="dv">2</span> )</span>
<span id="cb1086-2"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-2" tabindex="-1"></a>precis_nc <span class="ot">&lt;-</span> <span class="fu">precis</span>( m13<span class="fl">.4</span>nc, <span class="at">depth =</span> <span class="dv">2</span> )</span>
<span id="cb1086-3"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-3" tabindex="-1"></a>pars <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fu">paste</span>(<span class="st">&quot;a[&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="st">&quot;]&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>), </span>
<span id="cb1086-4"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-4" tabindex="-1"></a>           <span class="fu">paste</span>(<span class="st">&quot;g[&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="st">&quot;]&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>), </span>
<span id="cb1086-5"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-5" tabindex="-1"></a>           <span class="fu">paste</span>(<span class="st">&quot;b[&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="st">&quot;]&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;&quot;</span>), </span>
<span id="cb1086-6"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-6" tabindex="-1"></a>           <span class="st">&quot;a_bar&quot;</span>, <span class="st">&quot;sigma_a&quot;</span>, <span class="st">&quot;sigma_g&quot;</span>)</span>
<span id="cb1086-7"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-7" tabindex="-1"></a></span>
<span id="cb1086-8"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-8" tabindex="-1"></a>neff_table <span class="ot">&lt;-</span> <span class="fu">cbind</span>( precis_c[pars, <span class="st">&quot;n_eff&quot;</span>], </span>
<span id="cb1086-9"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-9" tabindex="-1"></a>                     precis_nc[pars, <span class="st">&quot;n_eff&quot;</span>])</span>
<span id="cb1086-10"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-10" tabindex="-1"></a></span>
<span id="cb1086-11"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-11" tabindex="-1"></a><span class="fu">plot</span>( neff_table, </span>
<span id="cb1086-12"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-12" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">range</span>(neff_table), </span>
<span id="cb1086-13"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-13" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">range</span>(neff_table), </span>
<span id="cb1086-14"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-14" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;n_eff (centered)&quot;</span>, </span>
<span id="cb1086-15"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-15" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;n_eff (non-centered)&quot;</span>, </span>
<span id="cb1086-16"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-16" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>, </span>
<span id="cb1086-17"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-17" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb1086-18"><a href="貝葉斯多層回歸模型-multilevel-models.html#cb1086-18" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes15-fig11"></span>
<img src="bookdown_files/figure-html/introBayes15-fig11-1.png" alt="Comparing the centered (horizontal) and non-centered (vertical) parameerizations of the multilevel chimpanzees model, m13.4. Each point is a parameter. All but two parameters lie above the diagonal, indicating better sampling for the non-centered parameterization." width="576" />
<p class="caption">
圖 55.11: Comparing the centered (horizontal) and non-centered (vertical) parameerizations of the multilevel chimpanzees model, m13.4. Each point is a parameter. All but two parameters lie above the diagonal, indicating better sampling for the non-centered parameterization.
</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/08-Intro-to-Bayes.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
