<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 53 章 貝葉斯廣義線性回歸 Bayesian GLM | 醫學統計學</title>
  <meta name="description" content="第 53 章 貝葉斯廣義線性回歸 Bayesian GLM | 醫學統計學" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="第 53 章 貝葉斯廣義線性回歸 Bayesian GLM | 醫學統計學" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/img/cover.jpg" />
  
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 53 章 貝葉斯廣義線性回歸 Bayesian GLM | 醫學統計學" />
  
  
  <meta name="twitter:image" content="/img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2023-09-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="馬可夫鏈蒙地卡羅-mcmc.html"/>
<link rel="next" href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的統計學筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="prob-intro.html"><a href="prob-intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a>
<ul>
<li class="chapter" data-level="1.1" data-path="prob-intro.html"><a href="prob-intro.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="prob-intro.html"><a href="prob-intro.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="prob-intro.html"><a href="prob-intro.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="expectation.html"><a href="expectation.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="expectation.html"><a href="expectation.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a>
<ul>
<li class="chapter" data-level="5.1" data-path="binomial.html"><a href="binomial.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="binomial.html"><a href="binomial.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="binomial.html"><a href="binomial.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="binomial.html"><a href="binomial.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="normaldistr.html"><a href="normaldistr.html"><i class="fa fa-check"></i><b>7</b> 正（常）態分佈 Normal Distribution</a>
<ul>
<li class="chapter" data-level="7.1" data-path="normaldistr.html"><a href="normaldistr.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="normaldistr.html"><a href="normaldistr.html#正常態分佈"><i class="fa fa-check"></i><b>7.2</b> 正（常）態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="normaldistr.html"><a href="normaldistr.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正（常）態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#泊松分佈的正常態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正（常）態分佈模擬的校正：continuity corrections</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="CLT.html"><a href="CLT.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="inference-basic.html"><a href="inference-basic.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a>
<ul>
<li class="chapter" data-level="9.1" data-path="inference-basic.html"><a href="inference-basic.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="inference-basic.html"><a href="inference-basic.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="inference-basic.html"><a href="inference-basic.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="inference-basic.html"><a href="inference-basic.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a>
<ul>
<li class="chapter" data-level="10.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#概率-vs.-推斷-probability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a>
<ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#inference-practical-05"><i class="fa fa-check"></i><b>13.5</b> Inference Practical 05</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a>
<ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#inference-practical-06"><i class="fa fa-check"></i><b>14.3</b> Inference Practical 06</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a>
<ul>
<li class="chapter" data-level="15.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="hypothesis-test.html"><a href="hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="hypothesis-test.html"><a href="hypothesis-test.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="hypothesis-test.html"><a href="hypothesis-test.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="hypothesis-test.html"><a href="hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="hypothesis-test.html"><a href="hypothesis-test.html#inference-practical-07"><i class="fa fa-check"></i><b>15.8</b> Inference Practical 07</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a>
<ul>
<li class="chapter" data-level="16.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#練習題"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#inference-practical-08"><i class="fa fa-check"></i><b>16.7</b> Inference Practical 08</a>
<ul>
<li class="chapter" data-level="16.7.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="normal-error-models.html"><a href="normal-error-models.html"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="normal-error-models.html"><a href="normal-error-models.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="normal-error-models.html"><a href="normal-error-models.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="normal-error-models.html"><a href="normal-error-models.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="normal-error-models.html"><a href="normal-error-models.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="normal-error-models.html"><a href="normal-error-models.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="normal-error-models.html"><a href="normal-error-models.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="normal-error-models.html"><a href="normal-error-models.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="normal-error-models.html"><a href="normal-error-models.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
<li class="chapter" data-level="17.7" data-path="normal-error-models.html"><a href="normal-error-models.html#inference-practical-09"><i class="fa fa-check"></i><b>17.7</b> Inference Practical 09</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a>
<ul>
<li class="chapter" data-level="18.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#inference-practical-10"><i class="fa fa-check"></i><b>18.5</b> Inference Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a>
<ul>
<li class="chapter" data-level="19.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#practical0"><i class="fa fa-check"></i><b>19.3</b> Inference Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>20</b> 統計推斷總結</a>
<ul>
<li class="chapter" data-level="20.0.1" data-path="summary.html"><a href="summary.html#快速複習"><i class="fa fa-check"></i><b>20.0.1</b> 快速複習</a></li>
<li class="chapter" data-level="20.0.2" data-path="summary.html"><a href="summary.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>20.0.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="20.0.3" data-path="summary.html"><a href="summary.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>20.0.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="21" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>21</b> 探索數據和簡單描述</a>
<ul>
<li class="chapter" data-level="21.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析的流程"><i class="fa fa-check"></i><b>21.1</b> 數據分析的流程</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#研究設計和實施"><i class="fa fa-check"></i><b>21.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="21.1.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析"><i class="fa fa-check"></i><b>21.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據類型"><i class="fa fa-check"></i><b>21.2</b> 數據類型</a></li>
<li class="chapter" data-level="21.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#如何總結並展示數據"><i class="fa fa-check"></i><b>21.3</b> 如何總結並展示數據</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>21.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="21.3.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#連續型變量"><i class="fa fa-check"></i><b>21.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>21.4</b> 數據總結方案：位置，分散，偏度，和峰度</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#位置"><i class="fa fa-check"></i><b>21.4.1</b> 位置</a></li>
<li class="chapter" data-level="21.4.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#分散"><i class="fa fa-check"></i><b>21.4.2</b> 分散</a></li>
<li class="chapter" data-level="21.4.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#偏度-skewness"><i class="fa fa-check"></i><b>21.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="21.4.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#峯度-kurtosis"><i class="fa fa-check"></i><b>21.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>22</b> 信賴區間 confidence intervals</a>
<ul>
<li class="chapter" data-level="22.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#定義"><i class="fa fa-check"></i><b>22.1</b> 定義</a></li>
<li class="chapter" data-level="22.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>22.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="22.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>22.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CImean"><i class="fa fa-check"></i><b>22.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="22.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#AT2-5"><i class="fa fa-check"></i><b>22.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#varCI"><i class="fa fa-check"></i><b>22.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="22.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>22.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="22.8" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>22.8</b> 情況4：求人羣百分比的信賴區間</a>
<ul>
<li class="chapter" data-level="22.8.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#一般原則"><i class="fa fa-check"></i><b>22.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="22.8.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#exactprop"><i class="fa fa-check"></i><b>22.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="22.8.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>22.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CIrate"><i class="fa fa-check"></i><b>22.9</b> 率的信賴區間</a>
<ul>
<li class="chapter" data-level="22.9.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>22.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="22.9.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用正態近似法計算"><i class="fa fa-check"></i><b>22.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="hypo-tests.html"><a href="hypo-tests.html"><i class="fa fa-check"></i><b>23</b> 假設檢驗</a>
<ul>
<li class="chapter" data-level="23.1" data-path="hypo-tests.html"><a href="hypo-tests.html#拋硬幣的例子"><i class="fa fa-check"></i><b>23.1</b> 拋硬幣的例子</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="hypo-tests.html"><a href="hypo-tests.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>23.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="23.1.2" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值的意義"><i class="fa fa-check"></i><b>23.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="23.1.3" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>23.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>23.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="23.3" data-path="hypo-tests.html"><a href="hypo-tests.html#當樣本量較大"><i class="fa fa-check"></i><b>23.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="23.4" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>23.4</b> 二項分佈的正態近似法假設檢驗</a>
<ul>
<li class="chapter" data-level="23.4.1" data-path="hypo-tests.html"><a href="hypo-tests.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>23.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="hypo-tests.html"><a href="hypo-tests.html#AT3-5"><i class="fa fa-check"></i><b>23.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="23.6" data-path="hypo-tests.html"><a href="hypo-tests.html#OneSampleT"><i class="fa fa-check"></i><b>23.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="23.7" data-path="hypo-tests.html"><a href="hypo-tests.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>23.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="association.html"><a href="association.html"><i class="fa fa-check"></i><b>24</b> 相關 association</a>
<ul>
<li class="chapter" data-level="24.1" data-path="association.html"><a href="association.html#背景介紹"><i class="fa fa-check"></i><b>24.1</b> 背景介紹</a></li>
<li class="chapter" data-level="24.2" data-path="association.html"><a href="association.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>24.2</b> 兩個連續型變量的相關分析</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="association.html"><a href="association.html#相關係數的定義"><i class="fa fa-check"></i><b>24.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="24.2.2" data-path="association.html"><a href="association.html#相關係數的性質"><i class="fa fa-check"></i><b>24.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="24.2.3" data-path="association.html"><a href="association.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>24.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="24.2.4" data-path="association.html"><a href="association.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>24.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="24.2.5" data-path="association.html"><a href="association.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>24.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="24.2.6" data-path="association.html"><a href="association.html#相關係數那些事兒"><i class="fa fa-check"></i><b>24.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="24.2.7" data-path="association.html"><a href="association.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>24.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="association.html"><a href="association.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>24.3</b> 二元變量之間的相關性 association between pairs of binary variables</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="association.html"><a href="association.html#or-的信賴區間"><i class="fa fa-check"></i><b>24.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="24.3.2" data-path="association.html"><a href="association.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>24.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="24.3.3" data-path="association.html"><a href="association.html#chisquaretest"><i class="fa fa-check"></i><b>24.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="24.3.4" data-path="association.html"><a href="association.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>24.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="association.html"><a href="association.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>24.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="comparisons.html"><a href="comparisons.html"><i class="fa fa-check"></i><b>25</b> 比較 Comparisons</a>
<ul>
<li class="chapter" data-level="25.1" data-path="comparisons.html"><a href="comparisons.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>25.1</b> 比較兩個均值 comparing two population means</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="comparisons.html"><a href="comparisons.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>25.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="25.1.2" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>25.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="25.1.3" data-path="comparisons.html"><a href="comparisons.html#練習"><i class="fa fa-check"></i><b>25.1.3</b> 練習</a></li>
<li class="chapter" data-level="25.1.4" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>25.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="comparisons.html"><a href="comparisons.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>25.2</b> 兩個人羣的方差比較</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="comparisons.html"><a href="comparisons.html#Ftest"><i class="fa fa-check"></i><b>25.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="25.2.2" data-path="comparisons.html"><a href="comparisons.html#信賴區間"><i class="fa fa-check"></i><b>25.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="comparisons.html"><a href="comparisons.html#比較兩個百分比"><i class="fa fa-check"></i><b>25.3</b> 比較兩個百分比</a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="comparisons.html"><a href="comparisons.html#proportiontest"><i class="fa fa-check"></i><b>25.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="25.3.2" data-path="comparisons.html"><a href="comparisons.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>25.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>26</b> 前提和數據轉換 Assumptions and transformations</a>
<ul>
<li class="chapter" data-level="26.1" data-path="assumptions.html"><a href="assumptions.html#穩健性"><i class="fa fa-check"></i><b>26.1</b> 穩健性</a></li>
<li class="chapter" data-level="26.2" data-path="assumptions.html"><a href="assumptions.html#正態性"><i class="fa fa-check"></i><b>26.2</b> 正態性</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="assumptions.html"><a href="assumptions.html#normalplot"><i class="fa fa-check"></i><b>26.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="assumptions.html"><a href="assumptions.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>26.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="26.4" data-path="assumptions.html"><a href="assumptions.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>26.4</b> 數學冪轉換 power transformations</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="assumptions.html"><a href="assumptions.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>26.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="26.4.2" data-path="assumptions.html"><a href="assumptions.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>26.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="26.4.3" data-path="assumptions.html"><a href="assumptions.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>26.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="26.4.4" data-path="assumptions.html"><a href="assumptions.html#百分比的轉換"><i class="fa fa-check"></i><b>26.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="27" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>27</b> 簡單線性迴歸 Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="27.1" data-path="lm.html"><a href="lm.html#一些背景和術語"><i class="fa fa-check"></i><b>27.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="27.2" data-path="lm.html"><a href="lm.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>27.2</b> 簡單線性迴歸模型 simple linear regression model</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="lm.html"><a href="lm.html#數據-a"><i class="fa fa-check"></i><b>27.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="27.2.2" data-path="lm.html"><a href="lm.html#數據-b"><i class="fa fa-check"></i><b>27.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="lm.html"><a href="lm.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>27.3</b> 區分因變量和預測變量</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="lm.html"><a href="lm.html#meanfunction"><i class="fa fa-check"></i><b>27.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="27.3.2" data-path="lm.html"><a href="lm.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>27.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="27.3.3" data-path="lm.html"><a href="lm.html#defLM"><i class="fa fa-check"></i><b>27.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="27.3.4" data-path="lm.html"><a href="lm.html#殘差-residuals"><i class="fa fa-check"></i><b>27.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="lm.html"><a href="lm.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>27.4</b> 參數的估計 estimation of parameters</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="lm.html"><a href="lm.html#MLEalphabeta"><i class="fa fa-check"></i><b>27.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="lm.html"><a href="lm.html#ResidualVar"><i class="fa fa-check"></i><b>27.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="27.6" data-path="lm.html"><a href="lm.html#growgam"><i class="fa fa-check"></i><b>27.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="27.7" data-path="lm.html"><a href="lm.html#binarylms"><i class="fa fa-check"></i><b>27.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="27.8" data-path="lm.html"><a href="lm.html#exeChol"><i class="fa fa-check"></i><b>27.8</b> LM practical 01</a>
<ul>
<li class="chapter" data-level="27.8.1" data-path="lm.html"><a href="lm.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>27.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="27.8.2" data-path="lm.html"><a href="lm.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>27.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="27.8.3" data-path="lm.html"><a href="lm.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>27.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="27.8.4" data-path="lm.html"><a href="lm.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>27.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="27.8.5" data-path="lm.html"><a href="lm.html#diagnosis"><i class="fa fa-check"></i><b>27.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="OLS.html"><a href="OLS.html"><i class="fa fa-check"></i><b>28</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a>
<ul>
<li class="chapter" data-level="28.1" data-path="OLS.html"><a href="OLS.html#ols-估計量的性質"><i class="fa fa-check"></i><b>28.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="28.2" data-path="OLS.html"><a href="OLS.html#beta"><i class="fa fa-check"></i><b>28.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="OLS.html"><a href="OLS.html#randbeta"><i class="fa fa-check"></i><b>28.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="28.2.2" data-path="OLS.html"><a href="OLS.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>28.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="OLS.html"><a href="OLS.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>28.3</b> 截距和迴歸係數的方差，協方差</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="OLS.html"><a href="OLS.html#centring"><i class="fa fa-check"></i><b>28.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="OLS.html"><a href="OLS.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>28.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="OLS.html"><a href="OLS.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>28.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="28.4.2" data-path="OLS.html"><a href="OLS.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>28.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="28.4.3" data-path="OLS.html"><a href="OLS.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>28.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="28.4.4" data-path="OLS.html"><a href="OLS.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>28.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="OLS.html"><a href="OLS.html#rsquare"><i class="fa fa-check"></i><b>28.5</b> 線性迴歸模型和 Pearson 相關係數</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="OLS.html"><a href="OLS.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>28.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="OLS.html"><a href="OLS.html#t-r2-F"><i class="fa fa-check"></i><b>28.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="28.7" data-path="OLS.html"><a href="OLS.html#lm-practical-02"><i class="fa fa-check"></i><b>28.7</b> LM practical 02</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>29</b> 方差分析 Introduction to Analysis of Variance</a>
<ul>
<li class="chapter" data-level="29.1" data-path="ANOVA.html"><a href="ANOVA.html#背景"><i class="fa fa-check"></i><b>29.1</b> 背景</a></li>
<li class="chapter" data-level="29.2" data-path="ANOVA.html"><a href="ANOVA.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>29.2</b> 簡單線性迴歸模型的方差分析</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="ANOVA.html"><a href="ANOVA.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>29.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="29.2.2" data-path="ANOVA.html"><a href="ANOVA.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>29.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="29.2.3" data-path="ANOVA.html"><a href="ANOVA.html#Rsquare"><i class="fa fa-check"></i><b>29.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="29.2.4" data-path="ANOVA.html"><a href="ANOVA.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>29.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="29.2.5" data-path="ANOVA.html"><a href="ANOVA.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>29.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="29.2.6" data-path="ANOVA.html"><a href="ANOVA.html#lm-Ftest"><i class="fa fa-check"></i><b>29.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="29.2.7" data-path="ANOVA.html"><a href="ANOVA.html#F-t-same"><i class="fa fa-check"></i><b>29.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="ANOVA.html"><a href="ANOVA.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>29.3</b> 分類變量用作預測變量時的 ANOVA</a>
<ul>
<li class="chapter" data-level="29.3.1" data-path="ANOVA.html"><a href="ANOVA.html#一個二分類預測變量"><i class="fa fa-check"></i><b>29.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="29.3.2" data-path="ANOVA.html"><a href="ANOVA.html#一個模型兩種表述"><i class="fa fa-check"></i><b>29.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="29.3.3" data-path="ANOVA.html"><a href="ANOVA.html#分組變量的平方和"><i class="fa fa-check"></i><b>29.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="29.3.4" data-path="ANOVA.html"><a href="ANOVA.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>29.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="ANOVA.html"><a href="ANOVA.html#lm-practical-03"><i class="fa fa-check"></i><b>29.4</b> LM practical 03</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="multivariable-models.html"><a href="multivariable-models.html"><i class="fa fa-check"></i><b>30</b> 多元模型分析 Multivariable Models</a>
<ul>
<li class="chapter" data-level="30.1" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>30.1</b> 兩個預測變量的線性迴歸模型</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="multivariable-models.html"><a href="multivariable-models.html#數學標記法和解釋"><i class="fa fa-check"></i><b>30.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="30.1.2" data-path="multivariable-models.html"><a href="multivariable-models.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>30.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="multivariable-models.html"><a href="multivariable-models.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>30.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="30.3" data-path="multivariable-models.html"><a href="multivariable-models.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>30.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="30.4" data-path="multivariable-models.html"><a href="multivariable-models.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>30.4</b> 偏回歸係數的變化</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="multivariable-models.html"><a href="multivariable-models.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.2" data-path="multivariable-models.html"><a href="multivariable-models.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>30.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.3" data-path="multivariable-models.html"><a href="multivariable-models.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="multivariable-models.html"><a href="multivariable-models.html#confounding"><i class="fa fa-check"></i><b>30.5</b> 混雜 confounding</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="multivariable-models.html"><a href="multivariable-models.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>30.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="30.5.2" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>30.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="30.5.3" data-path="multivariable-models.html"><a href="multivariable-models.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>30.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="multivariable-models.html"><a href="multivariable-models.html#lm-practical-04"><i class="fa fa-check"></i><b>30.6</b> LM practical 04</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html"><i class="fa fa-check"></i><b>31</b> 多元模型分析：矩陣標記與其意義</a>
<ul>
<li class="chapter" data-level="31.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>31.1</b> 線性回歸模型的矩陣/非矩陣標記法</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#模型標記"><i class="fa fa-check"></i><b>31.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#解讀參數"><i class="fa fa-check"></i><b>31.2</b> 解讀參數</a>
<ul>
<li class="chapter" data-level="31.2.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#最小二乘估計"><i class="fa fa-check"></i><b>31.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="31.2.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>31.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="31.2.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#殘差"><i class="fa fa-check"></i><b>31.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="31.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>31.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a>
<ul>
<li class="chapter" data-level="31.3.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>31.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="31.3.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析表格"><i class="fa fa-check"></i><b>31.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="31.3.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#globalsig"><i class="fa fa-check"></i><b>31.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="31.3.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#partialF"><i class="fa fa-check"></i><b>31.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>31.4</b> 添加新變量對迴歸模型的影響</a>
<ul>
<li class="chapter" data-level="31.4.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>31.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="31.4.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>31.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="31.4.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#擬合值的改變"><i class="fa fa-check"></i><b>31.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="31.4.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#決定係數的改變"><i class="fa fa-check"></i><b>31.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="31.4.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#共線性-collinearity"><i class="fa fa-check"></i><b>31.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#實戰演習"><i class="fa fa-check"></i><b>31.5</b> 實戰演習</a>
<ul>
<li class="chapter" data-level="31.5.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>31.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="31.5.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>31.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#lm-practical-05"><i class="fa fa-check"></i><b>31.6</b> LM practical 05</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="lm-diag.html"><a href="lm-diag.html"><i class="fa fa-check"></i><b>32</b> 線性迴歸的模型診斷</a>
<ul>
<li class="chapter" data-level="32.1" data-path="lm-diag.html"><a href="lm-diag.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>32.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="32.2" data-path="lm-diag.html"><a href="lm-diag.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>32.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="32.3" data-path="lm-diag.html"><a href="lm-diag.html#殘差圖"><i class="fa fa-check"></i><b>32.3</b> 殘差圖</a></li>
<li class="chapter" data-level="32.4" data-path="lm-diag.html"><a href="lm-diag.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>32.4</b> 殘差正態圖 normal plot of residuals</a>
<ul>
<li class="chapter" data-level="32.4.1" data-path="lm-diag.html"><a href="lm-diag.html#模型診斷實例"><i class="fa fa-check"></i><b>32.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="32.5" data-path="lm-diag.html"><a href="lm-diag.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>32.5</b> 前提條件的統計學檢驗</a>
<ul>
<li class="chapter" data-level="32.5.1" data-path="lm-diag.html"><a href="lm-diag.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>32.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="32.5.2" data-path="lm-diag.html"><a href="lm-diag.html#非線性關係模型"><i class="fa fa-check"></i><b>32.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="32.6" data-path="lm-diag.html"><a href="lm-diag.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>32.6</b> 異常值，槓桿值，和庫克距離</a>
<ul>
<li class="chapter" data-level="32.6.1" data-path="lm-diag.html"><a href="lm-diag.html#standardres"><i class="fa fa-check"></i><b>32.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="32.6.2" data-path="lm-diag.html"><a href="lm-diag.html#槓桿值-leverage"><i class="fa fa-check"></i><b>32.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="32.6.3" data-path="lm-diag.html"><a href="lm-diag.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>32.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="32.7" data-path="lm-diag.html"><a href="lm-diag.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>32.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
<li class="chapter" data-level="32.8" data-path="lm-diag.html"><a href="lm-diag.html#lm-practical-06"><i class="fa fa-check"></i><b>32.8</b> LM practical 06</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>33</b> 交互作用 Interactions</a>
<ul>
<li class="chapter" data-level="33.1" data-path="interaction.html"><a href="interaction.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>33.1</b> 兩個預測變量之間的線性模型交互作用</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="interaction.html"><a href="interaction.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>33.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="33.1.2" data-path="interaction.html"><a href="interaction.html#interaction-cont-bin"><i class="fa fa-check"></i><b>33.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.3" data-path="interaction.html"><a href="interaction.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.4" data-path="interaction.html"><a href="interaction.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="interaction.html"><a href="interaction.html#lm-practical-07"><i class="fa fa-check"></i><b>33.2</b> LM practical 07</a></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="34" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>34</b> 樣本量計算問題</a>
<ul>
<li class="chapter" data-level="34.1" data-path="sample-size.html"><a href="sample-size.html#背景-1"><i class="fa fa-check"></i><b>34.1</b> 背景</a></li>
<li class="chapter" data-level="34.2" data-path="sample-size.html"><a href="sample-size.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>34.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="34.3" data-path="sample-size.html"><a href="sample-size.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>34.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="34.4" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>34.4</b> 比較兩組之間的百分比 (percentages or proportions)</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>34.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="34.4.2" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>34.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>34.5</b> 比較兩組之間的均值</a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式"><i class="fa fa-check"></i><b>34.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="sample-size.html"><a href="sample-size.html#樣本量計算的調整"><i class="fa fa-check"></i><b>34.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="baseline-adjustment-using-ancova.html"><a href="baseline-adjustment-using-ancova.html"><i class="fa fa-check"></i><b>35</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="36" data-path="robust-intro.html"><a href="robust-intro.html"><i class="fa fa-check"></i><b>36</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="37" data-path="rank-tests.html"><a href="rank-tests.html"><i class="fa fa-check"></i><b>37</b> 基於秩次的非參數檢驗</a>
<ul>
<li class="chapter" data-level="37.1" data-path="rank-tests.html"><a href="rank-tests.html#sign-test"><i class="fa fa-check"></i><b>37.1</b> 符號檢驗 the Sign test</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="rank-tests.html"><a href="rank-tests.html#符號檢驗的特點"><i class="fa fa-check"></i><b>37.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="rank-tests.html"><a href="rank-tests.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>37.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="37.3" data-path="rank-tests.html"><a href="rank-tests.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>37.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="37.4" data-path="rank-tests.html"><a href="rank-tests.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>37.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="37.5" data-path="rank-tests.html"><a href="rank-tests.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>37.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="permutation.html"><a href="permutation.html"><i class="fa fa-check"></i><b>38</b> 排列置換法 Permutation procedures</a>
<ul>
<li class="chapter" data-level="38.1" data-path="permutation.html"><a href="permutation.html#背景介紹-1"><i class="fa fa-check"></i><b>38.1</b> 背景介紹</a></li>
<li class="chapter" data-level="38.2" data-path="permutation.html"><a href="permutation.html#直接上實例"><i class="fa fa-check"></i><b>38.2</b> 直接上實例</a></li>
<li class="chapter" data-level="38.3" data-path="permutation.html"><a href="permutation.html#排列置換法三板斧"><i class="fa fa-check"></i><b>38.3</b> 排列置換法三板斧</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="permutation.html"><a href="permutation.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>38.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="38.3.2" data-path="permutation.html"><a href="permutation.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>38.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="38.3.3" data-path="permutation.html"><a href="permutation.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>38.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="38.3.4" data-path="permutation.html"><a href="permutation.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>38.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="permutation.html"><a href="permutation.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>38.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="38.5" data-path="permutation.html"><a href="permutation.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>38.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>39</b> 自助重抽法 The bootstrap</a>
<ul>
<li class="chapter" data-level="39.1" data-path="bootstrap.html"><a href="bootstrap.html#定義-1"><i class="fa fa-check"></i><b>39.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="the-sandwich-estimator.html"><a href="the-sandwich-estimator.html"><i class="fa fa-check"></i><b>40</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計 Introduction to Bayesian Statistics</b></span></li>
<li class="chapter" data-level="41" data-path="intro-Bayes.html"><a href="intro-Bayes.html"><i class="fa fa-check"></i><b>41</b> 貝葉斯統計入門</a>
<ul>
<li class="chapter" data-level="41.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>41.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="41.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>41.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>41.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="41.2.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>41.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>41.3</b> 貝葉斯推理的統計學實現</a>
<ul>
<li class="chapter" data-level="41.3.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>41.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="41.3.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>41.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="41.3.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#離散概率分佈實例遺傳學分析"><i class="fa fa-check"></i><b>41.3.3</b> 離散概率分佈實例：遺傳學分析</a></li>
<li class="chapter" data-level="41.3.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>41.3.4</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="41.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#practical-intro-to-bayes-01"><i class="fa fa-check"></i><b>41.4</b> Practical Intro-to-Bayes 01</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="single-para-model.html"><a href="single-para-model.html"><i class="fa fa-check"></i><b>42</b> 貝葉斯定理的應用：單一參數模型 Single-parameter models</a>
<ul>
<li class="chapter" data-level="42.1" data-path="single-para-model.html"><a href="single-para-model.html#從二進制數據中估計概率-estimating-a-probability-from-binomial-data"><i class="fa fa-check"></i><b>42.1</b> 從二進制數據中估計概率 Estimating a probability from binomial data</a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="single-para-model.html"><a href="single-para-model.html#事後概率分佈是數據和先驗概率分佈之間的妥協"><i class="fa fa-check"></i><b>42.1.1</b> 事後概率分佈是數據和先驗概率分佈之間的妥協</a></li>
<li class="chapter" data-level="42.1.2" data-path="single-para-model.html"><a href="single-para-model.html#不同先驗概率分佈對事後概率分佈估計的影響"><i class="fa fa-check"></i><b>42.1.2</b> 不同先驗概率分佈對事後概率分佈估計的影響</a></li>
<li class="chapter" data-level="42.1.3" data-path="single-para-model.html"><a href="single-para-model.html#從已知的事後概率分佈中採樣對採集的事後樣本數據轉換"><i class="fa fa-check"></i><b>42.1.3</b> 從已知的事後概率分佈中採樣，對採集的事後樣本數據轉換</a></li>
<li class="chapter" data-level="42.1.4" data-path="single-para-model.html"><a href="single-para-model.html#使用非共軛先驗概率計算事後概率分佈"><i class="fa fa-check"></i><b>42.1.4</b> 使用非共軛先驗概率計算事後概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="single-para-model.html"><a href="single-para-model.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions-in-binomial-data"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions in binomial data</a></li>
<li class="chapter" data-level="42.3" data-path="single-para-model.html"><a href="single-para-model.html#theta-的先驗概率"><i class="fa fa-check"></i><b>42.3</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="single-para-model.html"><a href="single-para-model.html#beta-distribution-intro"><i class="fa fa-check"></i><b>42.3.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="42.3.2" data-path="single-para-model.html"><a href="single-para-model.html#conjugate"><i class="fa fa-check"></i><b>42.3.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="42.4" data-path="single-para-model.html"><a href="single-para-model.html#附贈加量不加價"><i class="fa fa-check"></i><b>42.4</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="42.5" data-path="single-para-model.html"><a href="single-para-model.html#practical-intro-to-bayes-02"><i class="fa fa-check"></i><b>42.5</b> Practical Intro-to-Bayes 02</a>
<ul>
<li class="chapter" data-level="42.5.1" data-path="single-para-model.html"><a href="single-para-model.html#q1-4"><i class="fa fa-check"></i><b>42.5.1</b> Q1</a></li>
<li class="chapter" data-level="42.5.2" data-path="single-para-model.html"><a href="single-para-model.html#q2-3"><i class="fa fa-check"></i><b>42.5.2</b> Q2</a></li>
<li class="chapter" data-level="42.5.3" data-path="single-para-model.html"><a href="single-para-model.html#q3-2"><i class="fa fa-check"></i><b>42.5.3</b> Q3</a></li>
<li class="chapter" data-level="42.5.4" data-path="single-para-model.html"><a href="single-para-model.html#q4"><i class="fa fa-check"></i><b>42.5.4</b> Q4</a></li>
<li class="chapter" data-level="42.5.5" data-path="single-para-model.html"><a href="single-para-model.html#q5"><i class="fa fa-check"></i><b>42.5.5</b> Q5</a></li>
<li class="chapter" data-level="42.5.6" data-path="single-para-model.html"><a href="single-para-model.html#q6"><i class="fa fa-check"></i><b>42.5.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="normal-distr.html"><a href="normal-distr.html"><i class="fa fa-check"></i><b>43</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a>
<ul>
<li class="chapter" data-level="43.1" data-path="normal-distr.html"><a href="normal-distr.html#事後概率的總結方法"><i class="fa fa-check"></i><b>43.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="43.2" data-path="normal-distr.html"><a href="normal-distr.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>43.2</b> 貝葉斯統計推斷中的正態分布</a>
<ul>
<li class="chapter" data-level="43.2.1" data-path="normal-distr.html"><a href="normal-distr.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>43.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="43.3" data-path="normal-distr.html"><a href="normal-distr.html#事後預測分佈-posterior-predictive-distribution"><i class="fa fa-check"></i><b>43.3</b> 事後預測分佈 Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html"><i class="fa fa-check"></i><b>44</b> 其他典型的單一參數模型 Other standard single-parameter models</a>
<ul>
<li class="chapter" data-level="44.1" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#unknownvarBayes"><i class="fa fa-check"></i><b>44.1</b> 正（常）態分佈僅均值已知（方差未知） Normal distribution with known mean but unknown variance</a></li>
<li class="chapter" data-level="44.2" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#泊松分佈模型的貝葉斯思路-poisson-distribution-model-under-bayesian-framework"><i class="fa fa-check"></i><b>44.2</b> 泊松分佈模型的貝葉斯思路 Poisson distribution model under Bayesian framework</a></li>
<li class="chapter" data-level="44.3" data-path="其他典型的單一參數模型-other-standard-single-parameter-models.html"><a href="其他典型的單一參數模型-other-standard-single-parameter-models.html#泊松模型的其他表達形式-poisson-model-parameterized-in-terms-of-rate-and-exposure"><i class="fa fa-check"></i><b>44.3</b> 泊松模型的其他表達形式 poisson model parameterized in terms of rate and exposure</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html"><i class="fa fa-check"></i><b>45</b> 多參數模型 Introduction to multiparameter models</a>
<ul>
<li class="chapter" data-level="45.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#把不需要的噪音參數平均出去-averaging-over-nuisance-parameters"><i class="fa fa-check"></i><b>45.1</b> 把不需要的噪音參數平均出去 Averaging over ‘nuisance parameters’</a></li>
<li class="chapter" data-level="45.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#未知均值也未知方差的正常態分佈數據-normal-data-with-unknown-mean-and-variance"><i class="fa fa-check"></i><b>45.2</b> 未知均值也未知方差的正（常）態分佈數據 normal data with unknown mean and variance</a>
<ul>
<li class="chapter" data-level="45.2.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#無信息先驗概率分佈-noninformative-prior-distribution"><i class="fa fa-check"></i><b>45.2.1</b> 無信息先驗概率分佈 noninformative prior distribution</a></li>
<li class="chapter" data-level="45.2.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#均值的事後邊際概率分佈-marginal-posterior-distribution-of-mu"><i class="fa fa-check"></i><b>45.2.2</b> 均值的事後邊際概率分佈 marginal posterior distribution of <span class="math inline">\(\mu\)</span></a></li>
</ul></li>
<li class="chapter" data-level="45.3" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#r-演示-正常態數據但均值方差均未知"><i class="fa fa-check"></i><b>45.3</b> R 演示 正常態數據但均值方差均未知</a>
<ul>
<li class="chapter" data-level="45.3.1" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#繪製聯合事後密度分佈及均值和方差各自的邊際分佈-visualise-the-joint-and-marginal-densities"><i class="fa fa-check"></i><b>45.3.1</b> 繪製聯合事後密度分佈及均值和方差各自的邊際分佈 visualise the joint and marginal densities</a></li>
<li class="chapter" data-level="45.3.2" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#單獨繪製邊際分佈的每一個部分"><i class="fa fa-check"></i><b>45.3.2</b> 單獨繪製邊際分佈的每一個部分</a></li>
<li class="chapter" data-level="45.3.3" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#繪製事後均值的概率密度分佈"><i class="fa fa-check"></i><b>45.3.3</b> 繪製事後均值的概率密度分佈</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="多參數模型-introduction-to-multiparameter-models.html"><a href="多參數模型-introduction-to-multiparameter-models.html#r-演示-分析二進制數據-bda3-p.74"><i class="fa fa-check"></i><b>45.4</b> R 演示 分析二進制數據 (BDA3 P.74)</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><i class="fa fa-check"></i><b>46</b> 簡單線型回歸模型 - 地心說模型 Linear regression is the geocentric model of applied statistics</a>
<ul>
<li class="chapter" data-level="46.1" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#為什麼正常態分佈是正常的-why-normal-distribution-is-normal"><i class="fa fa-check"></i><b>46.1</b> 為什麼正（常）態分佈是正常的 why normal distribution is normal?</a></li>
<li class="chapter" data-level="46.2" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#身高的高斯模型-gaussian-model-of-height"><i class="fa fa-check"></i><b>46.2</b> 身高的高斯模型 Gaussian model of height</a>
<ul>
<li class="chapter" data-level="46.2.1" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#小方格估計法近似事後概率分佈"><i class="fa fa-check"></i><b>46.2.1</b> 小方格估計法近似事後概率分佈</a></li>
<li class="chapter" data-level="46.2.2" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#從計算獲得的事後概率分佈中採樣"><i class="fa fa-check"></i><b>46.2.2</b> 從計算獲得的事後概率分佈中採樣</a></li>
<li class="chapter" data-level="46.2.3" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#使用二次方程近似法"><i class="fa fa-check"></i><b>46.2.3</b> 使用二次方程近似法</a></li>
<li class="chapter" data-level="46.2.4" data-path="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="簡單線型回歸模型---地心說模型-linear-regression-is-the-geocentric-model-of-applied-statistics.html#關於-beta-的先驗概率-priors"><i class="fa fa-check"></i><b>46.2.4</b> 關於 <span class="math inline">\(\beta\)</span> 的先驗概率 Priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html"><i class="fa fa-check"></i><b>47</b> 直線和曲線 curves and lines</a>
<ul>
<li class="chapter" data-level="47.1" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html#多項式回歸模型"><i class="fa fa-check"></i><b>47.1</b> 多項式回歸模型</a></li>
<li class="chapter" data-level="47.2" data-path="直線和曲線-curves-and-lines.html"><a href="直線和曲線-curves-and-lines.html#平滑曲線-splines"><i class="fa fa-check"></i><b>47.2</b> 平滑曲線 Splines</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html"><i class="fa fa-check"></i><b>48</b> 多重線性回歸模型 many more variables</a>
<ul>
<li class="chapter" data-level="48.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#waffle"><i class="fa fa-check"></i><b>48.1</b> 虛假的相關性</a></li>
<li class="chapter" data-level="48.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#繪製輔助我們理解的有向無環圖"><i class="fa fa-check"></i><b>48.2</b> 繪製輔助我們理解的有向無環圖</a></li>
<li class="chapter" data-level="48.3" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#多重線性回歸模型的表達"><i class="fa fa-check"></i><b>48.3</b> 多重線性回歸模型的表達</a>
<ul>
<li class="chapter" data-level="48.3.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#預測變量殘差圖-predictor-residual-plots"><i class="fa fa-check"></i><b>48.3.1</b> 預測變量殘差圖 predictor residual plots</a></li>
<li class="chapter" data-level="48.3.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#事後分佈預測圖-posterior-prediction-plots"><i class="fa fa-check"></i><b>48.3.2</b> 事後分佈預測圖 posterior prediction plots</a></li>
<li class="chapter" data-level="48.3.3" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#反現實圖-counterfactual-plots"><i class="fa fa-check"></i><b>48.3.3</b> 反現實圖 counterfactual plots</a></li>
</ul></li>
<li class="chapter" data-level="48.4" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#被掩蓋起來的關係"><i class="fa fa-check"></i><b>48.4</b> 被掩蓋起來的關係</a></li>
<li class="chapter" data-level="48.5" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#分類型變量-categorical-variables"><i class="fa fa-check"></i><b>48.5</b> 分類型變量 categorical variables</a>
<ul>
<li class="chapter" data-level="48.5.1" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#二進制型變量"><i class="fa fa-check"></i><b>48.5.1</b> 二進制型變量</a></li>
<li class="chapter" data-level="48.5.2" data-path="多重線性回歸模型-many-more-variables.html"><a href="多重線性回歸模型-many-more-variables.html#多於兩個分類的分類變量"><i class="fa fa-check"></i><b>48.5.2</b> 多於兩個分類的分類變量</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html"><i class="fa fa-check"></i><b>49</b> 有向無環圖 DAG &amp; 可怕的因果 Causal Terror</a>
<ul>
<li class="chapter" data-level="49.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#multicollinearity"><i class="fa fa-check"></i><b>49.1</b> 多重共線性問題 multicollinearity</a>
<ul>
<li class="chapter" data-level="49.1.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#哺乳動物奶質量數據中的共線性"><i class="fa fa-check"></i><b>49.1.1</b> 哺乳動物奶質量數據中的共線性</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#posttreatbias"><i class="fa fa-check"></i><b>49.2</b> 治療後偏倚 post-treatment bias</a>
<ul>
<li class="chapter" data-level="49.2.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#設定模型"><i class="fa fa-check"></i><b>49.2.1</b> 設定模型</a></li>
</ul></li>
<li class="chapter" data-level="49.3" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#對撞因子偏倚-collider-bias"><i class="fa fa-check"></i><b>49.3</b> 對撞因子偏倚 collider bias</a>
<ul>
<li class="chapter" data-level="49.3.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#虛假的傷心對撞因子-collider-of-false-sorrow"><i class="fa fa-check"></i><b>49.3.1</b> 虛假的傷心對撞因子 collider of false sorrow</a></li>
<li class="chapter" data-level="49.3.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#對撞因子偏倚另一實例未測量變量造成的碰撞偏倚"><i class="fa fa-check"></i><b>49.3.2</b> 對撞因子偏倚另一實例（未測量變量造成的碰撞偏倚）</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#直面混雜效應"><i class="fa fa-check"></i><b>49.4</b> 直面混雜效應</a>
<ul>
<li class="chapter" data-level="49.4.1" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#兩條通路"><i class="fa fa-check"></i><b>49.4.1</b> 兩條通路</a></li>
<li class="chapter" data-level="49.4.2" data-path="有向無環圖-dag-可怕的因果-causal-terror.html"><a href="有向無環圖-dag-可怕的因果-causal-terror.html#華夫餅的後門"><i class="fa fa-check"></i><b>49.4.2</b> 華夫餅的後門</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="50" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html"><i class="fa fa-check"></i><b>50</b> 模型選擇 model selection</a>
<ul>
<li class="chapter" data-level="50.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#預測變量越多越好嗎"><i class="fa fa-check"></i><b>50.1</b> 預測變量越多越好嗎</a>
<ul>
<li class="chapter" data-level="50.1.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#變量越多總是會提高模型的擬合程度"><i class="fa fa-check"></i><b>50.1.1</b> 變量越多總是會提高模型的擬合程度</a></li>
<li class="chapter" data-level="50.1.2" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#也不是預測變量越少越好"><i class="fa fa-check"></i><b>50.1.2</b> 也不是預測變量越少越好</a></li>
</ul></li>
<li class="chapter" data-level="50.2" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#信息熵-information-entropy"><i class="fa fa-check"></i><b>50.2</b> 信息熵 information entropy</a>
<ul>
<li class="chapter" data-level="50.2.1" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#從信息熵到精確度-from-entropy-to-accuracy"><i class="fa fa-check"></i><b>50.2.1</b> 從信息熵到精確度 From entropy to accuracy</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="模型選擇-model-selection.html"><a href="模型選擇-model-selection.html#模型之間的比較"><i class="fa fa-check"></i><b>50.3</b> 模型之間的比較</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html"><i class="fa fa-check"></i><b>51</b> 交互作用 it’s all about interaction</a>
<ul>
<li class="chapter" data-level="51.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#設計一個交互作用模型"><i class="fa fa-check"></i><b>51.1</b> 設計一個交互作用模型</a>
<ul>
<li class="chapter" data-level="51.1.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#設計非洲大陸地形的模型"><i class="fa fa-check"></i><b>51.1.1</b> 設計非洲大陸地形的模型</a></li>
<li class="chapter" data-level="51.1.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#加一個指示變量並不是一個好選擇"><i class="fa fa-check"></i><b>51.1.2</b> 加一個指示變量並不是一個好選擇</a></li>
<li class="chapter" data-level="51.1.3" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#增加交互作用項是有幫助的"><i class="fa fa-check"></i><b>51.1.3</b> 增加交互作用項是有幫助的</a></li>
<li class="chapter" data-level="51.1.4" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#繪製交叉作用"><i class="fa fa-check"></i><b>51.1.4</b> 繪製交叉作用</a></li>
</ul></li>
<li class="chapter" data-level="51.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#連續型變量之間的交互作用"><i class="fa fa-check"></i><b>51.2</b> 連續型變量之間的交互作用</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#winter-flower-冬天的花"><i class="fa fa-check"></i><b>51.2.1</b> Winter flower 冬天的花</a></li>
<li class="chapter" data-level="51.2.2" data-path="交互作用-its-all-about-interaction.html"><a href="交互作用-its-all-about-interaction.html#繪製事後預測圖"><i class="fa fa-check"></i><b>51.2.2</b> 繪製事後預測圖</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="52" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html"><i class="fa fa-check"></i><b>52</b> 馬可夫鏈蒙地卡羅 MCMC</a>
<ul>
<li class="chapter" data-level="52.1" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#國王訪問個各島嶼問題"><i class="fa fa-check"></i><b>52.1</b> 國王訪問個各島嶼問題</a></li>
<li class="chapter" data-level="52.2" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#metropolis-演算法"><i class="fa fa-check"></i><b>52.2</b> Metropolis 演算法</a></li>
<li class="chapter" data-level="52.3" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#簡單的-hmc-hamitonian-monte-carlo-ulam"><i class="fa fa-check"></i><b>52.3</b> 簡單的 HMC (Hamitonian Monte Carlo) <code>ulam</code></a></li>
<li class="chapter" data-level="52.4" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#調教你的模型"><i class="fa fa-check"></i><b>52.4</b> 調教你的模型</a>
<ul>
<li class="chapter" data-level="52.4.1" data-path="馬可夫鏈蒙地卡羅-mcmc.html"><a href="馬可夫鏈蒙地卡羅-mcmc.html#無法被確認的參數-non-identifiable-parameters"><i class="fa fa-check"></i><b>52.4.1</b> 無法被確認的參數 non-identifiable parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="53" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html"><i class="fa fa-check"></i><b>53</b> 貝葉斯廣義線性回歸 Bayesian GLM</a>
<ul>
<li class="chapter" data-level="53.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#二項式回歸模型-binomial-regression"><i class="fa fa-check"></i><b>53.1</b> 二項式回歸模型 binomial regression</a>
<ul>
<li class="chapter" data-level="53.1.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#chimpanzees"><i class="fa fa-check"></i><b>53.1.1</b> 邏輯回歸模型數據實例：prosocial chimpanzees</a></li>
<li class="chapter" data-level="53.1.2" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#相對還是絕對"><i class="fa fa-check"></i><b>53.1.2</b> 相對還是絕對？</a></li>
<li class="chapter" data-level="53.1.3" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#歸納後的二進制數據繼續使用黑猩猩數據"><i class="fa fa-check"></i><b>53.1.3</b> 歸納後的二進制數據：繼續使用黑猩猩數據</a></li>
<li class="chapter" data-level="53.1.4" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#彙總型二進制數據大學錄取數據"><i class="fa fa-check"></i><b>53.1.4</b> 彙總型二進制數據：大學錄取數據</a></li>
</ul></li>
<li class="chapter" data-level="53.2" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸模型-poisson-regression"><i class="fa fa-check"></i><b>53.2</b> 泊松回歸模型 Poisson regression</a>
<ul>
<li class="chapter" data-level="53.2.1" data-path="貝葉斯廣義線性回歸-bayesian-glm.html"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸實例太平洋島國居民使用的工具"><i class="fa fa-check"></i><b>53.2.1</b> 泊松回歸實例：太平洋島國居民使用的工具</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><i class="fa fa-check"></i><b>54</b> 貝葉斯廣義線性回歸模型的擴展 continuous mixture models</a>
<ul>
<li class="chapter" data-level="54.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#beta-二項分佈模型-beta-binomial-model"><i class="fa fa-check"></i><b>54.1</b> Beta 二項分佈模型 beta-binomial model</a></li>
<li class="chapter" data-level="54.2" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#負二項分佈模型伽馬泊松回歸模型-negative-binomialgamma-poisson"><i class="fa fa-check"></i><b>54.2</b> 負二項分佈模型，伽馬泊松回歸模型 Negative-binomial/gamma-Poisson</a></li>
<li class="chapter" data-level="54.3" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#零膨脹模型-zero-inflated-models"><i class="fa fa-check"></i><b>54.3</b> 零膨脹模型 zero-inflated models</a>
<ul>
<li class="chapter" data-level="54.3.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#零膨脹泊松回歸模型-zero-inflated-poisson"><i class="fa fa-check"></i><b>54.3.1</b> 零膨脹泊松回歸模型 zero-inflated Poisson</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#帶順序含義的多類別結果變量-ordered-categorical-outcomes"><i class="fa fa-check"></i><b>54.4</b> 帶順序含義的多類別結果變量 ordered categorical outcomes</a>
<ul>
<li class="chapter" data-level="54.4.1" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#用不同的截距來描述一個有順序的分佈-describing-an-ordered-distribution-with-intercepts"><i class="fa fa-check"></i><b>54.4.1</b> 用不同的截距來描述一個有順序的分佈 describing an ordered distribution with intercepts</a></li>
<li class="chapter" data-level="54.4.2" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#增加預測變量"><i class="fa fa-check"></i><b>54.4.2</b> 增加預測變量</a></li>
</ul></li>
<li class="chapter" data-level="54.5" data-path="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html"><a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html#帶順序含義的多類別預測型變量-ordered-categorical-predictors"><i class="fa fa-check"></i><b>54.5</b> 帶順序含義的多類別預測型變量 ordered categorical predictors</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html"><i class="fa fa-check"></i><b>55</b> 貝葉斯多層回歸模型 multilevel models</a>
<ul>
<li class="chapter" data-level="55.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#多層數據實例蝌蚪和青蛙數據-multilevel-tadpoles"><i class="fa fa-check"></i><b>55.1</b> 多層數據實例：蝌蚪和青蛙數據 multilevel tadpoles</a></li>
<li class="chapter" data-level="55.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#多層回歸的變化的效應和過度擬合過低擬合之間的交易-varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>55.2</b> 多層回歸的變化的效應和過度擬合/過低擬合之間的交易 varying effects and the underfitting/overfitting trade-off</a>
<ul>
<li class="chapter" data-level="55.2.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#用於產生模擬數據的模型-the-model"><i class="fa fa-check"></i><b>55.2.1</b> 用於產生模擬數據的模型 the model</a></li>
<li class="chapter" data-level="55.2.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#模擬存活概率結果-simulate-survivors"><i class="fa fa-check"></i><b>55.2.2</b> 模擬存活概率結果 simulate survivors</a></li>
<li class="chapter" data-level="55.2.3" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#計算完全不合併策略-no-pooling-estimates"><i class="fa fa-check"></i><b>55.2.3</b> 計算完全不合併策略 no-pooling estimates</a></li>
<li class="chapter" data-level="55.2.4" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#計算部分合併策略的結果-partial-pooling-estimates"><i class="fa fa-check"></i><b>55.2.4</b> 計算部分合併策略的結果 partial-pooling estimates</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#使用多於一個類別作爲多層回歸的隨機變量-more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>55.3</b> 使用多於一個類別作爲多層回歸的隨機變量 more than one type of cluster</a>
<ul>
<li class="chapter" data-level="55.3.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#黑猩猩數據的多層回歸模型-multilevel-chimpanzees"><i class="fa fa-check"></i><b>55.3.1</b> 黑猩猩數據的多層回歸模型 multilevel chimpanzees</a></li>
</ul></li>
<li class="chapter" data-level="55.4" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#分散轉換與非中心型先驗概率-divergent-transition-and-non-centered-priors"><i class="fa fa-check"></i><b>55.4</b> 分散轉換與非中心型先驗概率 divergent transition and non-centered priors</a>
<ul>
<li class="chapter" data-level="55.4.1" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#魔鬼的漏斗-the-devils-funnel"><i class="fa fa-check"></i><b>55.4.1</b> 魔鬼的漏斗 the devil’s funnel</a></li>
<li class="chapter" data-level="55.4.2" data-path="貝葉斯多層回歸模型-multilevel-models.html"><a href="貝葉斯多層回歸模型-multilevel-models.html#參數非中心化的黑猩猩數據"><i class="fa fa-check"></i><b>55.4.2</b> 參數非中心化的黑猩猩數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="56" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><i class="fa fa-check"></i><b>56</b> 貝葉斯多層回歸模型2 隨機斜率模型 multilevel models – varying slopes models</a>
<ul>
<li class="chapter" data-level="56.1" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#模擬隨機斜率數據"><i class="fa fa-check"></i><b>56.1</b> 模擬隨機斜率數據</a>
<ul>
<li class="chapter" data-level="56.1.1" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#模擬觀察值-simulate-observations"><i class="fa fa-check"></i><b>56.1.1</b> 模擬觀察值 simulate observations</a></li>
<li class="chapter" data-level="56.1.2" data-path="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html"><a href="貝葉斯多層回歸模型2-隨機斜率模型-multilevel-models-varying-slopes-models.html#隨機斜率模型-the-varying-slopes-model"><i class="fa fa-check"></i><b>56.1.2</b> 隨機斜率模型 the varying slopes model</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="57" data-path="revision.html"><a href="revision.html"><i class="fa fa-check"></i><b>57</b> 重要概念複習</a>
<ul>
<li class="chapter" data-level="57.1" data-path="revision.html"><a href="revision.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>57.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="57.2" data-path="revision.html"><a href="revision.html#似然"><i class="fa fa-check"></i><b>57.2</b> 似然</a></li>
<li class="chapter" data-level="57.3" data-path="revision.html"><a href="revision.html#極大似然估計"><i class="fa fa-check"></i><b>57.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="57.4" data-path="revision.html"><a href="revision.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>57.4</b> 關於假設檢驗的複習</a>
<ul>
<li class="chapter" data-level="57.4.1" data-path="revision.html"><a href="revision.html#子集似然函數"><i class="fa fa-check"></i><b>57.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="57.5" data-path="revision.html"><a href="revision.html#線性迴歸複習"><i class="fa fa-check"></i><b>57.5</b> 線性迴歸複習</a>
<ul>
<li class="chapter" data-level="57.5.1" data-path="revision.html"><a href="revision.html#簡單線性迴歸"><i class="fa fa-check"></i><b>57.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="57.5.2" data-path="revision.html"><a href="revision.html#多元線性迴歸"><i class="fa fa-check"></i><b>57.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="57.5.3" data-path="revision.html"><a href="revision.html#score-equations"><i class="fa fa-check"></i><b>57.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="57.6" data-path="revision.html"><a href="revision.html#glm-practical-01"><i class="fa fa-check"></i><b>57.6</b> GLM-Practical 01</a>
<ul>
<li class="chapter" data-level="57.6.1" data-path="revision.html"><a href="revision.html#建立似然方程"><i class="fa fa-check"></i><b>57.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="57.6.2" data-path="revision.html"><a href="revision.html#建立對數似然方程"><i class="fa fa-check"></i><b>57.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="57.6.3" data-path="revision.html"><a href="revision.html#線性回歸模型"><i class="fa fa-check"></i><b>57.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="57.6.4" data-path="revision.html"><a href="revision.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>57.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="58" data-path="intro-GLM.html"><a href="intro-GLM.html"><i class="fa fa-check"></i><b>58</b> 廣義線性迴歸入門</a>
<ul>
<li class="chapter" data-level="58.1" data-path="intro-GLM.html"><a href="intro-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>58.1</b> 指數分佈家族</a>
<ul>
<li class="chapter" data-level="58.1.1" data-path="intro-GLM.html"><a href="intro-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>58.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="58.1.2" data-path="intro-GLM.html"><a href="intro-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>58.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="58.2" data-path="intro-GLM.html"><a href="intro-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>58.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="58.3" data-path="intro-GLM.html"><a href="intro-GLM.html#注意"><i class="fa fa-check"></i><b>58.3</b> 注意</a></li>
<li class="chapter" data-level="58.4" data-path="intro-GLM.html"><a href="intro-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>58.4</b> 如何在 R 裏擬合 “GLM”</a>
<ul>
<li class="chapter" data-level="58.4.1" data-path="intro-GLM.html"><a href="intro-GLM.html#margins-命令"><i class="fa fa-check"></i><b>58.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="58.4.2" data-path="intro-GLM.html"><a href="intro-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>58.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="intro-GLM.html"><a href="intro-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>58.5</b> GLM-Practical 02</a>
<ul>
<li class="chapter" data-level="58.5.1" data-path="intro-GLM.html"><a href="intro-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>58.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="58.5.2" data-path="intro-GLM.html"><a href="intro-GLM.html#r-練習"><i class="fa fa-check"></i><b>58.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>59</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a>
<ul>
<li class="chapter" data-level="59.1" data-path="logistic.html"><a href="logistic.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>59.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="59.2" data-path="logistic.html"><a href="logistic.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>59.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="59.3" data-path="logistic.html"><a href="logistic.html#logit-or-log"><i class="fa fa-check"></i><b>59.3</b> 注</a>
<ul>
<li class="chapter" data-level="59.3.1" data-path="logistic.html"><a href="logistic.html#exercise.-link-functions."><i class="fa fa-check"></i><b>59.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="59.4" data-path="logistic.html"><a href="logistic.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>59.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="59.5" data-path="logistic.html"><a href="logistic.html#BSEinfection"><i class="fa fa-check"></i><b>59.5</b> 邏輯迴歸實際案例</a>
<ul>
<li class="chapter" data-level="59.5.1" data-path="logistic.html"><a href="logistic.html#分析目的"><i class="fa fa-check"></i><b>59.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="59.5.2" data-path="logistic.html"><a href="logistic.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>59.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="59.5.3" data-path="logistic.html"><a href="logistic.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>59.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="59.6" data-path="logistic.html"><a href="logistic.html#glm-practical-03"><i class="fa fa-check"></i><b>59.6</b> GLM-Practical 03</a>
<ul>
<li class="chapter" data-level="59.6.1" data-path="logistic.html"><a href="logistic.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>59.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="59.6.2" data-path="logistic.html"><a href="logistic.html#哮喘門診數據"><i class="fa fa-check"></i><b>59.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>60</b> 模型比較和擬合優度</a>
<ul>
<li class="chapter" data-level="60.1" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>60.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="60.2" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>60.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="60.3" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>60.3</b> 飽和模型，模型的偏差，擬合優度</a>
<ul>
<li class="chapter" data-level="60.3.1" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>60.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="60.3.2" data-path="model-comparison.html"><a href="model-comparison.html#deviance"><i class="fa fa-check"></i><b>60.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="60.3.3" data-path="model-comparison.html"><a href="model-comparison.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>60.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="model-comparison.html"><a href="model-comparison.html#gof"><i class="fa fa-check"></i><b>60.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="60.5" data-path="model-comparison.html"><a href="model-comparison.html#glm-practical-04"><i class="fa fa-check"></i><b>60.5</b> GLM Practical 04</a>
<ul>
<li class="chapter" data-level="60.5.1" data-path="model-comparison.html"><a href="model-comparison.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>60.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="60.5.2" data-path="model-comparison.html"><a href="model-comparison.html#低出生體重數據"><i class="fa fa-check"></i><b>60.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="count-outcomes.html"><a href="count-outcomes.html"><i class="fa fa-check"></i><b>61</b> 計數型因變量 Count outcomes</a>
<ul>
<li class="chapter" data-level="61.1" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松-glm"><i class="fa fa-check"></i><b>61.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="61.2" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松迴歸實例"><i class="fa fa-check"></i><b>61.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="61.3" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>61.3</b> 過度離散 overdispersion</a>
<ul>
<li class="chapter" data-level="61.3.1" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散怎麼查"><i class="fa fa-check"></i><b>61.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="61.3.2" data-path="count-outcomes.html"><a href="count-outcomes.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>61.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
<li class="chapter" data-level="61.4" data-path="count-outcomes.html"><a href="count-outcomes.html#glm-practical-05"><i class="fa fa-check"></i><b>61.4</b> GLM Practical 05</a></li>
</ul></li>
<li class="chapter" data-level="62" data-path="GLM-rates.html"><a href="GLM-rates.html"><i class="fa fa-check"></i><b>62</b> 率的廣義線性迴歸 Poisson GLM for rates</a>
<ul>
<li class="chapter" data-level="62.1" data-path="GLM-rates.html"><a href="GLM-rates.html#醫學中的率"><i class="fa fa-check"></i><b>62.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="62.2" data-path="GLM-rates.html"><a href="GLM-rates.html#泊松過程"><i class="fa fa-check"></i><b>62.2</b> 泊松過程</a></li>
<li class="chapter" data-level="62.3" data-path="GLM-rates.html"><a href="GLM-rates.html#率的模型"><i class="fa fa-check"></i><b>62.3</b> 率的模型</a></li>
<li class="chapter" data-level="62.4" data-path="GLM-rates.html"><a href="GLM-rates.html#率的-glm"><i class="fa fa-check"></i><b>62.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="62.5" data-path="GLM-rates.html"><a href="GLM-rates.html#分析實例-example-british-doctors-study"><i class="fa fa-check"></i><b>62.5</b> 分析實例 Example: British doctors study</a>
<ul>
<li class="chapter" data-level="62.5.1" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-1-吸菸"><i class="fa fa-check"></i><b>62.5.1</b> 模型 1: 吸菸</a></li>
<li class="chapter" data-level="62.5.2" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-2-吸菸-年齡"><i class="fa fa-check"></i><b>62.5.2</b> 模型 2: 吸菸 + 年齡</a></li>
<li class="chapter" data-level="62.5.3" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-3-吸菸-年齡-吸菸與年齡的交互作用項"><i class="fa fa-check"></i><b>62.5.3</b> 模型 3: 吸菸 + 年齡 + 吸菸與年齡的交互作用項</a></li>
</ul></li>
<li class="chapter" data-level="62.6" data-path="GLM-rates.html"><a href="GLM-rates.html#glm-practical-06"><i class="fa fa-check"></i><b>62.6</b> GLM Practical 06</a>
<ul>
<li class="chapter" data-level="62.6.1" data-path="GLM-rates.html"><a href="GLM-rates.html#將數據導入-r-環境中初步計算每個工廠不同年齡組工人的死亡人數和追蹤人年數據"><i class="fa fa-check"></i><b>62.6.1</b> 將數據導入 R 環境中，初步計算每個工廠不同年齡組工人的死亡人數，和追蹤人年數據。</a></li>
<li class="chapter" data-level="62.6.2" data-path="GLM-rates.html"><a href="GLM-rates.html#計算死亡率的對數值繪製其與年齡組的點圖"><i class="fa fa-check"></i><b>62.6.2</b> 計算死亡率的對數值，繪製其與年齡組的點圖。</a></li>
<li class="chapter" data-level="62.6.3" data-path="GLM-rates.html"><a href="GLM-rates.html#請用數學語言描述死亡率和年齡組之間關係的模型"><i class="fa fa-check"></i><b>62.6.3</b> 請用數學語言描述死亡率和年齡組之間關係的模型。</a></li>
<li class="chapter" data-level="62.6.4" data-path="GLM-rates.html"><a href="GLM-rates.html#接下來的模型中在前面的基礎上加入工廠編號你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異計算年齡調整過後的兩工廠之間死亡率之比和95ci"><i class="fa fa-check"></i><b>62.6.4</b> 接下來的模型中在前面的基礎上加入工廠編號，你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異？計算年齡調整過後的兩工廠之間死亡率之比和95%CI。</a></li>
<li class="chapter" data-level="62.6.5" data-path="GLM-rates.html"><a href="GLM-rates.html#現在在前一步加了工廠變量的基礎上重新擬合模型加入工廠和年齡之間的交互作用項"><i class="fa fa-check"></i><b>62.6.5</b> 現在在前一步加了工廠變量的基礎上，重新擬合模型，加入工廠和年齡之間的交互作用項</a></li>
<li class="chapter" data-level="62.6.6" data-path="GLM-rates.html"><a href="GLM-rates.html#現在把年齡當作連續型變量來考慮擬合下列模型"><i class="fa fa-check"></i><b>62.6.6</b> 現在把年齡當作連續型變量來考慮。擬合下列模型</a></li>
<li class="chapter" data-level="62.6.7" data-path="GLM-rates.html"><a href="GLM-rates.html#計算只有年齡連續型和工廠兩個變量模型時的模型偏差-deviance該模型和第一部分中飽和模型之間相比相差幾個參數parameters你有怎樣的推論"><i class="fa fa-check"></i><b>62.6.7</b> 計算只有年齡(連續型)和工廠兩個變量模型時的模型偏差 (deviance)，該模型和第一部分中飽和模型之間相比相差幾個參數(parameters)？你有怎樣的推論？</a></li>
<li class="chapter" data-level="62.6.8" data-path="GLM-rates.html"><a href="GLM-rates.html#對這個數據進行了這一系列的分析之後你從流行病學的角度來說有怎樣的結論"><i class="fa fa-check"></i><b>62.6.8</b> 對這個數據進行了這一系列的分析之後，你從流行病學的角度來說，有怎樣的結論？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="63" data-path="confounding-interaction.html"><a href="confounding-interaction.html"><i class="fa fa-check"></i><b>63</b> 混雜的調整，交互作用，和模型的可壓縮性</a>
<ul>
<li class="chapter" data-level="63.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#混雜因素的調整"><i class="fa fa-check"></i><b>63.1</b> 混雜因素的調整</a>
<ul>
<li class="chapter" data-level="63.1.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>63.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#交互作用"><i class="fa fa-check"></i><b>63.2</b> 交互作用</a></li>
<li class="chapter" data-level="63.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>63.3</b> 可壓縮性 collapsibility</a>
<ul>
<li class="chapter" data-level="63.3.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>63.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="63.3.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#collapsibility"><i class="fa fa-check"></i><b>63.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="63.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#interaction-depend-scale"><i class="fa fa-check"></i><b>63.4</b> 交互作用對尺度的依賴性</a></li>
<li class="chapter" data-level="63.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#glm-practical-07"><i class="fa fa-check"></i><b>63.5</b> GLM Practical 07</a>
<ul>
<li class="chapter" data-level="63.5.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#使用你熟悉的統計學軟件擬合一個由-fupcontrol-作爲結果變量treat-作爲唯一預測變量的廣義線性回歸模型-根據報告的結果寫一段適用於醫學流行病學文獻雜誌的報告"><i class="fa fa-check"></i><b>63.5.1</b> 使用你熟悉的統計學軟件擬合一個由 <code>fupcontrol</code> 作爲結果變量，<code>treat</code> 作爲唯一預測變量的廣義線性回歸模型。 根據報告的結果，寫一段適用於醫學/流行病學文獻雜誌的報告。</a></li>
<li class="chapter" data-level="63.5.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#分析-treat-和-basecontrol-之間的關係結果是否如你的預期那樣"><i class="fa fa-check"></i><b>63.5.2</b> 分析 <code>treat</code> 和 <code>basecontrol</code> 之間的關係，結果是否如你的預期那樣？</a></li>
<li class="chapter" data-level="63.5.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#已知模型中如果增加調整基線變量可能對-fupcontrol-有一定的預測效果-在你的模型中增加基線血壓控制情況的變量與-m0-的結果-治療效果-treatment-effect參數標準誤-standard-error和-p-值重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述"><i class="fa fa-check"></i><b>63.5.3</b> 已知模型中如果增加調整基線變量可能對 <code>fupcontrol</code> 有一定的預測效果。 在你的模型中增加基線血壓控制情況的變量。與 <code>m0</code> 的結果 (治療效果 treatment effect；參數標準誤 standard error；和 p 值)。重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述。</a></li>
<li class="chapter" data-level="63.5.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#你更推薦使用哪個模型作爲最終主要結果的彙報"><i class="fa fa-check"></i><b>63.5.4</b> 你更推薦使用哪個模型作爲最終主要結果的彙報？</a></li>
<li class="chapter" data-level="63.5.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同爲了回答這個問題請擬合對應的廣義線性回歸模型根據結果回答這個問題"><i class="fa fa-check"></i><b>63.5.5</b> 實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同。爲了回答這個問題，請擬合對應的廣義線性回歸模型。根據結果回答這個問題。</a></li>
<li class="chapter" data-level="63.5.6" data-path="confounding-interaction.html"><a href="confounding-interaction.html#換一個模型先不考慮-basecontrol使用危險度比-risk-ratio-來評價不同治療方案之間的療效"><i class="fa fa-check"></i><b>63.5.6</b> 換一個模型，先不考慮 <code>basecontrol</code>，使用危險度比 (risk ratio) 來評價不同治療方案之間的療效。</a></li>
<li class="chapter" data-level="63.5.7" data-path="confounding-interaction.html"><a href="confounding-interaction.html#在前一模型m4中加入-basecontrol與未加入該變量時模型的輸出結果相比有什麼不同"><i class="fa fa-check"></i><b>63.5.7</b> 在前一模型<code>m4</code>中加入 <code>basecontrol</code>，與未加入該變量時模型的輸出結果相比，有什麼不同？</a></li>
<li class="chapter" data-level="63.5.8" data-path="confounding-interaction.html"><a href="confounding-interaction.html#給上述模型增加交互作用項對於危險度比作爲指標時的交互作用分析結果和使用比值比時相比你有怎樣的思考和結論"><i class="fa fa-check"></i><b>63.5.8</b> 給上述模型增加交互作用項。對於危險度比作爲指標時的交互作用分析結果，和使用比值比時相比，你有怎樣的思考和結論？</a></li>
<li class="chapter" data-level="63.5.9" data-path="confounding-interaction.html"><a href="confounding-interaction.html#如果說不考慮一個rct的統計分析不能在收集完數據之後修改這一事實你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢"><i class="fa fa-check"></i><b>63.5.9</b> 如果說不考慮一個RCT的統計分析不能在收集完數據之後修改這一事實，你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢？</a></li>
<li class="chapter" data-level="63.5.10" data-path="confounding-interaction.html"><a href="confounding-interaction.html#證明危險度比模型是可以壓縮的prove-that-the-log-link-models-are-collapsible."><i class="fa fa-check"></i><b>63.5.10</b> 證明危險度比模型是可以壓縮的。Prove that the log-link models are collapsible.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="64" data-path="epi-logistic.html"><a href="epi-logistic.html"><i class="fa fa-check"></i><b>64</b> 流行病學中的邏輯迴歸</a>
<ul>
<li class="chapter" data-level="64.1" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>64.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="64.2" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3"><i class="fa fa-check"></i><b>64.2</b> 以簡單二進制暴露變量爲例</a>
<ul>
<li class="chapter" data-level="64.2.1" data-path="epi-logistic.html"><a href="epi-logistic.html#先決條件"><i class="fa fa-check"></i><b>64.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="64.2.2" data-path="epi-logistic.html"><a href="epi-logistic.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>64.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="64.2.3" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3-4"><i class="fa fa-check"></i><b>64.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="64.3" data-path="epi-logistic.html"><a href="epi-logistic.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>64.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a>
<ul>
<li class="chapter" data-level="64.3.1" data-path="epi-logistic.html"><a href="epi-logistic.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>64.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="64.3.2" data-path="epi-logistic.html"><a href="epi-logistic.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>64.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="64.3.3" data-path="epi-logistic.html"><a href="epi-logistic.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>64.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="64.4" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>64.4</b> 流行病學研究中變量的調整策略</a></li>
<li class="chapter" data-level="64.5" data-path="epi-logistic.html"><a href="epi-logistic.html#glm-practical-08"><i class="fa fa-check"></i><b>64.5</b> GLM Practical 08</a>
<ul>
<li class="chapter" data-level="64.5.1" data-path="epi-logistic.html"><a href="epi-logistic.html#part-1"><i class="fa fa-check"></i><b>64.5.1</b> Part 1</a></li>
<li class="chapter" data-level="64.5.2" data-path="epi-logistic.html"><a href="epi-logistic.html#part-2"><i class="fa fa-check"></i><b>64.5.2</b> Part 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="GLM-strategy.html"><a href="GLM-strategy.html"><i class="fa fa-check"></i><b>65</b> 分析策略</a>
<ul>
<li class="chapter" data-level="65.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#明確分析目的"><i class="fa fa-check"></i><b>65.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="65.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>65.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a>
<ul>
<li class="chapter" data-level="65.2.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>65.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="65.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>65.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a>
<ul>
<li class="chapter" data-level="65.3.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#不成熟的小策略"><i class="fa fa-check"></i><b>65.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="65.3.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#補充"><i class="fa fa-check"></i><b>65.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="65.4" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>65.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
<li class="chapter" data-level="65.5" data-path="GLM-strategy.html"><a href="GLM-strategy.html#glm-practical-09"><i class="fa fa-check"></i><b>65.5</b> GLM practical 09</a>
<ul>
<li class="chapter" data-level="65.5.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-1-1"><i class="fa fa-check"></i><b>65.5.1</b> Part 1</a></li>
<li class="chapter" data-level="65.5.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-2-1"><i class="fa fa-check"></i><b>65.5.2</b> Part 2</a></li>
<li class="chapter" data-level="65.5.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-3"><i class="fa fa-check"></i><b>65.5.3</b> Part 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="66" data-path="checkingGLM.html"><a href="checkingGLM.html"><i class="fa fa-check"></i><b>66</b> 檢查你的模型 Model Checking - GLM</a>
<ul>
<li class="chapter" data-level="66.1" data-path="checkingGLM.html"><a href="checkingGLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>66.1</b> 線性預測方程的定義</a>
<ul>
<li class="chapter" data-level="66.1.1" data-path="checkingGLM.html"><a href="checkingGLM.html#殘差-1"><i class="fa fa-check"></i><b>66.1.1</b> 殘差</a></li>
<li class="chapter" data-level="66.1.2" data-path="checkingGLM.html"><a href="checkingGLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>66.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="66.1.3" data-path="checkingGLM.html"><a href="checkingGLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>66.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="66.2" data-path="checkingGLM.html"><a href="checkingGLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>66.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="66.3" data-path="checkingGLM.html"><a href="checkingGLM.html#鏈接方程"><i class="fa fa-check"></i><b>66.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="66.4" data-path="checkingGLM.html"><a href="checkingGLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>66.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="66.5" data-path="checkingGLM.html"><a href="checkingGLM.html#practical-10"><i class="fa fa-check"></i><b>66.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="67" data-path="assess-perf.html"><a href="assess-perf.html"><i class="fa fa-check"></i><b>67</b> 評價模型的表現 Assessing model performance</a>
<ul>
<li class="chapter" data-level="67.1" data-path="assess-perf.html"><a href="assess-perf.html#calibration"><i class="fa fa-check"></i><b>67.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="67.2" data-path="assess-perf.html"><a href="assess-perf.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>67.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="67.3" data-path="assess-perf.html"><a href="assess-perf.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>67.3</b> 分辨能力 descrimination</a>
<ul>
<li class="chapter" data-level="67.3.1" data-path="assess-perf.html"><a href="assess-perf.html#敏感度和特異度"><i class="fa fa-check"></i><b>67.3.1</b> 敏感度和特異度</a></li>
</ul></li>
<li class="chapter" data-level="67.4" data-path="assess-perf.html"><a href="assess-perf.html#practical-11"><i class="fa fa-check"></i><b>67.4</b> Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="68" data-path="paired-ana.html"><a href="paired-ana.html"><i class="fa fa-check"></i><b>68</b> 配對實驗數據的分析法</a>
<ul>
<li class="chapter" data-level="68.1" data-path="paired-ana.html"><a href="paired-ana.html#配對的原理"><i class="fa fa-check"></i><b>68.1</b> 配對的原理</a>
<ul>
<li class="chapter" data-level="68.1.1" data-path="paired-ana.html"><a href="paired-ana.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>68.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="68.1.2" data-path="paired-ana.html"><a href="paired-ana.html#控制混雜因素"><i class="fa fa-check"></i><b>68.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="68.2" data-path="paired-ana.html"><a href="paired-ana.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>68.2</b> 結果變量爲連續型變量的配對實驗</a>
<ul>
<li class="chapter" data-level="68.2.1" data-path="paired-ana.html"><a href="paired-ana.html#一般檢驗方法"><i class="fa fa-check"></i><b>68.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="68.2.2" data-path="paired-ana.html"><a href="paired-ana.html#用迴歸法分析"><i class="fa fa-check"></i><b>68.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="68.3" data-path="paired-ana.html"><a href="paired-ana.html#結果變量是二進制變量的配對實驗"><i class="fa fa-check"></i><b>68.3</b> 結果變量是二進制變量的配對實驗</a>
<ul>
<li class="chapter" data-level="68.3.1" data-path="paired-ana.html"><a href="paired-ana.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>68.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="68.3.2" data-path="paired-ana.html"><a href="paired-ana.html#mcnemars-test"><i class="fa fa-check"></i><b>68.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="68.3.3" data-path="paired-ana.html"><a href="paired-ana.html#二進制型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>68.3.3</b> 二進制型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="68.3.4" data-path="paired-ana.html"><a href="paired-ana.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>68.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="paired-ana.html"><a href="paired-ana.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>68.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="69" data-path="conditional-logistic.html"><a href="conditional-logistic.html"><i class="fa fa-check"></i><b>69</b> 條件邏輯迴歸 Conditional logistic regression</a>
<ul>
<li class="chapter" data-level="69.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>69.1</b> 配對實驗的邏輯迴歸模型</a>
<ul>
<li class="chapter" data-level="69.1.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對病例對照研究"><i class="fa fa-check"></i><b>69.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="69.1.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對隊列研究"><i class="fa fa-check"></i><b>69.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="69.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸-二進制暴露變量"><i class="fa fa-check"></i><b>69.2</b> 條件邏輯回歸 – 二進制暴露變量</a>
<ul>
<li class="chapter" data-level="69.2.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>69.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="69.2.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>69.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="69.2.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>69.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="69.2.4" data-path="conditional-logistic.html"><a href="conditional-logistic.html#進一步擴展"><i class="fa fa-check"></i><b>69.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="69.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>69.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="70" data-path="multinomial-logistic.html"><a href="multinomial-logistic.html"><i class="fa fa-check"></i><b>70</b> 多項邏輯回歸 Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="71" data-path="ordinal-logistic.html"><a href="ordinal-logistic.html"><i class="fa fa-check"></i><b>71</b> 順序邏輯回歸 Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="72" data-path="Hierarchical.html"><a href="Hierarchical.html"><i class="fa fa-check"></i><b>72</b> 相互依賴數據及簡單的應對方案</a>
<ul>
<li class="chapter" data-level="72.1" data-path="Hierarchical.html"><a href="Hierarchical.html#相互依賴的數據"><i class="fa fa-check"></i><b>72.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="72.2" data-path="Hierarchical.html"><a href="Hierarchical.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>72.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="72.3" data-path="Hierarchical.html"><a href="Hierarchical.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>72.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="72.4" data-path="Hierarchical.html"><a href="Hierarchical.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>72.4</b> 邊際模型和條件模型 marginal and conditional models</a>
<ul>
<li class="chapter" data-level="72.4.1" data-path="Hierarchical.html"><a href="Hierarchical.html#標記法-notation"><i class="fa fa-check"></i><b>72.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="72.4.2" data-path="Hierarchical.html"><a href="Hierarchical.html#合並每個階層"><i class="fa fa-check"></i><b>72.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="72.4.3" data-path="Hierarchical.html"><a href="Hierarchical.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>72.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="72.4.4" data-path="Hierarchical.html"><a href="Hierarchical.html#分解層級數據"><i class="fa fa-check"></i><b>72.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="72.4.5" data-path="Hierarchical.html"><a href="Hierarchical.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>72.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="72.5" data-path="Hierarchical.html"><a href="Hierarchical.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>72.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="72.6" data-path="Hierarchical.html"><a href="Hierarchical.html#practical-hierarchical-01"><i class="fa fa-check"></i><b>72.6</b> Practical Hierarchical 01</a>
<ul>
<li class="chapter" data-level="72.6.1" data-path="Hierarchical.html"><a href="Hierarchical.html#數據"><i class="fa fa-check"></i><b>72.6.1</b> 數據</a></li>
<li class="chapter" data-level="72.6.2" data-path="Hierarchical.html"><a href="Hierarchical.html#問題"><i class="fa fa-check"></i><b>72.6.2</b> 問題</a></li>
<li class="chapter" data-level="72.6.3" data-path="Hierarchical.html"><a href="Hierarchical.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>72.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="72.6.4" data-path="Hierarchical.html"><a href="Hierarchical.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>72.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="72.6.5" data-path="Hierarchical.html"><a href="Hierarchical.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>72.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="72.6.6" data-path="Hierarchical.html"><a href="Hierarchical.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>72.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="72.6.7" data-path="Hierarchical.html"><a href="Hierarchical.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>72.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="72.6.8" data-path="Hierarchical.html"><a href="Hierarchical.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>72.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="72.6.9" data-path="Hierarchical.html"><a href="Hierarchical.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>72.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="72.6.10" data-path="Hierarchical.html"><a href="Hierarchical.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>72.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="72.6.11" data-path="Hierarchical.html"><a href="Hierarchical.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>72.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="72.6.12" data-path="Hierarchical.html"><a href="Hierarchical.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>72.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="72.6.13" data-path="Hierarchical.html"><a href="Hierarchical.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>72.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="72.6.14" data-path="Hierarchical.html"><a href="Hierarchical.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>72.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="72.6.15" data-path="Hierarchical.html"><a href="Hierarchical.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>72.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="72.6.16" data-path="Hierarchical.html"><a href="Hierarchical.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>72.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="73" data-path="random-intercept.html"><a href="random-intercept.html"><i class="fa fa-check"></i><b>73</b> 隨機截距模型 random intercept model</a>
<ul>
<li class="chapter" data-level="73.1" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>73.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="73.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>73.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="73.3" data-path="random-intercept.html"><a href="random-intercept.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>73.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="73.4" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>73.4</b> 隨機截距模型中的統計推斷</a>
<ul>
<li class="chapter" data-level="73.4.1" data-path="random-intercept.html"><a href="random-intercept.html#fixed-inference"><i class="fa fa-check"></i><b>73.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="73.4.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>73.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="73.5" data-path="random-intercept.html"><a href="random-intercept.html#practical-hierarchical-02"><i class="fa fa-check"></i><b>73.5</b> Practical Hierarchical 02</a>
<ul>
<li class="chapter" data-level="73.5.1" data-path="random-intercept.html"><a href="random-intercept.html#數據-1"><i class="fa fa-check"></i><b>73.5.1</b> 數據</a></li>
<li class="chapter" data-level="73.5.2" data-path="random-intercept.html"><a href="random-intercept.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>73.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="73.5.3" data-path="random-intercept.html"><a href="random-intercept.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>73.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="73.5.4" data-path="random-intercept.html"><a href="random-intercept.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>73.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="73.5.5" data-path="random-intercept.html"><a href="random-intercept.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>73.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="73.5.6" data-path="random-intercept.html"><a href="random-intercept.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>73.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="73.5.7" data-path="random-intercept.html"><a href="random-intercept.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>73.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="73.5.8" data-path="random-intercept.html"><a href="random-intercept.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>73.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="73.5.9" data-path="random-intercept.html"><a href="random-intercept.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>73.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="73.5.10" data-path="random-intercept.html"><a href="random-intercept.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>73.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="73.5.11" data-path="random-intercept.html"><a href="random-intercept.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>73.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="74" data-path="random-inter-cov.html"><a href="random-inter-cov.html"><i class="fa fa-check"></i><b>74</b> 隨機截距模型中加入共變量 random intercept model with covariates</a>
<ul>
<li class="chapter" data-level="74.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>74.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="74.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>74.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="74.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>74.3</b> 賦值予隨機效應成分</a>
<ul>
<li class="chapter" data-level="74.3.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>74.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="74.3.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#eb-預測值"><i class="fa fa-check"></i><b>74.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="74.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>74.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="74.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>74.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="74.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#層內層間效應估計"><i class="fa fa-check"></i><b>74.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="74.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>74.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="74.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#practical-hierarchical-03"><i class="fa fa-check"></i><b>74.8</b> Practical Hierarchical 03</a>
<ul>
<li class="chapter" data-level="74.8.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>74.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="74.8.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>74.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="74.8.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>74.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="74.8.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>74.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="74.8.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>74.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="74.8.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>74.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="74.8.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>74.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="74.8.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>74.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="74.8.9" data-path="random-inter-cov.html"><a href="random-inter-cov.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>74.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="74.8.10" data-path="random-inter-cov.html"><a href="random-inter-cov.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>74.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="74.8.11" data-path="random-inter-cov.html"><a href="random-inter-cov.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>74.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="75" data-path="random-coefficient.html"><a href="random-coefficient.html"><i class="fa fa-check"></i><b>75</b> 隨機回歸系數模型 random coefficient model</a>
<ul>
<li class="chapter" data-level="75.1" data-path="random-coefficient.html"><a href="random-coefficient.html#gcse-scores-實例"><i class="fa fa-check"></i><b>75.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="75.2" data-path="random-coefficient.html"><a href="random-coefficient.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>75.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="75.3" data-path="random-coefficient.html"><a href="random-coefficient.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>75.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="75.4" data-path="random-coefficient.html"><a href="random-coefficient.html#使用模型結果推斷"><i class="fa fa-check"></i><b>75.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="75.5" data-path="random-coefficient.html"><a href="random-coefficient.html#random-var"><i class="fa fa-check"></i><b>75.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="75.6" data-path="random-coefficient.html"><a href="random-coefficient.html#模型效果評估"><i class="fa fa-check"></i><b>75.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="75.7" data-path="random-coefficient.html"><a href="random-coefficient.html#practical-hierarchical-04"><i class="fa fa-check"></i><b>75.7</b> Practical Hierarchical 04</a>
<ul>
<li class="chapter" data-level="75.7.1" data-path="random-coefficient.html"><a href="random-coefficient.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>75.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="75.7.2" data-path="random-coefficient.html"><a href="random-coefficient.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>75.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="75.7.3" data-path="random-coefficient.html"><a href="random-coefficient.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>75.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="75.7.4" data-path="random-coefficient.html"><a href="random-coefficient.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>75.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="75.7.5" data-path="random-coefficient.html"><a href="random-coefficient.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>75.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="75.7.6" data-path="random-coefficient.html"><a href="random-coefficient.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>75.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="75.7.7" data-path="random-coefficient.html"><a href="random-coefficient.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>75.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="75.7.8" data-path="random-coefficient.html"><a href="random-coefficient.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>75.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="75.7.9" data-path="random-coefficient.html"><a href="random-coefficient.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>75.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="75.7.10" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>75.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="75.7.11" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>75.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="longitudinal1.html"><a href="longitudinal1.html"><i class="fa fa-check"></i><b>76</b> 縱向研究數據 longitudinal data 1</a>
<ul>
<li class="chapter" data-level="76.1" data-path="longitudinal1.html"><a href="longitudinal1.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>76.1</b> 固定測量時刻 fixed occasions</a>
<ul>
<li class="chapter" data-level="76.1.1" data-path="longitudinal1.html"><a href="longitudinal1.html#缺失值-missing-data"><i class="fa fa-check"></i><b>76.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="longitudinal1.html"><a href="longitudinal1.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>76.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="76.3" data-path="longitudinal1.html"><a href="longitudinal1.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>76.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="76.4" data-path="longitudinal1.html"><a href="longitudinal1.html#practical-05-hier"><i class="fa fa-check"></i><b>76.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="77" data-path="longitudinal2.html"><a href="longitudinal2.html"><i class="fa fa-check"></i><b>77</b> 縱向研究數據 longitudinal data 2</a>
<ul>
<li class="chapter" data-level="77.1" data-path="longitudinal2.html"><a href="longitudinal2.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>77.1</b> 邊際結構 marginal structures</a>
<ul>
<li class="chapter" data-level="77.1.1" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機截距模型"><i class="fa fa-check"></i><b>77.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="77.1.2" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機系數模型"><i class="fa fa-check"></i><b>77.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="77.2" data-path="longitudinal2.html"><a href="longitudinal2.html#矩陣記法"><i class="fa fa-check"></i><b>77.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="77.3" data-path="longitudinal2.html"><a href="longitudinal2.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>77.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="77.4" data-path="longitudinal2.html"><a href="longitudinal2.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>77.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="77.5" data-path="longitudinal2.html"><a href="longitudinal2.html#其他要點評論"><i class="fa fa-check"></i><b>77.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="77.6" data-path="longitudinal2.html"><a href="longitudinal2.html#不平衡數據"><i class="fa fa-check"></i><b>77.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="77.7" data-path="longitudinal2.html"><a href="longitudinal2.html#practical-06-hier"><i class="fa fa-check"></i><b>77.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="78" data-path="longitudinal3.html"><a href="longitudinal3.html"><i class="fa fa-check"></i><b>78</b> 縱向研究數據 longitudinal data 3</a>
<ul>
<li class="chapter" data-level="78.1" data-path="longitudinal3.html"><a href="longitudinal3.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>78.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="78.2" data-path="longitudinal3.html"><a href="longitudinal3.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>78.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="78.3" data-path="longitudinal3.html"><a href="longitudinal3.html#分析策略"><i class="fa fa-check"></i><b>78.3</b> 分析策略</a>
<ul>
<li class="chapter" data-level="78.3.1" data-path="longitudinal3.html"><a href="longitudinal3.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>78.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="longitudinal3.html"><a href="longitudinal3.html#practical-07-hier"><i class="fa fa-check"></i><b>78.4</b> Practical 07-Hier</a></li>
</ul></li>
<li class="chapter" data-level="79" data-path="廣義估計方程式-generalized-estimating-equation.html"><a href="廣義估計方程式-generalized-estimating-equation.html"><i class="fa fa-check"></i><b>79</b> 廣義估計方程式 Generalized Estimating Equation</a>
<ul>
<li class="chapter" data-level="79.1" data-path="廣義估計方程式-generalized-estimating-equation.html"><a href="廣義估計方程式-generalized-estimating-equation.html#practical-08-hier"><i class="fa fa-check"></i><b>79.1</b> Practical 08-Hier</a></li>
</ul></li>
<li class="chapter" data-level="80" data-path="cluster-ana.html"><a href="cluster-ana.html"><i class="fa fa-check"></i><b>80</b> 聚類分析 Cluster analysis/unsupervised learning</a>
<ul>
<li class="chapter" data-level="80.1" data-path="cluster-ana.html"><a href="cluster-ana.html#聚類分析過程"><i class="fa fa-check"></i><b>80.1</b> 聚類分析過程</a>
<ul>
<li class="chapter" data-level="80.1.1" data-path="cluster-ana.html"><a href="cluster-ana.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>80.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="80.1.2" data-path="cluster-ana.html"><a href="cluster-ana.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>80.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="80.1.3" data-path="cluster-ana.html"><a href="cluster-ana.html#定義分類方法"><i class="fa fa-check"></i><b>80.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="PCA.html"><a href="PCA.html"><i class="fa fa-check"></i><b>81</b> 主成分分析 Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="81.1" data-path="PCA.html"><a href="PCA.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>81.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="81.2" data-path="PCA.html"><a href="PCA.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>81.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="81.3" data-path="PCA.html"><a href="PCA.html#數學推導"><i class="fa fa-check"></i><b>81.3</b> 數學推導</a>
<ul>
<li class="chapter" data-level="81.3.1" data-path="PCA.html"><a href="PCA.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>81.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="81.4" data-path="PCA.html"><a href="PCA.html#主成分分析數據實例"><i class="fa fa-check"></i><b>81.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="81.5" data-path="PCA.html"><a href="PCA.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>81.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a>
<ul>
<li class="chapter" data-level="81.5.1" data-path="PCA.html"><a href="PCA.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>81.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="81.6" data-path="PCA.html"><a href="PCA.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>81.6</b> Cluster analysis/PCA practical</a>
<ul>
<li class="chapter" data-level="81.6.1" data-path="PCA.html"><a href="PCA.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>81.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="82" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html"><i class="fa fa-check"></i><b>82</b> 缺失數據 Missing data 1</a>
<ul>
<li class="chapter" data-level="82.1" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#處理原則建議recommended-principles"><i class="fa fa-check"></i><b>82.1</b> 處理原則（建議）recommended principles</a></li>
<li class="chapter" data-level="82.2" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#缺失數據機制-missingness-mechanisms"><i class="fa fa-check"></i><b>82.2</b> 缺失數據機制 missingness mechanisms</a></li>
<li class="chapter" data-level="82.3" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#臨時解決方案-ad-hoc-approaches"><i class="fa fa-check"></i><b>82.3</b> 臨時解決方案 ad-hoc approaches</a></li>
<li class="chapter" data-level="82.4" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#單一變量的參數多重插補法-parametric-multiple-imputation-of-one-variable"><i class="fa fa-check"></i><b>82.4</b> 單一變量的參數多重插補法 parametric multiple imputation of one variable</a></li>
<li class="chapter" data-level="82.5" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#變量選擇插補次數模型檢查"><i class="fa fa-check"></i><b>82.5</b> 變量選擇，插補次數，模型檢查</a></li>
<li class="chapter" data-level="82.6" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#總結"><i class="fa fa-check"></i><b>82.6</b> 總結</a></li>
<li class="chapter" data-level="82.7" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#practical-10-hier"><i class="fa fa-check"></i><b>82.7</b> Practical 10-Hier</a>
<ul>
<li class="chapter" data-level="82.7.1" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#數據缺失產生的影響缺失機制和多重插補法"><i class="fa fa-check"></i><b>82.7.1</b> 數據缺失產生的影響，缺失機制，和多重插補法</a></li>
<li class="chapter" data-level="82.7.2" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#二進制變量的缺失-class-size-study"><i class="fa fa-check"></i><b>82.7.2</b> 二進制變量的缺失 “class size study”</a></li>
<li class="chapter" data-level="82.7.3" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#完整數據分析結果"><i class="fa fa-check"></i><b>82.7.3</b> 完整數據分析結果</a></li>
<li class="chapter" data-level="82.7.4" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#去除了缺失值的分析結果-complete-case-analysis"><i class="fa fa-check"></i><b>82.7.4</b> 去除了缺失值的分析結果 complete case analysis</a></li>
<li class="chapter" data-level="82.7.5" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#分析-sen_m-的缺失值機制"><i class="fa fa-check"></i><b>82.7.5</b> 分析 <code>sen_m</code> 的缺失值機制</a></li>
<li class="chapter" data-level="82.7.6" data-path="缺失數據-missing-data-1.html"><a href="缺失數據-missing-data-1.html#多重插補-multiple-imputation"><i class="fa fa-check"></i><b>82.7.6</b> 多重插補 multiple imputation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="83" data-path="缺失數據-missing-data-2.html"><a href="缺失數據-missing-data-2.html"><i class="fa fa-check"></i><b>83</b> 缺失數據 Missing data 2</a></li>
<li class="chapter" data-level="84" data-path="further-issues.html"><a href="further-issues.html"><i class="fa fa-check"></i><b>84</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="85" data-path="surv-intro.html"><a href="surv-intro.html"><i class="fa fa-check"></i><b>85</b> 生存分析入門</a>
<ul>
<li class="chapter" data-level="85.1" data-path="surv-intro.html"><a href="surv-intro.html#本章概要"><i class="fa fa-check"></i><b>85.1</b> 本章概要</a></li>
<li class="chapter" data-level="85.2" data-path="surv-intro.html"><a href="surv-intro.html#什麼是生存分析-what-is-survival-analysis"><i class="fa fa-check"></i><b>85.2</b> 什麼是生存分析 What is survival analysis?</a></li>
<li class="chapter" data-level="85.3" data-path="surv-intro.html"><a href="surv-intro.html#生存數據在哪裏"><i class="fa fa-check"></i><b>85.3</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="85.4" data-path="surv-intro.html"><a href="surv-intro.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>85.4</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="85.5" data-path="surv-intro.html"><a href="surv-intro.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>85.5</b> 生存數據的左右截尾</a>
<ul>
<li class="chapter" data-level="85.5.1" data-path="surv-intro.html"><a href="surv-intro.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>85.5.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="85.6" data-path="surv-intro.html"><a href="surv-intro.html#初步分析生存數據"><i class="fa fa-check"></i><b>85.6</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="85.7" data-path="surv-intro.html"><a href="surv-intro.html#初步描述生存數據"><i class="fa fa-check"></i><b>85.7</b> 初步描述生存數據</a>
<ul>
<li class="chapter" data-level="85.7.1" data-path="surv-intro.html"><a href="surv-intro.html#生存方程"><i class="fa fa-check"></i><b>85.7.1</b> 生存方程</a></li>
<li class="chapter" data-level="85.7.2" data-path="surv-intro.html"><a href="surv-intro.html#風險度方程"><i class="fa fa-check"></i><b>85.7.2</b> 風險度方程</a></li>
<li class="chapter" data-level="85.7.3" data-path="surv-intro.html"><a href="surv-intro.html#概率密度方程"><i class="fa fa-check"></i><b>85.7.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="85.7.4" data-path="surv-intro.html"><a href="surv-intro.html#各方程之間的關系"><i class="fa fa-check"></i><b>85.7.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="85.8" data-path="surv-intro.html"><a href="surv-intro.html#生存時間的參數分布"><i class="fa fa-check"></i><b>85.8</b> 生存時間的參數分布</a>
<ul>
<li class="chapter" data-level="85.8.1" data-path="surv-intro.html"><a href="surv-intro.html#exponentialdist"><i class="fa fa-check"></i><b>85.8.1</b> 指數分布</a></li>
<li class="chapter" data-level="85.8.2" data-path="surv-intro.html"><a href="surv-intro.html#weibulldist"><i class="fa fa-check"></i><b>85.8.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="85.9" data-path="surv-intro.html"><a href="surv-intro.html#極大似然法估計"><i class="fa fa-check"></i><b>85.9</b> 極大似然法估計</a></li>
<li class="chapter" data-level="85.10" data-path="surv-intro.html"><a href="surv-intro.html#practical-survival-01"><i class="fa fa-check"></i><b>85.10</b> Practical Survival 01</a>
<ul>
<li class="chapter" data-level="85.10.1" data-path="surv-intro.html"><a href="surv-intro.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>85.10.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="85.10.2" data-path="surv-intro.html"><a href="surv-intro.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>85.10.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="85.10.3" data-path="surv-intro.html"><a href="surv-intro.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>85.10.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="85.10.4" data-path="surv-intro.html"><a href="surv-intro.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>85.10.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="nonparametric.html"><a href="nonparametric.html"><i class="fa fa-check"></i><b>86</b> 非參數法分析生存數據</a>
<ul>
<li class="chapter" data-level="86.1" data-path="nonparametric.html"><a href="nonparametric.html#本章概要-1"><i class="fa fa-check"></i><b>86.1</b> 本章概要</a></li>
<li class="chapter" data-level="86.2" data-path="nonparametric.html"><a href="nonparametric.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>86.2</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="86.3" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>86.3</b> Kaplan-Meier 法分析生存方程</a>
<ul>
<li class="chapter" data-level="86.3.1" data-path="nonparametric.html"><a href="nonparametric.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>86.3.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="86.3.2" data-path="nonparametric.html"><a href="nonparametric.html#當數據中有刪失值"><i class="fa fa-check"></i><b>86.3.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="86.4" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-數據的信賴區間的估計"><i class="fa fa-check"></i><b>86.4</b> Kaplan-Meier 數據的信賴區間的估計</a></li>
<li class="chapter" data-level="86.5" data-path="nonparametric.html"><a href="nonparametric.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>86.5</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="86.6" data-path="nonparametric.html"><a href="nonparametric.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>86.6</b> 兩組之間生存概率的比較</a>
<ul>
<li class="chapter" data-level="86.6.1" data-path="nonparametric.html"><a href="nonparametric.html#the-log-rank-test"><i class="fa fa-check"></i><b>86.6.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="86.7" data-path="nonparametric.html"><a href="nonparametric.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>86.7</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="86.8" data-path="nonparametric.html"><a href="nonparametric.html#關於非參數分析法的一些延伸"><i class="fa fa-check"></i><b>86.8</b> 關於非參數分析法的一些延伸</a></li>
<li class="chapter" data-level="86.9" data-path="nonparametric.html"><a href="nonparametric.html#practical-survival-02"><i class="fa fa-check"></i><b>86.9</b> Practical Survival 02</a>
<ul>
<li class="chapter" data-level="86.9.1" data-path="nonparametric.html"><a href="nonparametric.html#part-1-pbc-數據"><i class="fa fa-check"></i><b>86.9.1</b> Part 1: PBC 數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="87" data-path="surv-reg.html"><a href="surv-reg.html"><i class="fa fa-check"></i><b>87</b> 生存數據中的回歸模型</a>
<ul>
<li class="chapter" data-level="87.1" data-path="surv-reg.html"><a href="surv-reg.html#本章概要-2"><i class="fa fa-check"></i><b>87.1</b> 本章概要</a></li>
<li class="chapter" data-level="87.2" data-path="surv-reg.html"><a href="surv-reg.html#使用參數模型分析生存數據的目的"><i class="fa fa-check"></i><b>87.2</b> 使用參數模型分析生存數據的目的</a></li>
<li class="chapter" data-level="87.3" data-path="surv-reg.html"><a href="surv-reg.html#生存數據的似然方程"><i class="fa fa-check"></i><b>87.3</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="87.4" data-path="surv-reg.html"><a href="surv-reg.html#如何加入解釋變量"><i class="fa fa-check"></i><b>87.4</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="87.5" data-path="surv-reg.html"><a href="surv-reg.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>87.5</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="87.6" data-path="surv-reg.html"><a href="surv-reg.html#weibull-分布"><i class="fa fa-check"></i><b>87.6</b> Weibull 分布</a></li>
<li class="chapter" data-level="87.7" data-path="surv-reg.html"><a href="surv-reg.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>87.7</b> Weibull 和 指數模型的比較</a>
<ul>
<li class="chapter" data-level="87.7.1" data-path="surv-reg.html"><a href="surv-reg.html#繪圖法"><i class="fa fa-check"></i><b>87.7.1</b> 繪圖法</a></li>
<li class="chapter" data-level="87.7.2" data-path="surv-reg.html"><a href="surv-reg.html#統計檢驗法"><i class="fa fa-check"></i><b>87.7.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="87.8" data-path="surv-reg.html"><a href="surv-reg.html#拓展解釋變量類型與個數的參數模型"><i class="fa fa-check"></i><b>87.8</b> 拓展解釋變量（類型與個數）的參數模型</a>
<ul>
<li class="chapter" data-level="87.8.1" data-path="surv-reg.html"><a href="surv-reg.html#當變量是連續型時"><i class="fa fa-check"></i><b>87.8.1</b> 當變量是連續型時</a></li>
<li class="chapter" data-level="87.8.2" data-path="surv-reg.html"><a href="surv-reg.html#多於兩種類型的分類型變量"><i class="fa fa-check"></i><b>87.8.2</b> （多於兩種類型的）分類型變量</a></li>
<li class="chapter" data-level="87.8.3" data-path="surv-reg.html"><a href="surv-reg.html#當你加入了多個解釋變量時"><i class="fa fa-check"></i><b>87.8.3</b> 當你加入了多個解釋變量時</a></li>
</ul></li>
<li class="chapter" data-level="87.9" data-path="surv-reg.html"><a href="surv-reg.html#practical-survival-03"><i class="fa fa-check"></i><b>87.9</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="cox.html"><a href="cox.html"><i class="fa fa-check"></i><b>88</b> Cox 比例風險模型</a>
<ul>
<li class="chapter" data-level="88.1" data-path="cox.html"><a href="cox.html#本章概要-3"><i class="fa fa-check"></i><b>88.1</b> 本章概要</a></li>
<li class="chapter" data-level="88.2" data-path="cox.html"><a href="cox.html#初步介紹-cox-比例風險模型"><i class="fa fa-check"></i><b>88.2</b> 初步介紹 Cox 比例風險模型</a></li>
<li class="chapter" data-level="88.3" data-path="cox.html"><a href="cox.html#偏似然法-partial-likelihood"><i class="fa fa-check"></i><b>88.3</b> 偏似然法 (partial likelihood)</a>
<ul>
<li class="chapter" data-level="88.3.1" data-path="cox.html"><a href="cox.html#爲什麼使用-cox-回歸模型"><i class="fa fa-check"></i><b>88.3.1</b> 爲什麼使用 Cox 回歸模型？</a></li>
</ul></li>
<li class="chapter" data-level="88.4" data-path="cox.html"><a href="cox.html#處理相等的生存時間-handling-tied-survival-times"><i class="fa fa-check"></i><b>88.4</b> 處理相等的生存時間 handling tied survival times</a></li>
<li class="chapter" data-level="88.5" data-path="cox.html"><a href="cox.html#估計生存曲線"><i class="fa fa-check"></i><b>88.5</b> 估計生存曲線</a></li>
<li class="chapter" data-level="88.6" data-path="cox.html"><a href="cox.html#cox回歸模型中包涵的假設"><i class="fa fa-check"></i><b>88.6</b> Cox回歸模型中包涵的假設：</a></li>
<li class="chapter" data-level="88.7" data-path="cox.html"><a href="cox.html#評估比例風險假設-assessing-the-proportional-hazard-assumption"><i class="fa fa-check"></i><b>88.7</b> 評估比例風險假設 assessing the proportional hazard assumption</a></li>
<li class="chapter" data-level="88.8" data-path="cox.html"><a href="cox.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>88.8</b> 該用半參數模型還是用全參數模型</a></li>
<li class="chapter" data-level="88.9" data-path="cox.html"><a href="cox.html#practical-survival-04"><i class="fa fa-check"></i><b>88.9</b> Practical Survival 04</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="surv-check.html"><a href="surv-check.html"><i class="fa fa-check"></i><b>89</b> 分析策略和模型檢查 Model checking-survival analysis</a>
<ul>
<li class="chapter" data-level="89.1" data-path="surv-check.html"><a href="surv-check.html#本章概要-4"><i class="fa fa-check"></i><b>89.1</b> 本章概要</a></li>
<li class="chapter" data-level="89.2" data-path="surv-check.html"><a href="surv-check.html#生存分析策略"><i class="fa fa-check"></i><b>89.2</b> 生存分析策略</a>
<ul>
<li class="chapter" data-level="89.2.1" data-path="surv-check.html"><a href="surv-check.html#關於似然比檢驗-a-note-on-likelihood-ratio-tests"><i class="fa fa-check"></i><b>89.2.1</b> 關於似然比檢驗 A note on likelihood ratio tests</a></li>
</ul></li>
<li class="chapter" data-level="89.3" data-path="surv-check.html"><a href="surv-check.html#針對不同的研究設計不同的分析策略"><i class="fa fa-check"></i><b>89.3</b> 針對不同的研究設計不同的分析策略</a>
<ul>
<li class="chapter" data-level="89.3.1" data-path="surv-check.html"><a href="surv-check.html#針對隨機對照臨牀試驗-rct"><i class="fa fa-check"></i><b>89.3.1</b> 針對隨機對照臨牀試驗 RCT</a></li>
<li class="chapter" data-level="89.3.2" data-path="surv-check.html"><a href="surv-check.html#針對觀察型研究-observational-studies"><i class="fa fa-check"></i><b>89.3.2</b> 針對觀察型研究 observational studies</a></li>
</ul></li>
<li class="chapter" data-level="89.4" data-path="surv-check.html"><a href="surv-check.html#模型檢查的要點"><i class="fa fa-check"></i><b>89.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="89.5" data-path="surv-check.html"><a href="surv-check.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>89.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a>
<ul>
<li class="chapter" data-level="89.5.1" data-path="surv-check.html"><a href="surv-check.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>89.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="89.5.2" data-path="surv-check.html"><a href="surv-check.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>89.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="89.6" data-path="surv-check.html"><a href="surv-check.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>89.6</b> 評價模型擬合的其他有趣方法</a>
<ul>
<li class="chapter" data-level="89.6.1" data-path="surv-check.html"><a href="surv-check.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>89.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="89.6.2" data-path="surv-check.html"><a href="surv-check.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>89.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
<li class="chapter" data-level="89.7" data-path="surv-check.html"><a href="surv-check.html#practical-survival-05"><i class="fa fa-check"></i><b>89.7</b> Practical Survival 05</a>
<ul>
<li class="chapter" data-level="89.7.1" data-path="surv-check.html"><a href="surv-check.html#把數據讀入你最喜歡的-r-的環境中先考慮一個二進制變量-cir0-對生存的影響在建立的模型中加入該-cir0-變量和時間的交互作用項在-r-裏需要用到-tt-命令"><i class="fa fa-check"></i><b>89.7.1</b> 把數據讀入你最喜歡的 R 的環境中，先考慮一個二進制變量 <code>cir0</code> 對生存的影響。在建立的模型中加入該 <code>cir0</code> 變量和時間的交互作用項。在 R 裏需要用到 <code>tt()</code> 命令。</a></li>
<li class="chapter" data-level="89.7.2" data-path="surv-check.html"><a href="surv-check.html#繪製模型中只有-cir0-一個變量的情況下調整後的-scaled-schoenfeld-殘差圖"><i class="fa fa-check"></i><b>89.7.2</b> 繪製模型中只有 <code>cir0</code> 一個變量的情況下，調整後的 scaled Schoenfeld 殘差圖。</a></li>
<li class="chapter" data-level="89.7.3" data-path="surv-check.html"><a href="surv-check.html#另外一種探索變量-cir0-的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段分別估計每個時間段內該暴露變量的風險度比"><i class="fa fa-check"></i><b>89.7.3</b> 另外一種探索變量 <code>cir0</code> 的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段，分別估計每個時間段內該暴露變量的風險度比。</a></li>
<li class="chapter" data-level="89.7.4" data-path="surv-check.html"><a href="surv-check.html#接下來我們來看該數據集中的一個連續型變量-bil0-我們練習使用-martingale-殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式"><i class="fa fa-check"></i><b>89.7.4</b> 接下來我們來看該數據集中的一個連續型變量， <code>bil0</code> 。我們練習使用 Martingale 殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式。</a></li>
<li class="chapter" data-level="89.7.5" data-path="surv-check.html"><a href="surv-check.html#選擇你認爲應該對-bil0-進行的數學函數形式使用-scaled-schoenfeld-殘差檢查它是否違反比例風險假設"><i class="fa fa-check"></i><b>89.7.5</b> 選擇你認爲應該對 <code>bil0</code> 進行的數學函數形式，使用 Scaled Schoenfeld 殘差檢查它是否違反比例風險假設。</a></li>
<li class="chapter" data-level="89.7.6" data-path="surv-check.html"><a href="surv-check.html#建立一個含有如下解釋變量的-cox-比例風險回歸模型轉換過後的bil0-cir0cenc0-age"><i class="fa fa-check"></i><b>89.7.6</b> 建立一個含有如下解釋變量的 Cox 比例風險回歸模型：轉換過後的<code>bil0</code>, <code>cir0</code>，<code>cenc0</code>, <code>Age</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="90" data-path="competing-risk.html"><a href="competing-risk.html"><i class="fa fa-check"></i><b>90</b> 競爭風險模型 competing risk</a>
<ul>
<li class="chapter" data-level="90.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazard"><i class="fa fa-check"></i><b>90.1</b> Cause-specific hazard</a>
<ul>
<li class="chapter" data-level="90.1.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>90.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="90.2" data-path="competing-risk.html"><a href="competing-risk.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>90.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="90.3" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>90.3</b> Subdistribution hazard - Fine and Gray model</a>
<ul>
<li class="chapter" data-level="90.3.1" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>90.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="90.4" data-path="competing-risk.html"><a href="competing-risk.html#multi-state-models"><i class="fa fa-check"></i><b>90.4</b> Multi-state models</a>
<ul>
<li class="chapter" data-level="90.4.1" data-path="competing-risk.html"><a href="competing-risk.html#the-markov-model"><i class="fa fa-check"></i><b>90.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="90.4.2" data-path="competing-risk.html"><a href="competing-risk.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>90.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
<li class="chapter" data-level="90.5" data-path="competing-risk.html"><a href="competing-risk.html#practical-survival-06"><i class="fa fa-check"></i><b>90.5</b> Practical Survival 06</a></li>
</ul></li>
<li class="chapter" data-level="91" data-path="other-surv.html"><a href="other-surv.html"><i class="fa fa-check"></i><b>91</b> 生存分析的其他手段</a>
<ul>
<li class="chapter" data-level="91.1" data-path="other-surv.html"><a href="other-surv.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>91.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="91.2" data-path="other-surv.html"><a href="other-surv.html#加速失效死亡模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>91.2</b> 加速失效(死亡)模型 Accelerated failure time (AFT) model</a>
<ul>
<li class="chapter" data-level="91.2.1" data-path="other-surv.html"><a href="other-surv.html#詳細推導"><i class="fa fa-check"></i><b>91.2.1</b> 詳細推導</a></li>
<li class="chapter" data-level="91.2.2" data-path="other-surv.html"><a href="other-surv.html#再詳細推導"><i class="fa fa-check"></i><b>91.2.2</b> 再詳細推導</a></li>
<li class="chapter" data-level="91.2.3" data-path="other-surv.html"><a href="other-surv.html#風險比例模型ph和加速失效死亡模型aft的比較"><i class="fa fa-check"></i><b>91.2.3</b> 風險比例模型(PH)和加速失效（死亡）模型(AFT)的比較</a></li>
<li class="chapter" data-level="91.2.4" data-path="other-surv.html"><a href="other-surv.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>91.2.4</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
<li class="chapter" data-level="91.3" data-path="other-surv.html"><a href="other-surv.html#practical-survival-07"><i class="fa fa-check"></i><b>91.3</b> Practical Survival 07</a></li>
</ul></li>
<li class="chapter" data-level="92" data-path="time-dep.html"><a href="time-dep.html"><i class="fa fa-check"></i><b>92</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a>
<ul>
<li class="chapter" data-level="92.1" data-path="time-dep.html"><a href="time-dep.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>92.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="92.2" data-path="time-dep.html"><a href="time-dep.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>92.2</b> Extended Cox model 把Cox模型擴展開去</a></li>
<li class="chapter" data-level="92.3" data-path="time-dep.html"><a href="time-dep.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>92.3</b> 時間依存變量數據的結構</a>
<ul>
<li class="chapter" data-level="92.3.1" data-path="time-dep.html"><a href="time-dep.html#值得注意的點"><i class="fa fa-check"></i><b>92.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="92.4" data-path="time-dep.html"><a href="time-dep.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>92.4</b> Frailty Models (脆弱模型?)</a>
<ul>
<li class="chapter" data-level="92.4.1" data-path="time-dep.html"><a href="time-dep.html#individual-frailty-model"><i class="fa fa-check"></i><b>92.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="92.4.2" data-path="time-dep.html"><a href="time-dep.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>92.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="92.4.3" data-path="time-dep.html"><a href="time-dep.html#shared-frailty-model"><i class="fa fa-check"></i><b>92.4.3</b> Shared frailty model</a></li>
</ul></li>
<li class="chapter" data-level="92.5" data-path="time-dep.html"><a href="time-dep.html#practical-survival-08"><i class="fa fa-check"></i><b>92.5</b> Practical Survival 08</a>
<ul>
<li class="chapter" data-level="92.5.1" data-path="time-dep.html"><a href="time-dep.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>92.5.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="92.5.2" data-path="time-dep.html"><a href="time-dep.html#解答"><i class="fa fa-check"></i><b>92.5.2</b> 解答</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="93" data-path="surv-advance.html"><a href="surv-advance.html"><i class="fa fa-check"></i><b>93</b> 時間事件數據的高級分析法</a></li>
<li class="chapter" data-level="94" data-path="bayes-surv.html"><a href="bayes-surv.html"><i class="fa fa-check"></i><b>94</b> 貝葉斯生存分析 Bayesian Survival Analysis</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="95" data-path="why-bayes.html"><a href="why-bayes.html"><i class="fa fa-check"></i><b>95</b> 爲什麼我們要用貝葉斯統計學方法？</a>
<ul>
<li class="chapter" data-level="95.1" data-path="why-bayes.html"><a href="why-bayes.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>95.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a>
<ul>
<li class="chapter" data-level="95.1.1" data-path="why-bayes.html"><a href="why-bayes.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>95.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="95.1.2" data-path="why-bayes.html"><a href="why-bayes.html#概率論者分析結果"><i class="fa fa-check"></i><b>95.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="95.1.3" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>95.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="95.2" data-path="why-bayes.html"><a href="why-bayes.html#example-the-great-trial"><i class="fa fa-check"></i><b>95.2</b> Example: The GREAT trial</a>
<ul>
<li class="chapter" data-level="95.2.1" data-path="why-bayes.html"><a href="why-bayes.html#background-great-trial"><i class="fa fa-check"></i><b>95.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="95.2.2" data-path="why-bayes.html"><a href="why-bayes.html#試驗結果"><i class="fa fa-check"></i><b>95.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="95.2.3" data-path="why-bayes.html"><a href="why-bayes.html#經典統計學分析方法"><i class="fa fa-check"></i><b>95.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="95.2.4" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>95.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="96" data-path="MC-estimation.html"><a href="MC-estimation.html"><i class="fa fa-check"></i><b>96</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a>
<ul>
<li class="chapter" data-level="96.1" data-path="MC-estimation.html"><a href="MC-estimation.html#起源"><i class="fa fa-check"></i><b>96.1</b> 起源</a></li>
<li class="chapter" data-level="96.2" data-path="MC-estimation.html"><a href="MC-estimation.html#百分比的統計學推斷-inference-on-proportions"><i class="fa fa-check"></i><b>96.2</b> 百分比的統計學推斷 inference on proportions</a>
<ul>
<li class="chapter" data-level="96.2.1" data-path="MC-estimation.html"><a href="MC-estimation.html#example-new-drug"><i class="fa fa-check"></i><b>96.2.1</b> Example: New Drug</a></li>
<li class="chapter" data-level="96.2.2" data-path="MC-estimation.html"><a href="MC-estimation.html#beta-distr"><i class="fa fa-check"></i><b>96.2.2</b> Beta 分布</a></li>
<li class="chapter" data-level="96.2.3" data-path="MC-estimation.html"><a href="MC-estimation.html#作出預測"><i class="fa fa-check"></i><b>96.2.3</b> 作出預測</a></li>
<li class="chapter" data-level="96.2.4" data-path="MC-estimation.html"><a href="MC-estimation.html#example-新藥表現預測"><i class="fa fa-check"></i><b>96.2.4</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="96.3" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>96.3</b> 蒙特卡羅估計</a>
<ul>
<li class="chapter" data-level="96.3.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>96.3.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="96.3.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>96.3.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="96.4" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅法分析軟件-openbugs-jags"><i class="fa fa-check"></i><b>96.4</b> 蒙特卡羅法分析軟件 OpenBUGS / JAGS</a>
<ul>
<li class="chapter" data-level="96.4.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jagsbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>96.4.1</b> 用 JAGS/BUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="96.4.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jags-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>96.4.2</b> 用 JAGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="96.4.3" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>96.4.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="96.5" data-path="MC-estimation.html"><a href="MC-estimation.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>96.5</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="97" data-path="conjugate-priors.html"><a href="conjugate-priors.html"><i class="fa fa-check"></i><b>97</b> 共軛先驗概率 Conjugate priors</a>
<ul>
<li class="chapter" data-level="97.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>97.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="97.2" data-path="conjugate-priors.html"><a href="conjugate-priors.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.2</b> 二項分布(似然)數據的共軛先驗概率</a>
<ul>
<li class="chapter" data-level="97.2.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#事後概率分布預測"><i class="fa fa-check"></i><b>97.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="97.3" data-path="conjugate-priors.html"><a href="conjugate-priors.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="97.4" data-path="conjugate-priors.html"><a href="conjugate-priors.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>97.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="97.5" data-path="conjugate-priors.html"><a href="conjugate-priors.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>97.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="97.6" data-path="conjugate-priors.html"><a href="conjugate-priors.html#BayesPrac03"><i class="fa fa-check"></i><b>97.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="98" data-path="MCMC-methods.html"><a href="MCMC-methods.html"><i class="fa fa-check"></i><b>98</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a>
<ul>
<li class="chapter" data-level="98.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>98.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a>
<ul>
<li class="chapter" data-level="98.1.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>98.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="98.1.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#Gibbs-sampling"><i class="fa fa-check"></i><b>98.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="98.1.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#初始值-initial-values"><i class="fa fa-check"></i><b>98.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="98.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>98.2</b> 使用 MCMC 時需要考慮的一些問題</a>
<ul>
<li class="chapter" data-level="98.2.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#收斂時間"><i class="fa fa-check"></i><b>98.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="98.2.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>98.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="98.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-軟件"><i class="fa fa-check"></i><b>98.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="98.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>98.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a>
<ul>
<li class="chapter" data-level="98.4.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>98.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="98.5" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-language"><i class="fa fa-check"></i><b>98.5</b> BUGS language</a>
<ul>
<li class="chapter" data-level="98.5.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>98.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="98.5.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#分布的標記法"><i class="fa fa-check"></i><b>98.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="98.5.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#arrays-and-loops"><i class="fa fa-check"></i><b>98.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="98.5.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#常用的方程"><i class="fa fa-check"></i><b>98.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="98.6" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>98.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="98.7" data-path="MCMC-methods.html"><a href="MCMC-methods.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>98.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="99" data-path="Bayes-check.html"><a href="Bayes-check.html"><i class="fa fa-check"></i><b>99</b> 建模和模型的檢查</a>
<ul>
<li class="chapter" data-level="99.1" data-path="Bayes-check.html"><a href="Bayes-check.html#BayesianLM"><i class="fa fa-check"></i><b>99.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="99.2" data-path="Bayes-check.html"><a href="Bayes-check.html#children-in-the-gambia"><i class="fa fa-check"></i><b>99.2</b> Children in the Gambia</a>
<ul>
<li class="chapter" data-level="99.2.1" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>99.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="99.2.2" data-path="Bayes-check.html"><a href="Bayes-check.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>99.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="99.2.3" data-path="Bayes-check.html"><a href="Bayes-check.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>99.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="99.2.4" data-path="Bayes-check.html"><a href="Bayes-check.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>99.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="99.2.5" data-path="Bayes-check.html"><a href="Bayes-check.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>99.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="99.2.6" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>99.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="99.2.7" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>99.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="99.2.8" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>99.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="99.2.9" data-path="Bayes-check.html"><a href="Bayes-check.html#tdreplacegaussian"><i class="fa fa-check"></i><b>99.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="99.3" data-path="Bayes-check.html"><a href="Bayes-check.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>99.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a>
<ul>
<li class="chapter" data-level="99.3.1" data-path="Bayes-check.html"><a href="Bayes-check.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>99.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="99.3.2" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>99.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="99.4" data-path="Bayes-check.html"><a href="Bayes-check.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>99.4</b> Practical Bayesian Statistics 05</a>
<ul>
<li class="chapter" data-level="99.4.1" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>99.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="99.4.2" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>99.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="100" data-path="Bayes-design.html"><a href="Bayes-design.html"><i class="fa fa-check"></i><b>100</b> 不同實驗/研究設計時適用的貝葉斯模型</a>
<ul>
<li class="chapter" data-level="100.1" data-path="Bayes-design.html"><a href="Bayes-design.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>100.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.2" data-path="Bayes-design.html"><a href="Bayes-design.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>100.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.3" data-path="Bayes-design.html"><a href="Bayes-design.html#bayes-crosssectional"><i class="fa fa-check"></i><b>100.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="100.4" data-path="Bayes-design.html"><a href="Bayes-design.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>100.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a>
<ul>
<li class="chapter" data-level="100.4.1" data-path="Bayes-design.html"><a href="Bayes-design.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>100.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="100.5" data-path="Bayes-design.html"><a href="Bayes-design.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>100.5</b> Practical Bayesian Statistics 06</a>
<ul>
<li class="chapter" data-level="100.5.1" data-path="Bayes-design.html"><a href="Bayes-design.html#the-great-trial"><i class="fa fa-check"></i><b>100.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="100.5.2" data-path="Bayes-design.html"><a href="Bayes-design.html#吸煙與癌症"><i class="fa fa-check"></i><b>100.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="101" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html"><i class="fa fa-check"></i><b>101</b> 貝葉斯廣義線性回歸</a>
<ul>
<li class="chapter" data-level="101.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>101.1</b> 如何在BUGS語言中描述分類型變量</a>
<ul>
<li class="chapter" data-level="101.1.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>101.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="101.1.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>101.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="101.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>101.2</b> 邏輯回歸 Bayesian Logistic Regression</a>
<ul>
<li class="chapter" data-level="101.2.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#低出生體重數據-1"><i class="fa fa-check"></i><b>101.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="101.3" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>101.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="101.4" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>101.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="101.5" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#Bayesian-practical07"><i class="fa fa-check"></i><b>101.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="102" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html"><i class="fa fa-check"></i><b>102</b> 貝葉斯等級回歸模型</a>
<ul>
<li class="chapter" data-level="102.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>102.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="102.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>102.2</b> 多層數據在模型中可能要用到的前提條件</a>
<ul>
<li class="chapter" data-level="102.2.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>102.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="102.2.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>102.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="102.2.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>102.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="102.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>102.3</b> 抗抑鬱臨牀試驗實例</a>
<ul>
<li class="chapter" data-level="102.3.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#縱向數據"><i class="fa fa-check"></i><b>102.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="102.3.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-example"><i class="fa fa-check"></i><b>102.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="102.3.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>102.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="102.3.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>102.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="102.3.5" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>102.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="102.3.6" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>102.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="102.3.7" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>102.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="102.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>102.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="103" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html"><i class="fa fa-check"></i><b>103</b> 再訪 MCMC</a>
<ul>
<li class="chapter" data-level="103.1" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>103.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="103.2" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>103.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="104" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html"><i class="fa fa-check"></i><b>104</b> 貝葉斯和概率論的比較</a>
<ul>
<li class="chapter" data-level="104.1" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>104.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="104.2" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>104.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="104.3" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>104.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 非參數貝葉斯統計 Bayesian Nonparametric Data Analysis</b></span></li>
<li class="chapter" data-level="105" data-path="nonparaBayes-intro.html"><a href="nonparaBayes-intro.html"><i class="fa fa-check"></i><b>105</b> 非參貝葉斯入門</a></li>
<li class="chapter" data-level="106" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><i class="fa fa-check"></i><b>106</b> 密度估計 Density estimation - 狄雷克雷過程模型 DP models</a>
<ul>
<li class="chapter" data-level="106.1" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#狄雷克雷過程-dirichlet-process"><i class="fa fa-check"></i><b>106.1</b> 狄雷克雷過程 Dirichlet process</a>
<ul>
<li class="chapter" data-level="106.1.1" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#定義-definition"><i class="fa fa-check"></i><b>106.1.1</b> 定義 definition</a></li>
<li class="chapter" data-level="106.1.2" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#推導"><i class="fa fa-check"></i><b>106.1.2</b> 推導</a></li>
<li class="chapter" data-level="106.1.3" data-path="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html"><a href="密度估計-density-estimation---狄雷克雷過程模型-dp-models.html#事後概率分佈和邊際分佈"><i class="fa fa-check"></i><b>106.1.3</b> 事後概率分佈和邊際分佈</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XIII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="107" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html"><i class="fa fa-check"></i><b>107</b> Causal Languages 因果推斷的語法</a>
<ul>
<li class="chapter" data-level="107.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>107.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="107.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>107.2</b> 傳統的統計學方法</a>
<ul>
<li class="chapter" data-level="107.2.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#初步分析"><i class="fa fa-check"></i><b>107.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="107.2.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#混雜"><i class="fa fa-check"></i><b>107.2.2</b> 混雜</a></li>
<li class="chapter" data-level="107.2.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>107.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="107.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>107.3</b> 更加正規的方法</a>
<ul>
<li class="chapter" data-level="107.3.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>107.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="107.3.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>107.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="107.3.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>107.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="107.3.4" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>107.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="108" data-path="graphical-models.html"><a href="graphical-models.html"><i class="fa fa-check"></i><b>108</b> Graphical Models 因果推斷的圖形模型</a>
<ul>
<li class="chapter" data-level="108.1" data-path="graphical-models.html"><a href="graphical-models.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>108.1</b> 統計學中的有向無環圖</a>
<ul>
<li class="chapter" data-level="108.1.1" data-path="graphical-models.html"><a href="graphical-models.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>108.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="108.1.2" data-path="graphical-models.html"><a href="graphical-models.html#dag-圖的術語"><i class="fa fa-check"></i><b>108.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="108.1.3" data-path="graphical-models.html"><a href="graphical-models.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>108.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="108.1.4" data-path="graphical-models.html"><a href="graphical-models.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>108.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="108.2" data-path="graphical-models.html"><a href="graphical-models.html#以非對撞爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>108.2</b> 以非對撞爲條件 conditioning on a non-collider</a>
<ul>
<li class="chapter" data-level="108.2.1" data-path="graphical-models.html"><a href="graphical-models.html#條件的總結"><i class="fa fa-check"></i><b>108.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="108.2.2" data-path="graphical-models.html"><a href="graphical-models.html#d-分離-d-separation"><i class="fa fa-check"></i><b>108.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="109" data-path="reg-cont.html"><a href="reg-cont.html"><i class="fa fa-check"></i><b>109</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a>
<ul>
<li class="chapter" data-level="109.1" data-path="reg-cont.html"><a href="reg-cont.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>109.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="109.2" data-path="reg-cont.html"><a href="reg-cont.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>109.2</b> 鑑定 identification - revision</a>
<ul>
<li class="chapter" data-level="109.2.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>109.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="109.2.2" data-path="reg-cont.html"><a href="reg-cont.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>109.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="109.2.3" data-path="reg-cont.html"><a href="reg-cont.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>109.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="109.3" data-path="reg-cont.html"><a href="reg-cont.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>109.3</b> 通過線性回歸模型來估計 ACE</a>
<ul>
<li class="chapter" data-level="109.3.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均值差"><i class="fa fa-check"></i><b>109.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="109.3.2" data-path="reg-cont.html"><a href="reg-cont.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>109.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="109.3.3" data-path="reg-cont.html"><a href="reg-cont.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>109.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="109.3.4" data-path="reg-cont.html"><a href="reg-cont.html#positivity-非零性"><i class="fa fa-check"></i><b>109.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="109.3.5" data-path="reg-cont.html"><a href="reg-cont.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>109.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="109.4" data-path="reg-cont.html"><a href="reg-cont.html#practical03---causal-inference"><i class="fa fa-check"></i><b>109.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="110" data-path="regre-binary.html"><a href="regre-binary.html"><i class="fa fa-check"></i><b>110</b> Regression Methods with binary outcomes 結果變量爲二進制變量</a>
<ul>
<li class="chapter" data-level="110.1" data-path="regre-binary.html"><a href="regre-binary.html#二進制結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>110.1</b> 二進制結果變量的因果被估計量 (causal estimand):</a>
<ul>
<li class="chapter" data-level="110.1.1" data-path="regre-binary.html"><a href="regre-binary.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>110.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="110.2" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>110.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="110.3" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>110.3</b> 鑑定 identification - marginal effects</a>
<ul>
<li class="chapter" data-level="110.3.1" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>110.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="110.3.2" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>110.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="110.4" data-path="regre-binary.html"><a href="regre-binary.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>110.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="110.5" data-path="regre-binary.html"><a href="regre-binary.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>110.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="110.6" data-path="regre-binary.html"><a href="regre-binary.html#practical04---causal-inference"><i class="fa fa-check"></i><b>110.6</b> Practical04 - causal inference</a>
<ul>
<li class="chapter" data-level="110.6.1" data-path="regre-binary.html"><a href="regre-binary.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>110.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="110.6.2" data-path="regre-binary.html"><a href="regre-binary.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>110.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="110.6.3" data-path="regre-binary.html"><a href="regre-binary.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>110.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="110.6.4" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>110.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="110.6.5" data-path="regre-binary.html"><a href="regre-binary.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>110.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="110.6.6" data-path="regre-binary.html"><a href="regre-binary.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>110.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="110.6.7" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>110.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="110.6.8" data-path="regre-binary.html"><a href="regre-binary.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>110.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="110.6.9" data-path="regre-binary.html"><a href="regre-binary.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>110.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="110.6.10" data-path="regre-binary.html"><a href="regre-binary.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>110.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="110.6.11" data-path="regre-binary.html"><a href="regre-binary.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>110.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="110.6.12" data-path="regre-binary.html"><a href="regre-binary.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>110.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="111" data-path="prop-score.html"><a href="prop-score.html"><i class="fa fa-check"></i><b>111</b> Prospensity Score 傾向性評分</a>
<ul>
<li class="chapter" data-level="111.1" data-path="prop-score.html"><a href="prop-score.html#practical05---causal-inference"><i class="fa fa-check"></i><b>111.1</b> Practical05 - causal inference</a>
<ul>
<li class="chapter" data-level="111.1.1" data-path="prop-score.html"><a href="prop-score.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>111.1.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="111.1.2" data-path="prop-score.html"><a href="prop-score.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>111.1.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="111.1.3" data-path="prop-score.html"><a href="prop-score.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>111.1.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="111.1.4" data-path="prop-score.html"><a href="prop-score.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>111.1.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="111.1.5" data-path="prop-score.html"><a href="prop-score.html#用配對法計算-ace"><i class="fa fa-check"></i><b>111.1.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="111.1.6" data-path="prop-score.html"><a href="prop-score.html#模型校正-ps"><i class="fa fa-check"></i><b>111.1.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="112" data-path="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><a href="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><i class="fa fa-check"></i><b>112</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="113" data-path="causal-mediation-analysis.html"><a href="causal-mediation-analysis.html"><i class="fa fa-check"></i><b>113</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIV 真實世界數據 Real World Data and Real World Evidence</b></span></li>
<li class="chapter" data-level="114" data-path="rationale-behind-and-challenges-to-health-data-analysis.html"><a href="rationale-behind-and-challenges-to-health-data-analysis.html"><i class="fa fa-check"></i><b>114</b> Rationale behind and challenges to health data analysis</a></li>
<li class="part"><span><b>XV 醫療技術評價之成本效益分析模型 Cost effectiveness modelling for health technology assessment</b></span></li>
<li class="chapter" data-level="115" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><i class="fa fa-check"></i><b>115</b> 簡介馬克夫成本效益模型 Introduction to Markov Cost Effectiveness Models</a>
<ul>
<li class="chapter" data-level="115.1" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#入門簡介"><i class="fa fa-check"></i><b>115.1</b> 入門簡介</a></li>
<li class="chapter" data-level="115.2" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#爲什麼要使用馬克夫模型-why-markov-models"><i class="fa fa-check"></i><b>115.2</b> 爲什麼要使用馬克夫模型 why Markov models?</a></li>
<li class="chapter" data-level="115.3" data-path="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html"><a href="簡介馬克夫成本效益模型-introduction-to-markov-cost-effectiveness-models.html#健康狀態-health-states"><i class="fa fa-check"></i><b>115.3</b> 健康狀態 health states</a></li>
</ul></li>
<li class="part"><span><b>XVI Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="116" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><i class="fa fa-check"></i><b>116</b> 粗率比和分層率比 Crude and stratified rate ratios</a>
<ul>
<li class="chapter" data-level="116.1" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q1-q3-讀取數據簡單歸納分割年齡計算年齡組的粗死亡率"><i class="fa fa-check"></i><b>116.1</b> Q1-Q3 讀取數據，簡單歸納，分割年齡，計算年齡組的粗死亡率</a></li>
<li class="chapter" data-level="116.2" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q4-計算不同年齡組相對於最年輕的年齡組的死亡率比-rate-ratio-rr"><i class="fa fa-check"></i><b>116.2</b> Q4 計算不同年齡組相對於最年輕的年齡組的死亡率比 Rate ratio, RR</a></li>
<li class="chapter" data-level="116.3" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q5-分析另一個關於職業等級-grade-和死亡之間的關係使用-stata-的-stmh-命令來計算並比較較低等級職業-low-grade-和較高等級職業-high-grade-相比死亡率比是多少你認爲結果是否提供強有力的證據證明這兩種職業等級之間的死亡率存在顯著差異"><i class="fa fa-check"></i><b>116.3</b> Q5 分析另一個關於職業等級 <code>grade</code> 和死亡之間的關係。使用 Stata 的 <code>stmh</code> 命令來計算並比較較低等級職業 (low grade) 和較高等級職業 (high grade) 相比，死亡率比是多少。你認爲結果是否提供強有力的證據證明這兩種職業等級之間的死亡率存在顯著差異？</a></li>
<li class="chapter" data-level="116.4" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q6-q8-試分析上一題中觀察到的職業等級和死亡率之間的關係是否受到年齡的影響先嘗試使用-stmh-by-函數來分析不同年齡層中職業等級之間的死亡率比是否有證據證明職業等級的高低和年齡之間在死亡率比的關係上存在交互作用又或者是否有年齡的混淆因素會對職業等級和死亡之間的關係造成影響"><i class="fa fa-check"></i><b>116.4</b> Q6-Q8 試分析上一題中觀察到的職業等級和死亡率之間的關係，是否受到年齡的影響。先嘗試使用 <code>stmh, by()</code> 函數來分析不同年齡層中職業等級之間的死亡率比。是否有證據證明職業等級的高低和年齡之間在死亡率比的關係上存在交互作用？又或者是否有年齡的混淆因素會對職業等級和死亡之間的關係造成影響？</a></li>
<li class="chapter" data-level="116.5" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#q9-試分析職業等級和chd冠心病死亡之間的關係此時在stata需要重新修改你的觀察結果爲-chd職業等級和冠心病死亡之間的關係是否受到吸菸習慣的影響或者有交互作用呢"><i class="fa fa-check"></i><b>116.5</b> Q9 試分析職業等級和CHD，冠心病死亡之間的關係。此時在Stata需要重新修改你的觀察結果爲 <code>chd</code>。職業等級和冠心病死亡之間的關係是否受到吸菸習慣的影響，或者有交互作用呢？</a></li>
<li class="chapter" data-level="116.6" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#further-q1-請分析膽固醇水平和-冠心病死亡之間的關係這一關係是否受到年齡的混雜影響"><i class="fa fa-check"></i><b>116.6</b> Further Q1 請分析膽固醇水平和 冠心病死亡之間的關係。這一關係是否受到年齡的混雜影響？</a></li>
<li class="chapter" data-level="116.7" data-path="粗率比和分層率比-crude-and-stratified-rate-ratios.html"><a href="粗率比和分層率比-crude-and-stratified-rate-ratios.html#further-q2-你認爲當我們在分析膽固醇和冠心病死亡率之間的關係的時候需要考慮調整收縮期血壓嗎-systolic-blood-pressure如果你不同意爲什麼"><i class="fa fa-check"></i><b>116.7</b> Further Q2 你認爲，當我們在分析膽固醇和冠心病死亡率之間的關係的時候，需要考慮調整收縮期血壓嗎 (systolic blood pressure)？如果你不同意，爲什麼？</a></li>
</ul></li>
<li class="chapter" data-level="117" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><i class="fa fa-check"></i><b>117</b> 從流行病學的角度初步分析生存數據 introduction to survival analysis</a>
<ul>
<li class="chapter" data-level="117.1" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q1-5"><i class="fa fa-check"></i><b>117.1</b> Q1</a></li>
<li class="chapter" data-level="117.2" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q2-4"><i class="fa fa-check"></i><b>117.2</b> Q2</a></li>
<li class="chapter" data-level="117.3" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q3-3"><i class="fa fa-check"></i><b>117.3</b> Q3</a></li>
<li class="chapter" data-level="117.4" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q4-1"><i class="fa fa-check"></i><b>117.4</b> Q4</a></li>
<li class="chapter" data-level="117.5" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q5-1"><i class="fa fa-check"></i><b>117.5</b> Q5</a></li>
<li class="chapter" data-level="117.6" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q6-1"><i class="fa fa-check"></i><b>117.6</b> Q6</a></li>
<li class="chapter" data-level="117.7" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q7"><i class="fa fa-check"></i><b>117.7</b> Q7</a></li>
<li class="chapter" data-level="117.8" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q8"><i class="fa fa-check"></i><b>117.8</b> Q8</a></li>
<li class="chapter" data-level="117.9" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q9"><i class="fa fa-check"></i><b>117.9</b> Q9</a></li>
<li class="chapter" data-level="117.10" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q10"><i class="fa fa-check"></i><b>117.10</b> Q10</a></li>
<li class="chapter" data-level="117.11" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q11"><i class="fa fa-check"></i><b>117.11</b> Q11</a></li>
<li class="chapter" data-level="117.12" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q12-13"><i class="fa fa-check"></i><b>117.12</b> Q12-13</a></li>
<li class="chapter" data-level="117.13" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q14"><i class="fa fa-check"></i><b>117.13</b> Q14</a></li>
<li class="chapter" data-level="117.14" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q15"><i class="fa fa-check"></i><b>117.14</b> Q15</a></li>
<li class="chapter" data-level="117.15" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q16"><i class="fa fa-check"></i><b>117.15</b> Q16</a></li>
<li class="chapter" data-level="117.16" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q17"><i class="fa fa-check"></i><b>117.16</b> Q17</a></li>
<li class="chapter" data-level="117.17" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q18"><i class="fa fa-check"></i><b>117.17</b> Q18</a></li>
<li class="chapter" data-level="117.18" data-path="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html"><a href="從流行病學的角度初步分析生存數據-introduction-to-survival-analysis.html#q19"><i class="fa fa-check"></i><b>117.18</b> Q19</a></li>
</ul></li>
<li class="chapter" data-level="118" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><i class="fa fa-check"></i><b>118</b> （無匹配的）病例對照研究的分析方法 analysis of unmatched case-control studies</a>
<ul>
<li class="chapter" data-level="118.1" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q1-數據讀入"><i class="fa fa-check"></i><b>118.1</b> Q1 數據讀入</a></li>
<li class="chapter" data-level="118.2" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q2-計算粗比值比"><i class="fa fa-check"></i><b>118.2</b> Q2 計算粗比值比</a></li>
<li class="chapter" data-level="118.3" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q3-年齡的混雜或者交互-confounding-or-effect-mnodifier"><i class="fa fa-check"></i><b>118.3</b> Q3 年齡的混雜或者交互 confounding or effect-mnodifier</a></li>
<li class="chapter" data-level="118.4" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q4-宗教信仰-religion-rel-和hiv之間的關係"><i class="fa fa-check"></i><b>118.4</b> Q4 宗教信仰 religion <code>rel</code> 和HIV之間的關係</a></li>
<li class="chapter" data-level="118.5" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q5-性伴侶人數"><i class="fa fa-check"></i><b>118.5</b> Q5 性伴侶人數</a></li>
<li class="chapter" data-level="118.6" data-path="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html"><a href="無匹配的病例對照研究的分析方法-analysis-of-unmatched-case-control-studies.html#q6-分析劑量-反應關係-dose-response-relationship"><i class="fa fa-check"></i><b>118.6</b> Q6 分析劑量-反應關係 dose-response relationship</a></li>
</ul></li>
<li class="chapter" data-level="119" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html"><i class="fa fa-check"></i><b>119</b> 似然的概念和圖形理解 Likelihood</a>
<ul>
<li class="chapter" data-level="119.1" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q1-二項分佈似然的圖形"><i class="fa fa-check"></i><b>119.1</b> Q1 二項分佈似然的圖形</a></li>
<li class="chapter" data-level="119.2" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q2-修改信賴區間的寬度"><i class="fa fa-check"></i><b>119.2</b> Q2 修改信賴區間的寬度</a></li>
<li class="chapter" data-level="119.3" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q3-嘗試繪製一些極端情況下的似然函數圖"><i class="fa fa-check"></i><b>119.3</b> Q3 嘗試繪製一些極端情況下的似然函數圖</a></li>
<li class="chapter" data-level="119.4" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q4-失敗次數爲-0-會發生什麼"><i class="fa fa-check"></i><b>119.4</b> Q4 失敗次數爲 0 會發生什麼</a></li>
<li class="chapter" data-level="119.5" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q5-泊松分佈參數的似然函數"><i class="fa fa-check"></i><b>119.5</b> Q5 泊松分佈參數的似然函數</a></li>
<li class="chapter" data-level="119.6" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q6-特別少的病例死亡的情況"><i class="fa fa-check"></i><b>119.6</b> Q6 特別少的病例死亡的情況</a></li>
<li class="chapter" data-level="119.7" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q7-25人中15人選a"><i class="fa fa-check"></i><b>119.7</b> Q7 25人中15人選A</a></li>
<li class="chapter" data-level="119.8" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q8-40人中24人選a"><i class="fa fa-check"></i><b>119.8</b> Q8 40人中24人選A</a></li>
<li class="chapter" data-level="119.9" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q9-60人中36人選a"><i class="fa fa-check"></i><b>119.9</b> Q9 60人中36人選A</a></li>
<li class="chapter" data-level="119.10" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q10-繪製精確-exact-和-近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.10</b> Q10 繪製精確 exact 和 近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.11" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q11-繼續繪製精確-exact-和近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.11</b> Q11 繼續繪製精確 exact 和近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.12" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q12-繼續繪製精確-exact-和-近似-approximate-對數似然比函數"><i class="fa fa-check"></i><b>119.12</b> Q12 繼續繪製精確 exact 和 近似 approximate 對數似然比函數</a></li>
<li class="chapter" data-level="119.13" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q13-2人死亡18人存活的實驗"><i class="fa fa-check"></i><b>119.13</b> Q13 2人死亡18人存活的實驗</a></li>
<li class="chapter" data-level="119.14" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q14-對數比值-logodds-的對數似然比函數"><i class="fa fa-check"></i><b>119.14</b> Q14 對數比值 logodds 的對數似然比函數</a></li>
<li class="chapter" data-level="119.15" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q15-繪製泊松分佈的對數似然比函數"><i class="fa fa-check"></i><b>119.15</b> Q15 繪製泊松分佈的對數似然比函數</a></li>
<li class="chapter" data-level="119.16" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q16-繪製泊松分佈的對數率的對數似然比函數"><i class="fa fa-check"></i><b>119.16</b> Q16 繪製泊松分佈的對數率的對數似然比函數</a></li>
<li class="chapter" data-level="119.17" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#q17-繪製極端情況下的泊松分佈對數似然比函數"><i class="fa fa-check"></i><b>119.17</b> Q17 繪製極端情況下的泊松分佈對數似然比函數</a></li>
<li class="chapter" data-level="119.18" data-path="似然的概念和圖形理解-likelihood.html"><a href="似然的概念和圖形理解-likelihood.html#關鍵點"><i class="fa fa-check"></i><b>119.18</b> 關鍵點</a></li>
</ul></li>
<li class="chapter" data-level="120" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><i class="fa fa-check"></i><b>120</b> 邏輯回歸模型1 - 單一暴露變量 Logistic regression 1 - effect of a single exposure</a>
<ul>
<li class="chapter" data-level="120.1" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q1-q2-讀入-mortality.dta-數據"><i class="fa fa-check"></i><b>120.1</b> Q1-Q2 讀入 <code>mortality.dta</code> 數據</a></li>
<li class="chapter" data-level="120.2" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q3-結果變量-died"><i class="fa fa-check"></i><b>120.2</b> Q3 結果變量 <code>died</code></a></li>
<li class="chapter" data-level="120.3" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q4-5-第一個簡單邏輯回歸模型"><i class="fa fa-check"></i><b>120.3</b> Q4-5 第一個簡單邏輯回歸模型</a></li>
<li class="chapter" data-level="120.4" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q6-給出-or-值"><i class="fa fa-check"></i><b>120.4</b> Q6 給出 OR 值</a></li>
<li class="chapter" data-level="120.5" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q7-彙總成報告用的表格"><i class="fa fa-check"></i><b>120.5</b> Q7 彙總成報告用的表格</a></li>
<li class="chapter" data-level="120.6" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q8-瞭解微小絲蟲傳染病-microfilarial-infection-和死亡之間的關係"><i class="fa fa-check"></i><b>120.6</b> Q8 瞭解微小絲蟲傳染病 (microfilarial infection) 和死亡之間的關係</a></li>
<li class="chapter" data-level="120.7" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q9-使用指示變量-indicator-variable"><i class="fa fa-check"></i><b>120.7</b> Q9 使用指示變量 indicator variable</a></li>
<li class="chapter" data-level="120.8" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q10-計算比值比"><i class="fa fa-check"></i><b>120.8</b> Q10 計算比值比</a></li>
<li class="chapter" data-level="120.9" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q11-簡單陳述上述分析的結果"><i class="fa fa-check"></i><b>120.9</b> Q11 簡單陳述上述分析的結果</a></li>
<li class="chapter" data-level="120.10" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q12-似然比檢驗用於模型比較"><i class="fa fa-check"></i><b>120.10</b> Q12 似然比檢驗用於模型比較</a></li>
<li class="chapter" data-level="120.11" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#q13-分析年齡組和死亡之間的關係"><i class="fa fa-check"></i><b>120.11</b> Q13 分析年齡組和死亡之間的關係</a></li>
<li class="chapter" data-level="120.12" data-path="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html"><a href="邏輯回歸模型1---單一暴露變量-logistic-regression-1---effect-of-a-single-exposure.html#分析要點"><i class="fa fa-check"></i><b>120.12</b> 分析要點</a></li>
</ul></li>
<li class="chapter" data-level="121" data-path="邏輯回歸模型2---多於一個預測變量的模型-logistic-regression-2---models-with-more-than-one-variable.html"><a href="邏輯回歸模型2---多於一個預測變量的模型-logistic-regression-2---models-with-more-than-one-variable.html"><i class="fa fa-check"></i><b>121</b> 邏輯回歸模型2 - 多於一個預測變量的模型 Logistic regression 2 - models with more than one variable</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a>
<ul>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html#rsession"><i class="fa fa-check"></i>以下是我的 R 進程信息</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本書由 bookdown 強力驅動</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="貝葉斯廣義線性回歸-bayesian-glm" class="section level1 hasAnchor" number="53">
<h1><span class="header-section-number">第 53 章</span> 貝葉斯廣義線性回歸 Bayesian GLM<a href="貝葉斯廣義線性回歸-bayesian-glm.html#貝葉斯廣義線性回歸-bayesian-glm" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<dl>
<dt>Bayesian updating is entropy maximization…. Information entropy is a way of counting how many unique arrangements correspond to a distribution.</dt>
<dd>
Richard McElreath
</dd>
</dl>
</blockquote>
<blockquote>
<p>A sensitivity analysis explores how changes in assumptions influence inference. If none of the alternative assumptions you consider have much impact on inference, that’s worth reporting. Likewise, if the alternatives you consider to have an important impact on inference, that’s also worth reporting.</p>
</blockquote>
<div id="二項式回歸模型-binomial-regression" class="section level2 hasAnchor" number="53.1">
<h2><span class="header-section-number">53.1</span> 二項式回歸模型 binomial regression<a href="貝葉斯廣義線性回歸-bayesian-glm.html#二項式回歸模型-binomial-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>二項分佈通常標記爲：</p>
<p><span class="math display">\[
y \sim \text{Binomial}(n, p)
\]</span></p>
<p>其中，</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(y\)</span> 是一個計數結果，可以是 0，或者其他正整數；</li>
<li><span class="math inline">\(p\)</span> 是每個試驗 (trial) 成功（或者失敗）的概率；</li>
<li><span class="math inline">\(n\)</span> 是實施試驗的總次數。</li>
</ol>
<p>一共有兩種類型的廣義線性回歸模型會使用到二項分佈的概率方程，他們本身其實也是同一種模型，只是由於數據被歸納成了不同的形式：</p>
<ol style="list-style-type: decimal">
<li>邏輯回歸 logistic regression，適應的數據是把每一次的試驗結果單獨列出來的格式，此時結果變量只有兩個取值，0 或 1。</li>
<li>歸納數據的二項回歸模型 aggregated binomial regression，適應的數據類型是，把相同共變量的試驗歸納之後的數據，此時結果變量可以取 0 至 n 之間的任意正整數。</li>
</ol>
<p>不論是上述哪種二項式回歸，使用的鏈接方程都是邏輯函數 logit function。</p>
<div id="chimpanzees" class="section level3 hasAnchor" number="53.1.1">
<h3><span class="header-section-number">53.1.1</span> 邏輯回歸模型數據實例：prosocial chimpanzees<a href="貝葉斯廣義線性回歸-bayesian-glm.html#chimpanzees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb866-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb866-1" tabindex="-1"></a><span class="fu">data</span>(chimpanzees)</span>
<span id="cb866-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb866-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> chimpanzees</span>
<span id="cb866-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb866-3" tabindex="-1"></a><span class="fu">str</span>(d)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    504 obs. of  8 variables:
##  $ actor       : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ recipient   : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ condition   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ block       : int  1 1 1 1 1 1 2 2 2 2 ...
##  $ trial       : int  2 4 6 8 10 12 14 16 18 20 ...
##  $ prosoc_left : int  0 0 1 0 1 1 1 1 0 0 ...
##  $ chose_prosoc: int  1 0 0 1 1 1 0 0 1 1 ...
##  $ pulled_left : int  0 1 0 0 1 1 0 0 0 0 ...</code></pre>
<p>上述數據其實來自 <span class="citation">(<a href="#ref-silk2005chimpanzees">Silk et al. 2005</a>)</span> ，該實驗講的是針對類人猿或者黑猩猩做的社會學實驗。設計是這樣的，在一張桌子上擺了四個盤子和兩個槓桿。其中東側槓桿，西側槓桿的功能是相同的，就是分別把放在槓桿裝置上的兩個盤子送往桌子的南北兩側。其中一側槓桿控制的兩個盤子裏只有一個裝有食物，另一側槓桿控制的兩個盤子都裝有食物。社會學研究做的實驗是，讓參加實驗的黑猩猩自行選擇搖動東側還是西側的槓桿。但是有的黑猩猩的對面會坐另外一只不能控制槓桿的同類。當相同的實驗在人類學生羣體中實施的時候，幾乎所有對面還坐有另一名學生的實驗學生都選擇了去搖動能夠控制兩盤食物的槓桿，也就是傾向於讓對面的同類也能獲得食物而不是只選擇自己有食物。這被叫做社會傾向化 (prosocial option)。於是我們的疑問是，是否類人猿黑猩猩也會有相似的行爲呢？也就是當對面也坐有同類時會作出社會傾向化的選擇呢？</p>
<p>上述數據中的兩個變量是特別關鍵的，</p>
<ul>
<li><code>prosoc_left</code>: 二進制變量，0 表示右側槓桿是社會傾向化，1 表示左側槓桿是社會傾向化。</li>
<li><code>condition</code>: 二進制變量，0 表示對面沒有同伴，1 表示對面坐有同伴。</li>
</ul>
<p>也就是說，在我們的模型中，我們希望研究這兩個變量之間是不是存在交互作用。我們希望分析下列四種情況下，類人猿黑猩猩作出的選擇：</p>
<ul>
<li><code>prosoc_left = 0</code> and <code>condition = 0</code>，右側槓桿有兩份食物，對面沒有同伴；</li>
<li><code>prosoc_left = 1</code> and <code>condition = 0</code>，左側槓桿有兩份食物，對面沒有同伴；</li>
<li><code>prosoc_left = 0</code> and <code>condition = 1</code>，右側槓桿有兩份食物，對面有同伴；</li>
<li><code>prosoc_left = 1</code> and <code>condition = 1</code>，左側槓桿有兩份食物，對面有同伴；</li>
</ul>
<p>熟悉廣義線性回歸模型，比如邏輯回歸模型的朋友可能最開始想到的方法是用上述啞變量來建立簡單的交互作用項放在模型結構裏就可以解決問題了。但是我們知道使用啞變量的缺點是使得先驗概率分佈的設定變得困難，所以我們希望不要使用啞變量的方法，轉而使用更加靈活的索引變量法 (index variable):</p>
<div class="sourceCode" id="cb868"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb868-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb868-1" tabindex="-1"></a>d<span class="sc">$</span>treatment <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> d<span class="sc">$</span>prosoc_left <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> d<span class="sc">$</span>condition</span>
<span id="cb868-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb868-2" tabindex="-1"></a><span class="fu">xtabs</span>( <span class="sc">~</span> treatment <span class="sc">+</span> prosoc_left <span class="sc">+</span> condition, d)</span></code></pre></div>
<pre><code>## , , condition = 0
## 
##          prosoc_left
## treatment   0   1
##         1 126   0
##         2   0 126
##         3   0   0
##         4   0   0
## 
## , , condition = 1
## 
##          prosoc_left
## treatment   0   1
##         1   0   0
##         2   0   0
##         3 126   0
##         4   0 126</code></pre>
<p>於是，我們現在可以把這個實驗蘊含的數學模型寫下來：</p>
<p><span class="math display">\[
\begin{aligned}
L_i &amp; \sim \text{Binomial}(1, p_i) \\
\text{logit}(p_i) &amp; = \alpha_{\text{ACTOR}[i]} + \beta_{\text{TREATMENT}[i]} \\
\alpha_j &amp; \sim \text{To be determined} \\
\beta_k &amp; \sim \text{To be determined} \\
\end{aligned}
\]</span></p>
<p>這裏的 <span class="math inline">\(L_i \sim \text{Binomial}(1, p_i)\)</span> 其實等價於 <span class="math inline">\(L_i \sim \text{Bernoulli}(p_i)\)</span>。同時我們還需要決定每個參數的先驗概率分佈。其中有七隻黑猩猩，所以有 7 個 <span class="math inline">\(\alpha\)</span> 的先驗概率，還有 4 個回歸係數 <span class="math inline">\(\beta\)</span> 屬於上面描述的四種不同的條件。</p>
<p>在思考如何給這些參數設定先驗概率分佈時，我們先從最簡單的一個邏輯回歸模型出發：</p>
<p><span class="math display">\[
\begin{aligned}
L_i &amp; \sim \text{Binomial}(1, p_i) \\
\text{logit}(p_i) &amp; = \alpha \\
\alpha &amp; \sim \text{Normal}(0, \omega)
\end{aligned}
\]</span></p>
<p>這時，我們需要先決定這個 <span class="math inline">\(\omega\)</span> 作爲一個合理的先驗概率分佈。我們先從相當平坦的一個分佈開始，例如 <span class="math inline">\(\omega = 10\)</span>。</p>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb870-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-1" tabindex="-1"></a>m11<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb870-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-2" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb870-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-3" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb870-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-4" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a, </span>
<span id="cb870-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-5" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="dv">10</span> )</span>
<span id="cb870-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-6" tabindex="-1"></a>  ), <span class="at">data =</span> d</span>
<span id="cb870-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb870-7" tabindex="-1"></a>)</span></code></pre></div>
<p>接下來，我們從 <code>m11.1</code> 中的先驗概率採集一些樣本：</p>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb871-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb871-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1999</span>) </span>
<span id="cb871-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb871-2" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">extract.prior</span>( m11<span class="fl">.1</span>, <span class="at">n =</span> <span class="dv">10000</span>)</span></code></pre></div>
<p>接下來還有一步，就是要把數據通過鏈接函數的逆函數轉換回去原來的 0-1 之間的概率尺度。對於邏輯回歸來說，鏈接函數就是 <code>logit</code> 函數，其逆函數就是 <code>inv_logit</code>。</p>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb872-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-1" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">inv_logit</span>( prior<span class="sc">$</span>a )</span>
<span id="cb872-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-2" tabindex="-1"></a><span class="fu">dens</span>( p, <span class="at">adj =</span> <span class="fl">0.1</span> ,</span>
<span id="cb872-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-3" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb872-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-4" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;prior prob pull left&quot;</span>)</span>
<span id="cb872-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-5" tabindex="-1"></a>m11<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb872-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-6" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb872-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-7" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb872-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-8" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a, </span>
<span id="cb872-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-9" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> )</span>
<span id="cb872-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-10" tabindex="-1"></a>  ), <span class="at">data =</span> d</span>
<span id="cb872-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-11" tabindex="-1"></a>)</span>
<span id="cb872-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-12" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1999</span>) </span>
<span id="cb872-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-13" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">extract.prior</span>( m11<span class="fl">.1</span>, <span class="at">n =</span> <span class="dv">10000</span>)</span>
<span id="cb872-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-14" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">inv_logit</span>( prior<span class="sc">$</span>a )</span>
<span id="cb872-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-15" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">density</span>(p1), <span class="at">adj =</span> <span class="fl">0.1</span>, </span>
<span id="cb872-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-16" tabindex="-1"></a>       <span class="at">col =</span> rangi2)</span>
<span id="cb872-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-17" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.15</span>, <span class="dv">9</span>, <span class="st">&quot;a ~ dnorm(0, 10)&quot;</span>)</span>
<span id="cb872-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb872-18" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.5</span>, <span class="fl">1.8</span>, <span class="st">&quot;a ~ dnorm(0, 1.5)&quot;</span>, <span class="at">col =</span> rangi2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig01"></span>
<img src="bookdown_files/figure-html/introBayes13-fig01-1.png" alt="Prior predictive simulations for the most basic logistic regression. A flat Normal(0, 10) prior on the intercept produces a very non-flat prior distribution on the outcome scale. A more concentrated Normal(0, 1.5) prior produces something more reasonable (blue)." width="576" />
<p class="caption">
圖 53.1: Prior predictive simulations for the most basic logistic regression. A flat Normal(0, 10) prior on the intercept produces a very non-flat prior distribution on the outcome scale. A more concentrated Normal(0, 1.5) prior produces something more reasonable (blue).
</p>
</div>
<p>圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig01">53.1</a> 給出的先驗概率是多麼地不合理，它把大部分的概率權重都分配給了0，或者1附近的概率。這代表什麼含義呢？ 如果你使用 <span class="math inline">\(\alpha \sim \text{Normal}(0,10)\)</span> 作爲截距的先驗概率分佈，代表你初期的設定是，在還沒有開始進行實驗之前，我們認爲實驗對象的黑猩猩要麼總是去拉左手的槓桿，要麼永遠都不去拉左手槓桿。這其實不用說也知道是十分不合理的。如果我們把 <span class="math inline">\(\omega = 1.5\)</span> 作爲先驗概率分佈的方差的話，給出的圖形，會合理地多 (圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig01">53.1</a> 中藍色概率密度曲線)。</p>
<p>這裏告訴我們的是，一個先驗概率分佈在 logit 尺度上的平坦分佈，在回到原來的概率尺度上的時候，會給出事與願違的非平坦分佈結果。</p>
<p>接下來我們再來考慮不同條件下的回歸係數 <span class="math inline">\(\beta\)</span>，在這裏，術語可以使用治療效果 (treatment effect) 來表達。假如我們再次自作聰明地使用平坦的分佈 <span class="math inline">\(\text{Normal}(0,10)\)</span> 作先驗概率分佈，看它會給出怎樣的結果：</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb873-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-1" tabindex="-1"></a>m11<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb873-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-2" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb873-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-3" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb873-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-4" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a <span class="sc">+</span> b[treatment], </span>
<span id="cb873-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-5" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb873-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-6" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="dv">10</span> )</span>
<span id="cb873-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-7" tabindex="-1"></a>  ), <span class="at">data =</span> d</span>
<span id="cb873-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-8" tabindex="-1"></a>)</span>
<span id="cb873-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1999</span>)</span>
<span id="cb873-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-10" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">extract.prior</span>( m11<span class="fl">.2</span>, <span class="at">n =</span> <span class="dv">10000</span>) </span>
<span id="cb873-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-11" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="cf">function</span>(k) <span class="fu">inv_logit</span>(prior<span class="sc">$</span>a <span class="sc">+</span> prior<span class="sc">$</span>b[, k]))</span>
<span id="cb873-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-12" tabindex="-1"></a><span class="fu">dens</span>(<span class="fu">abs</span>(p[,<span class="dv">1</span>] <span class="sc">-</span> p[,<span class="dv">2</span>]), <span class="at">adj =</span> <span class="fl">0.1</span>, </span>
<span id="cb873-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-13" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb873-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-14" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;prior diff between treatments&quot;</span>)</span>
<span id="cb873-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-15" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="dv">9</span>, <span class="st">&quot;b ~ dnorm(0, 10)&quot;</span>)</span>
<span id="cb873-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-16" tabindex="-1"></a></span>
<span id="cb873-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-17" tabindex="-1"></a>m11.<span class="fl">2.1</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb873-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-18" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb873-19"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-19" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb873-20"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-20" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a <span class="sc">+</span> b[treatment], </span>
<span id="cb873-21"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-21" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb873-22"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-22" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> )</span>
<span id="cb873-23"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-23" tabindex="-1"></a>  ), <span class="at">data =</span> d</span>
<span id="cb873-24"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-24" tabindex="-1"></a>)</span>
<span id="cb873-25"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-25" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1999</span>)</span>
<span id="cb873-26"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-26" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">extract.prior</span>( m11.<span class="fl">2.1</span>, <span class="at">n =</span> <span class="dv">10000</span>) </span>
<span id="cb873-27"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-27" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="cf">function</span>(k) <span class="fu">inv_logit</span>(prior<span class="sc">$</span>a <span class="sc">+</span> prior<span class="sc">$</span>b[, k]))</span>
<span id="cb873-28"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-28" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">abs</span>(p1[,<span class="dv">1</span>] <span class="sc">-</span> p1[,<span class="dv">2</span>])), <span class="at">adj =</span> <span class="fl">0.1</span>, </span>
<span id="cb873-29"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-29" tabindex="-1"></a>       <span class="at">col =</span> rangi2)</span>
<span id="cb873-30"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb873-30" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.3</span>, <span class="dv">4</span>, <span class="st">&quot;b ~ dnorm(0, 0.5)&quot;</span>, <span class="at">col =</span> rangi2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig02"></span>
<img src="bookdown_files/figure-html/introBayes13-fig02-1.png" alt="Prior predictive simulations for the most basic logistic regression. A flat Normal(0, 10) prior on the treatment effect also produces a very non-flat prior distribution on the outcome scale. A more concentrated Normal(0, 0.5) prior produces something more reasonable (blue)." width="576" />
<p class="caption">
圖 53.2: Prior predictive simulations for the most basic logistic regression. A flat Normal(0, 10) prior on the treatment effect also produces a very non-flat prior distribution on the outcome scale. A more concentrated Normal(0, 0.5) prior produces something more reasonable (blue).
</p>
</div>
<p>修改了先驗概率分佈的方差 <span class="math inline">\(\omega = 0.5\)</span> 之後，我們發現大部分的概率密度被分配到了 0 附近而不是原來的非 0 即 1。但是此時的先驗療效差的平均值是：</p>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb874-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb874-1" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(p1[,<span class="dv">1</span>] <span class="sc">-</span> p1[,<span class="dv">2</span>]))</span></code></pre></div>
<pre><code>## [1] 0.098386632</code></pre>
<p>也就是 10% 左右的療效差，也就是不同條件下的概率不至於變得非常大。</p>
<p>於是我們搞定了該怎樣設定先驗概率的問題之後，進入數據準備，和模型的運行階段：</p>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb876-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-1" tabindex="-1"></a><span class="co"># trimmed data list </span></span>
<span id="cb876-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-2" tabindex="-1"></a>dat_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb876-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-3" tabindex="-1"></a>  <span class="at">pulled_left =</span> d<span class="sc">$</span>pulled_left, </span>
<span id="cb876-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-4" tabindex="-1"></a>  <span class="at">actor =</span> d<span class="sc">$</span>actor, </span>
<span id="cb876-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-5" tabindex="-1"></a>  <span class="at">treatment =</span> <span class="fu">as.integer</span>(d<span class="sc">$</span>treatment)</span>
<span id="cb876-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb876-6" tabindex="-1"></a>)</span></code></pre></div>
<p>數據準備好了以後，讓我們來使用 Markov Chain 運行這個邏輯回歸模型：</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-1" tabindex="-1"></a>m11<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb877-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-2" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb877-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-3" tabindex="-1"></a>    pulled_left <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb877-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-4" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[actor] <span class="sc">+</span> b[treatment], </span>
<span id="cb877-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-5" tabindex="-1"></a>    a[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb877-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-6" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> )</span>
<span id="cb877-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-7" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb877-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-8" tabindex="-1"></a>)</span>
<span id="cb877-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-9" tabindex="-1"></a></span>
<span id="cb877-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb877-10" tabindex="-1"></a><span class="fu">saveRDS</span>(m11<span class="fl">.4</span>, <span class="st">&quot;../Stanfits/m11_4.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb878-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb878-1" tabindex="-1"></a>m11<span class="fl">.4</span> <span class="ot">&lt;-</span>  <span class="fu">readRDS</span>(<span class="st">&quot;../Stanfits/m11_4.rds&quot;</span>)</span>
<span id="cb878-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb878-2" tabindex="-1"></a><span class="fu">precis</span>( m11<span class="fl">.4</span>, <span class="at">depth =</span> <span class="dv">2</span> )</span></code></pre></div>
<pre><code>##              mean         sd         5.5%        94.5%      n_eff      Rhat4
## a[1] -0.429942287 0.32559257 -0.946149825  0.104632565  832.88104 1.00258538
## a[2]  3.892282215 0.72040443  2.860756100  5.111318250 1661.26882 0.99943327
## a[3] -0.739816999 0.32292436 -1.264098750 -0.221254185  737.34692 1.00083906
## a[4] -0.734329668 0.31720925 -1.242542250 -0.229930505  738.26644 1.00081553
## a[5] -0.435195703 0.32629350 -0.947177970  0.092516450  770.97726 1.00122673
## a[6]  0.496271511 0.32303636 -0.014015981  1.027858700  740.59441 1.00383901
## a[7]  1.966138568 0.42321369  1.305282550  2.660314500 1132.59230 0.99981816
## b[1] -0.052332863 0.27477956 -0.492390840  0.375459205  703.79445 1.00129414
## b[2]  0.467946661 0.27569364  0.025882383  0.918256995  651.08788 1.00594527
## b[3] -0.401369705 0.27283765 -0.831073830  0.027599697  736.85875 1.00230582
## b[4]  0.356327179 0.27327018 -0.079038555  0.791810265  701.55693 1.00334895</code></pre>
<p>這個模型 <code>m11.4</code> 的實際 Stan 代碼是:</p>
<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb880-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb880-1" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">stancode</span>(m11<span class="fl">.4</span>)</span></code></pre></div>
<pre><code>## data{
##     int pulled_left[504];
##     int treatment[504];
##     int actor[504];
## }
## parameters{
##     vector[7] a;
##     vector[4] b;
## }
## model{
##     vector[504] p;
##     b ~ normal( 0 , 0.5 );
##     a ~ normal( 0 , 1.5 );
##     for ( i in 1:504 ) {
##         p[i] = a[actor[i]] + b[treatment[i]];
##         p[i] = inv_logit(p[i]);
##     }
##     pulled_left ~ binomial( 1 , p );
## }
## generated quantities{
##     vector[504] log_lik;
##     vector[504] p;
##     for ( i in 1:504 ) {
##         p[i] = a[actor[i]] + b[treatment[i]];
##         p[i] = inv_logit(p[i]);
##     }
##     for ( i in 1:504 ) log_lik[i] = binomial_lpmf( pulled_left[i] | 1 , p[i] );
## }</code></pre>
<p>上述模型運行的結果中，前面 7 個每隻黑猩猩的截距，也就是代表了每隻黑猩猩本身會主動去拉動左邊槓桿的傾向性。我們來把這個數據轉換到它本身應該有的數據尺度上來看：</p>
<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb882-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb882-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m11<span class="fl">.4</span>)</span>
<span id="cb882-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb882-2" tabindex="-1"></a>p_left <span class="ot">&lt;-</span> <span class="fu">inv_logit</span>( post<span class="sc">$</span>a )</span>
<span id="cb882-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb882-3" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">precis</span>(<span class="fu">as.data.frame</span>(p_left)), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig03"></span>
<img src="bookdown_files/figure-html/introBayes13-fig03-1.png" alt="The intercepts unique to each chimpanzee, on the probability scale." width="624" />
<p class="caption">
圖 53.3: The intercepts unique to each chimpanzee, on the probability scale.
</p>
</div>
<p>可以看到，比較明顯的傾向於去拉右側槓桿的是1，3，4，5這四隻黑猩猩。2號和7號黑猩猩則體現出了相反的興趣。這是每隻黑猩猩本身對於拉左右兩側哪隻槓桿的最基本的傾向性分析。接下來我們來看不同的條件下的效果差別：</p>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb883-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb883-1" tabindex="-1"></a>labs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;R/N&quot;</span>, <span class="st">&quot;L/N&quot;</span>, <span class="st">&quot;R/P&quot;</span>, <span class="st">&quot;L/P&quot;</span>)</span>
<span id="cb883-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb883-2" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">precis</span>(m11<span class="fl">.4</span>, <span class="at">depth =</span> <span class="dv">2</span>, <span class="at">pars =</span> <span class="st">&quot;b&quot;</span>), <span class="at">labels =</span> labs)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig04"></span>
<img src="bookdown_files/figure-html/introBayes13-fig04-1.png" alt="The treatment effect by different conditions, on the log-odds scale." width="624" />
<p class="caption">
圖 53.4: The treatment effect by different conditions, on the log-odds scale.
</p>
</div>
<p>我們通過該實驗希望獲得的分析結果是，到底桌子對面坐與不坐同類，黑猩猩是否會作出不同的社會化傾向選擇？也就是黑猩猩是否會根據對面有沒有同類而去拉那個有兩個食物那一側的槓桿。這意味着我們希望比較的是第一行和第三行，也就是當兩份食物都在右側槓桿時，對面有沒有同類是否會改變黑猩猩拉動右側槓桿的選擇；同時我們也希望比較第二行和第四行的結果，也就是兩份食物都在左側槓桿時，對面有沒有同類是否會改變黑猩猩拉動左側槓桿的選擇。其實我們看圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig04">53.4</a> 已經能夠猜出大概沒有差異的的結果了。但是我們是可以對這兩個條件下的差異作出比較，並計算其可信區間的：</p>
<div class="sourceCode" id="cb884"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb884-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-1" tabindex="-1"></a>diffs <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb884-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-2" tabindex="-1"></a>  <span class="at">db13 =</span> post<span class="sc">$</span>b[, <span class="dv">1</span>] <span class="sc">-</span> post<span class="sc">$</span>b[, <span class="dv">3</span>], </span>
<span id="cb884-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-3" tabindex="-1"></a>  <span class="at">db24 =</span> post<span class="sc">$</span>b[, <span class="dv">2</span>] <span class="sc">-</span> post<span class="sc">$</span>b[, <span class="dv">4</span>]</span>
<span id="cb884-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-4" tabindex="-1"></a>)</span>
<span id="cb884-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-5" tabindex="-1"></a></span>
<span id="cb884-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb884-6" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(diffs))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig05"></span>
<img src="bookdown_files/figure-html/introBayes13-fig05-1.png" alt="The treatment effect difference compared between R/N R/P, and L/N L/P, on the log-odds scale." width="624" />
<p class="caption">
圖 53.5: The treatment effect difference compared between R/N R/P, and L/N L/P, on the log-odds scale.
</p>
</div>
<p><code>db13, db14</code> 就是我們希望求的比較有/沒有同伴坐在桌子對面是否影響黑猩猩作出社會化傾向選擇的療效差異 (the contrast between the no-partner/partner treatments)。<code>db13</code> 的準確解釋是，當右側槓桿控制兩份食物時，對面有同伴/沒有同伴的情況下，黑猩猩會傾向於去使用左側槓桿的療效差異 (treatment effect difference)。所以，如果有證據證明有同伴的情況下，黑猩猩會傾向於作出社會化選擇，那麼我們應該會看到不等於零的療效差異，也就是會在有同伴的時候更多的去拉右邊的槓桿。但其實 <code>db13</code> 的結果似乎顯示有微弱的證據證明，當沒有同伴時，黑猩猩會略微更多的傾向於拉左邊槓桿（沒有社會化傾向），當然這個證據很微弱，可信區間也包括沒有療效差異的 0。相似地，<code>db24</code> 比較的是，當兩份食物出現在左側槓桿時，對面有同伴/沒有同伴情況之間拉動左側槓桿的療效差異。如果我們期待黑猩猩會作出會社會化傾向選擇當對面坐有同伴的話，我們會希望這個 <code>db24</code> 的取值會顯著小於零，但事實上卻沒有符合這樣期待的結果。</p>
<p>我們可以利用上述運行好的模型結果來進行事後的預測，爲每一只黑猩猩估計它在四種條件下主動去拉左側槓桿的概率。同時我們還可以把它們和每隻黑猩猩實際觀察到的拉動左側槓桿概率作直觀的比較：</p>
<p>下面的代碼計算出的是一個 <span class="math inline">\(7\times 4\)</span> 的矩陣，每一行有四列結果，代表7只黑猩猩在4中條件下實際觀察到拉動左側槓桿的概率，其中第一只黑猩猩的四種條件下拉動左側槓桿的概率分別是：<code>0.3333 0.5000 0.2778 0.5556</code>。</p>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb885-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb885-1" tabindex="-1"></a>pl <span class="ot">&lt;-</span> <span class="fu">by</span>( d<span class="sc">$</span>pulled_left, <span class="fu">list</span>(d<span class="sc">$</span>actor, d<span class="sc">$</span>treatment), mean)</span>
<span id="cb885-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb885-2" tabindex="-1"></a>pl[<span class="dv">1</span>, ]</span></code></pre></div>
<pre><code>##          1          2          3          4 
## 0.33333333 0.50000000 0.27777778 0.55555556</code></pre>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb887-1" tabindex="-1"></a><span class="fu">str</span>(pl)</span></code></pre></div>
<pre><code>##  &#39;by&#39; num [1:7, 1:4] 0.333 1 0.278 0.333 0.333 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : chr [1:7] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   ..$ : chr [1:4] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot;
##  - attr(*, &quot;call&quot;)= language by.default(data = d$pulled_left, INDICES = list(d$actor, d$treatment), FUN = mean)</code></pre>
<p>把每隻猩猩的四個條件下的觀察值散點圖繪製如下圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig06">53.6</a>：</p>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">28</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb889-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-2" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;proportion left lever&quot;</span>, <span class="at">xaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="at">yaxt =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb889-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-3" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.2</span>), <span class="at">labels =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.2</span>))</span>
<span id="cb889-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-4" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">2</span> )</span>
<span id="cb889-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-5" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> ) <span class="fu">abline</span>( <span class="at">v =</span> (j <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fl">4.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb889-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-6" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> ) <span class="fu">text</span>( (j <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fl">2.5</span>, <span class="fl">1.1</span>, <span class="fu">concat</span>(<span class="st">&quot;actor &quot;</span>, j), <span class="at">xpd =</span> <span class="cn">TRUE</span>)</span>
<span id="cb889-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-7" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>)[<span class="sc">-</span><span class="dv">2</span>] ) {</span>
<span id="cb889-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-8" tabindex="-1"></a>  <span class="fu">lines</span>( (j <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">*</span><span class="dv">4</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), pl[j, <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)], <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb889-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-9" tabindex="-1"></a>  <span class="fu">lines</span>( (j <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">*</span><span class="dv">4</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>), pl[j, <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)], <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb889-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-10" tabindex="-1"></a>}</span>
<span id="cb889-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-11" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="fu">t</span>(pl), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&quot;white&quot;</span>, <span class="at">cex =</span>  <span class="fl">1.7</span>)</span>
<span id="cb889-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-12" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="fu">t</span>(pl), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">16</span>,<span class="dv">16</span>), <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb889-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-13" tabindex="-1"></a>yoff <span class="ot">&lt;-</span> <span class="fl">0.01</span></span>
<span id="cb889-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-14" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">1</span>, pl[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">-</span> yoff, <span class="st">&quot;R/N&quot;</span>, <span class="at">pos =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb889-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-15" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">2</span>, pl[<span class="dv">1</span>,<span class="dv">2</span>] <span class="sc">+</span> yoff, <span class="st">&quot;L/N&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb889-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-16" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">3</span>, pl[<span class="dv">1</span>,<span class="dv">3</span>] <span class="sc">-</span> yoff, <span class="st">&quot;R/P&quot;</span>, <span class="at">pos =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb889-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-17" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">4</span>, pl[<span class="dv">1</span>,<span class="dv">4</span>] <span class="sc">+</span> yoff, <span class="st">&quot;L/P&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb889-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb889-18" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">&quot;observed proportions</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig06"></span>
<img src="bookdown_files/figure-html/introBayes13-fig06-1.png" alt="Observed data for the chimpanzee data. Data are grouped by actor. Open points are non-partner treatments. Filled points are partner treatments. The right R and left L sides of the prosocial options are labeled in the figure." width="672" />
<p class="caption">
圖 53.6: Observed data for the chimpanzee data. Data are grouped by actor. Open points are non-partner treatments. Filled points are partner treatments. The right R and left L sides of the prosocial options are labeled in the figure.
</p>
</div>
<p>接下來我們來計算模型運行之後的這些概率的預測值。圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig07">53.7</a> 生成的代碼如下。模型本身告訴我們，有沒有同伴坐在桌子對面，基本上不會影響黑猩猩的選擇。(The model expects no change when adding a partner.) 大部分的選擇變化取決於黑猩猩本身，也就是每隻黑猩猩自己的模型截距。</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb890-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-1" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">actor =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="at">each =</span> <span class="dv">4</span>), </span>
<span id="cb890-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-2" tabindex="-1"></a>             <span class="at">treatment =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">times =</span> <span class="dv">7</span>))</span>
<span id="cb890-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-3" tabindex="-1"></a>p_post <span class="ot">&lt;-</span> <span class="fu">link</span>( m11<span class="fl">.4</span>, <span class="at">data =</span> dat )</span>
<span id="cb890-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-4" tabindex="-1"></a>p_mu <span class="ot">&lt;-</span> <span class="fu">apply</span>( p_post, <span class="dv">2</span>, mean )</span>
<span id="cb890-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-5" tabindex="-1"></a>p_ci <span class="ot">&lt;-</span> <span class="fu">apply</span>( p_post, <span class="dv">2</span>, PI )</span>
<span id="cb890-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-6" tabindex="-1"></a></span>
<span id="cb890-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-7" tabindex="-1"></a>p_mu <span class="ot">&lt;-</span> <span class="fu">matrix</span>(p_mu, <span class="at">nrow =</span> <span class="dv">7</span>, <span class="at">ncol =</span> <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb890-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-8" tabindex="-1"></a></span>
<span id="cb890-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-9" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">28</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb890-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-10" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;proportion left lever&quot;</span>, <span class="at">xaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="at">yaxt =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb890-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-11" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.2</span>), <span class="at">labels =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.2</span>))</span>
<span id="cb890-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-12" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">2</span> )</span>
<span id="cb890-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-13" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> ) <span class="fu">abline</span>( <span class="at">v =</span> (j <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fl">4.5</span>, <span class="at">lwd =</span> <span class="fl">0.5</span> )</span>
<span id="cb890-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-14" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> ) <span class="fu">text</span>( (j <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fl">2.5</span>, <span class="fl">1.1</span>, <span class="fu">concat</span>(<span class="st">&quot;actor &quot;</span>, j), <span class="at">xpd =</span> <span class="cn">TRUE</span>)</span>
<span id="cb890-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-15" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>)[<span class="sc">-</span><span class="dv">2</span>] ) {</span>
<span id="cb890-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-16" tabindex="-1"></a>  <span class="fu">lines</span>( (j <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">*</span><span class="dv">4</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), p_mu[j, <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)], <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb890-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-17" tabindex="-1"></a>  <span class="fu">lines</span>( (j <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">*</span><span class="dv">4</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>), p_mu[j, <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)], <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb890-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-18" tabindex="-1"></a>}</span>
<span id="cb890-19"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-19" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>) {</span>
<span id="cb890-20"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-20" tabindex="-1"></a>  <span class="fu">lines</span>( <span class="fu">c</span>(j, j), p_ci[<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), j], <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb890-21"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-21" tabindex="-1"></a>}</span>
<span id="cb890-22"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-22" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="fu">t</span>(p_mu), <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&quot;white&quot;</span>, <span class="at">cex =</span>  <span class="fl">1.7</span>)</span>
<span id="cb890-23"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-23" tabindex="-1"></a><span class="fu">points</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="fu">t</span>(p_mu), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">16</span>,<span class="dv">16</span>), <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb890-24"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-24" tabindex="-1"></a>yoff <span class="ot">&lt;-</span> <span class="fl">0.07</span></span>
<span id="cb890-25"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-25" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">1</span>, p_mu[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">-</span> yoff, <span class="st">&quot;R/N&quot;</span>, <span class="at">pos =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb890-26"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-26" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">2</span>, p_mu[<span class="dv">1</span>,<span class="dv">2</span>] <span class="sc">+</span> yoff, <span class="st">&quot;L/N&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb890-27"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-27" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">3</span>, p_mu[<span class="dv">1</span>,<span class="dv">3</span>] <span class="sc">-</span> yoff, <span class="st">&quot;R/P&quot;</span>, <span class="at">pos =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb890-28"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-28" tabindex="-1"></a><span class="fu">text</span>( <span class="dv">4</span>, p_mu[<span class="dv">1</span>,<span class="dv">4</span>] <span class="sc">+</span> yoff, <span class="st">&quot;L/P&quot;</span>, <span class="at">pos =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb890-29"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb890-29" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">&quot;posterior prediction proportions</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig07"></span>
<img src="bookdown_files/figure-html/introBayes13-fig07-1.png" alt="Posterior predictions for the chimpanzee data. Data are grouped by actor. Open points are non-partner treatments. Filled points are partner treatments. The right R and left L sides of the prosocial options are labeled in the figure. 89% compatibility intervals for each proportion for each actor are shown as well." width="672" />
<p class="caption">
圖 53.7: Posterior predictions for the chimpanzee data. Data are grouped by actor. Open points are non-partner treatments. Filled points are partner treatments. The right R and left L sides of the prosocial options are labeled in the figure. 89% compatibility intervals for each proportion for each actor are shown as well.
</p>
</div>
<p><code>m11.4</code> 模型實際上直接跳過了只有 <code>procosial option</code> 和 <code>partner</code> 兩個變量時的模型直接加了交互作用項的模型。下面的代碼運行的模型是沒有交互作用項的版本，我麼來比較一下兩個模型的擬合度：</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-1" tabindex="-1"></a>d<span class="sc">$</span>side <span class="ot">&lt;-</span> d<span class="sc">$</span>prosoc_left <span class="sc">+</span> <span class="dv">1</span> <span class="co"># right = 1, left = 2</span></span>
<span id="cb891-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-2" tabindex="-1"></a>d<span class="sc">$</span>cond <span class="ot">&lt;-</span> d<span class="sc">$</span>condition <span class="sc">+</span> <span class="dv">1</span> <span class="co"># no partner = 1, with partner = 2</span></span>
<span id="cb891-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-3" tabindex="-1"></a></span>
<span id="cb891-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-4" tabindex="-1"></a>dat_list2 <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb891-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-5" tabindex="-1"></a>  <span class="at">pulled_left =</span> d<span class="sc">$</span>pulled_left, </span>
<span id="cb891-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-6" tabindex="-1"></a>  <span class="at">actor =</span> d<span class="sc">$</span>actor, </span>
<span id="cb891-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-7" tabindex="-1"></a>  <span class="at">side =</span> d<span class="sc">$</span>side, </span>
<span id="cb891-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-8" tabindex="-1"></a>  <span class="at">cond =</span> d<span class="sc">$</span>cond</span>
<span id="cb891-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-9" tabindex="-1"></a>)</span>
<span id="cb891-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-10" tabindex="-1"></a></span>
<span id="cb891-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-11" tabindex="-1"></a>m11<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb891-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-12" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb891-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-13" tabindex="-1"></a>    pulled_left  <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">1</span>, p ), </span>
<span id="cb891-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-14" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[actor] <span class="sc">+</span> bs[side] <span class="sc">+</span> bc[cond] , </span>
<span id="cb891-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-15" tabindex="-1"></a>    a[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb891-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-16" tabindex="-1"></a>    bs[side] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb891-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-17" tabindex="-1"></a>    bc[cond] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> )</span>
<span id="cb891-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-18" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list2, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb891-19"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb891-19" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb893-1" tabindex="-1"></a><span class="fu">precis</span>(m11<span class="fl">.5</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##               mean         sd         5.5%        94.5%      n_eff     Rhat4
## a[1]  -0.655770413 0.43535605 -1.359676900  0.022933406  710.00083 1.0045239
## a[2]   3.743865885 0.79650038  2.538768700  5.084815100 1142.22454 1.0007099
## a[3]  -0.951412794 0.43147243 -1.620515350 -0.277939290  738.32519 1.0030614
## a[4]  -0.966171614 0.43224075 -1.649405200 -0.284136425  795.58057 1.0036848
## a[5]  -0.655961462 0.42790668 -1.339657200  0.026944903  739.66497 1.0043577
## a[6]   0.272662554 0.42780637 -0.434731340  0.951514435  769.85407 1.0024592
## a[7]   1.756695293 0.50582298  0.972839695  2.550957250  840.14229 1.0028437
## bs[1] -0.180166983 0.33200510 -0.727985335  0.356886305  771.91278 1.0032280
## bs[2]  0.503903317 0.33198302 -0.031784743  1.043773600  826.00366 1.0034213
## bc[1]  0.278262385 0.33353433 -0.248087980  0.823398375  730.26640 1.0055826
## bc[2]  0.038256826 0.33203543 -0.488788280  0.561857315  728.94709 1.0047022</code></pre>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb895-1" tabindex="-1"></a><span class="fu">compare</span>(m11<span class="fl">.5</span>, m11<span class="fl">.4</span>)</span></code></pre></div>
<pre><code>##            WAIC        SE     dWAIC       dSE     pWAIC     weight
## m11.5 531.00132 19.112666 0.0000000        NA 7.8710514 0.66681879
## m11.4 532.38899 18.937857 1.3876636 1.2797982 8.5576211 0.33318121</code></pre>
<p>我們可以看到無論是 <code>m11.5</code> 本身給出的模型運行結果，還是從模型比較給出的報告，我們都認爲加不加這個交互作用項其實沒有太大的影響。這裏只是把如何進行模型之間的比較拿來做示範而已。但是這裏我們需要用到有交互作用項的模型 <code>m11.4</code>，因爲這是該實驗設計的初衷和目的之一。</p>
</div>
<div id="相對還是絕對" class="section level3 hasAnchor" number="53.1.2">
<h3><span class="header-section-number">53.1.2</span> 相對還是絕對？<a href="貝葉斯廣義線性回歸-bayesian-glm.html#相對還是絕對" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider for example the parable of relative shark and absolute deer. People are very afraid of shark, but not so afraid of deer. But each year, deer kill many more people than sharks do. In this comparison, absolute risks are being compared: the lifetime risk of death from deer vastly exceeds the lifetime risk death from shark bite.</p>
</blockquote>
</div>
<div id="歸納後的二進制數據繼續使用黑猩猩數據" class="section level3 hasAnchor" number="53.1.3">
<h3><span class="header-section-number">53.1.3</span> 歸納後的二進制數據：繼續使用黑猩猩數據<a href="貝葉斯廣義線性回歸-bayesian-glm.html#歸納後的二進制數據繼續使用黑猩猩數據" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>前面黑猩猩數據的邏輯回歸模型實例中，我們使用的數據是每一隻黑猩猩，在每次以實驗作出的是否拉動左側槓桿的單個實驗數據 individual data。但是事實上很多數據在獲取的時候是已經被整理彙總過的。相同的信息可以被整理成更加簡約的數據形式。我們可以從原始數據計算每隻黑猩猩，在不同的實驗條件下拉動左側槓桿的次數：</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb897-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-1" tabindex="-1"></a>d_aggregated <span class="ot">&lt;-</span> <span class="fu">aggregate</span>(</span>
<span id="cb897-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-2" tabindex="-1"></a>  d<span class="sc">$</span>pulled_left, </span>
<span id="cb897-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-3" tabindex="-1"></a>  <span class="fu">list</span>( <span class="at">treatment =</span> d<span class="sc">$</span>treatment, </span>
<span id="cb897-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-4" tabindex="-1"></a>        <span class="at">actor =</span> d<span class="sc">$</span>actor, </span>
<span id="cb897-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-5" tabindex="-1"></a>        <span class="at">side =</span> d<span class="sc">$</span>side, </span>
<span id="cb897-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-6" tabindex="-1"></a>        <span class="at">cond =</span> d<span class="sc">$</span>cond), </span>
<span id="cb897-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-7" tabindex="-1"></a>  sum</span>
<span id="cb897-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-8" tabindex="-1"></a>)</span>
<span id="cb897-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-9" tabindex="-1"></a><span class="fu">colnames</span>(d_aggregated)[<span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="st">&quot;left_pulls&quot;</span></span>
<span id="cb897-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb897-10" tabindex="-1"></a><span class="fu">head</span>(d_aggregated, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##    treatment actor side cond left_pulls
## 1          1     1    1    1          6
## 2          1     2    1    1         18
## 3          1     3    1    1          5
## 4          1     4    1    1          6
## 5          1     5    1    1          6
## 6          1     6    1    1         14
## 7          1     7    1    1         14
## 8          2     1    2    1          9
## 9          2     2    2    1         18
## 10         2     3    2    1         11</code></pre>
<p>彙總後的數據中 <code>left_pulls</code> 就是不同條件下每隻黑猩猩拉動左側槓桿的次數彙總。記得2號黑猩猩始終都拉左側槓桿，所以你看 <code>actor = 2</code> 的時候 <code>left_pulls = 18</code> 都是保持不變的。也就是說，每隻黑猩猩在每種條件下都進行了總共18次的測試。接下來我們可以使用這個歸納彙總過的數據來做和 <code>m11.4</code> 完全相同的統計推斷：</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb899-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-1" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">with</span>(d_aggregated, </span>
<span id="cb899-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-2" tabindex="-1"></a>            <span class="fu">list</span>(</span>
<span id="cb899-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-3" tabindex="-1"></a>              <span class="at">left_pulls =</span> left_pulls, </span>
<span id="cb899-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-4" tabindex="-1"></a>              <span class="at">treatment =</span> treatment, </span>
<span id="cb899-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-5" tabindex="-1"></a>              <span class="at">actor =</span> actor, </span>
<span id="cb899-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-6" tabindex="-1"></a>              <span class="at">side =</span> side, </span>
<span id="cb899-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-7" tabindex="-1"></a>              <span class="at">cond =</span> cond</span>
<span id="cb899-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-8" tabindex="-1"></a>            ))</span>
<span id="cb899-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-9" tabindex="-1"></a></span>
<span id="cb899-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-10" tabindex="-1"></a>m11<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb899-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-11" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb899-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-12" tabindex="-1"></a>    left_pulls <span class="sc">~</span> <span class="fu">dbinom</span>( <span class="dv">18</span>, p ), <span class="co"># it used to be dbinom( 1, p )</span></span>
<span id="cb899-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-13" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[actor] <span class="sc">+</span> b[treatment], </span>
<span id="cb899-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-14" tabindex="-1"></a>    a[actor] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb899-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-15" tabindex="-1"></a>    b[treatment] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.5</span> )</span>
<span id="cb899-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-16" tabindex="-1"></a>  ), <span class="at">data =</span>  dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb899-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb899-17" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb901-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb901-1" tabindex="-1"></a><span class="fu">precis</span>(m11<span class="fl">.6</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##              mean         sd          5.5%        94.5%      n_eff     Rhat4
## a[1] -0.424329845 0.33225455 -0.9717962800  0.107563840  751.25275 1.0010184
## a[2]  3.905644780 0.73365840  2.8015572000  5.092984400 1175.40498 1.0040630
## a[3] -0.718862381 0.33942253 -1.2509039000 -0.176636505  656.31617 1.0034022
## a[4] -0.725620187 0.34207384 -1.2725226000 -0.199060145  729.12027 1.0020010
## a[5] -0.415109948 0.33281305 -0.9350171550  0.108374340  682.90898 1.0020564
## a[6]  0.517620115 0.33489927 -0.0177663795  1.053053200  748.53099 1.0005144
## a[7]  1.990939258 0.42751276  1.3124323500  2.691393600  939.21031 1.0017960
## b[1] -0.072113997 0.28635069 -0.5296995400  0.387299215  643.53631 1.0034820
## b[2]  0.448618561 0.29380027 -0.0050808559  0.914412720  573.56020 1.0031237
## b[3] -0.410367007 0.29251328 -0.9085838250  0.051336309  621.61493 1.0028349
## b[4]  0.340992596 0.29000128 -0.1277295450  0.807177990  629.44879 1.0026665</code></pre>
<p>運行結果和 <code>m11.4</code> 是完全一致的。但是，如果你比較 <code>m11.6, m11.4</code> 兩個模型之間卻給出了差異很大的模型特徵值：</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb903-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb903-1" tabindex="-1"></a><span class="fu">compare</span>(m11<span class="fl">.6</span>, m11<span class="fl">.4</span>, <span class="at">func =</span> PSIS)</span></code></pre></div>
<pre><code>## Warning in compare(m11.6, m11.4, func = PSIS): Different numbers of observations found for at least two models.
## Model comparison is valid only for models fit to exactly the same observations.
## Number of observations for each model:
## m11.6 28 
## m11.4 504</code></pre>
<pre><code>## Some Pareto k values are high (&gt;0.5). Set pointwise=TRUE to inspect individual points.</code></pre>
<pre><code>##            PSIS         SE     dPSIS       dSE     pPSIS        weight
## m11.6 114.22180  8.4288808   0.00000        NA 8.3931986 1.0000000e+00
## m11.4 532.45095 18.9595761 418.22915 9.4536509 8.5886007 1.5229787e-91</code></pre>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb907-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb907-1" tabindex="-1"></a><span class="fu">compare</span>(m11<span class="fl">.6</span>, m11<span class="fl">.4</span>)</span></code></pre></div>
<pre><code>## Warning in compare(m11.6, m11.4): Different numbers of observations found for at least two models.
## Model comparison is valid only for models fit to exactly the same observations.
## Number of observations for each model:
## m11.6 28 
## m11.4 504</code></pre>
<pre><code>##            WAIC         SE     dWAIC       dSE     pWAIC        weight
## m11.6 112.78542  8.0166453   0.00000        NA 7.6750096 1.0000000e+00
## m11.4 532.38899 18.9378572 419.60357 9.2283331 8.5576211 7.6602436e-92</code></pre>
<p>你看見比較之後給出很多的結果。這主要是由於數據被彙總之後和沒有被彙總之前的產生差異很大的對數概率。例如同樣是計算 <code>dbinom(6, 9, 0.2)</code>，如果是彙總型數據，它計算的概率公式還包含一個複雜的常數項：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(6|9, p) = \frac{6!}{6!(9 - 6)!}p^6 (1-p)^{9-6}
\end{aligned}
\]</span></p>
<p>計算概率的公式的前半部分 <span class="math inline">\(\frac{6!}{6!(9 - 6)!}\)</span> 雖然很醜陋，但是它是計算所有 9 次試驗中出現 6 次成功的全部可能的組合。但是當我們把數據分割成 9 個單獨的實驗數據的話，這部分醜陋的相乘項就不見了：</p>
<p><span class="math display">\[
\begin{aligned}
\text{Pr}(1,1,1,1,1,1,0,0,0 | p) = p^6 (1 - p)^{9 - 6}
\end{aligned}
\]</span></p>
<p>所以兩種數據形式，兩種模型給出的參數估計結果完全一致，但是他們兩個模型之間的特徵值差異很大。簡單地看下列計算比較兩種數據形式給出的對數概率和的結果差異有多大：</p>
<div class="sourceCode" id="cb910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb910-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb910-1" tabindex="-1"></a><span class="co"># deviance of aggregated 6-in-9</span></span>
<span id="cb910-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb910-2" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="dv">9</span>, <span class="fl">0.2</span>, <span class="at">log =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 11.790483</code></pre>
<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb912-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb912-1" tabindex="-1"></a><span class="co"># deviance of dis-aggregated</span></span>
<span id="cb912-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb912-2" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sum</span>(<span class="fu">dbern</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="fl">0.2</span>, <span class="at">log =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## [1] 20.652116</code></pre>
<p>但我們其實根本不用在乎這兩者之間模型的特徵值差異。所有模型參數的事後概率分佈估計都會是完全一致的。另外還有一個警報：<code>Model comparison is valid only for models fit to exactly the same observations.</code> 提示我們這兩個模型之間的觀察值個數不同。</p>
</div>
<div id="彙總型二進制數據大學錄取數據" class="section level3 hasAnchor" number="53.1.4">
<h3><span class="header-section-number">53.1.4</span> 彙總型二進制數據：大學錄取數據<a href="貝葉斯廣義線性回歸-bayesian-glm.html#彙總型二進制數據大學錄取數據" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>有時候不同的彙總數據，他們各自的試驗總次數不一定總是像黑猩猩數據那樣都是相同的。例如下面的大學錄取數據，一共只有12行：</p>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb914-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;UCBadmit&quot;</span>)</span>
<span id="cb914-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb914-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> UCBadmit</span>
<span id="cb914-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb914-3" tabindex="-1"></a>d</span></code></pre></div>
<pre><code>##    dept applicant.gender admit reject applications
## 1     A             male   512    313          825
## 2     A           female    89     19          108
## 3     B             male   353    207          560
## 4     B           female    17      8           25
## 5     C             male   120    205          325
## 6     C           female   202    391          593
## 7     D             male   138    279          417
## 8     D           female   131    244          375
## 9     E             male    53    138          191
## 10    E           female    94    299          393
## 11    F             male    22    351          373
## 12    F           female    24    317          341</code></pre>
<p>該數據是某大學的6個研究生院的申請人數，被拒人數，合格人數的彙總。雖然每個申請人都有單獨的數據，但是上面的彙總後數據把這些申請數據根據每個學院，和申請人的性別進行了彙總，所以最後只剩下12行，但是這12行的數據其實包含了總數爲 4526 個學生的研究生院申請結果。我們來使用這個數據分析一下性別是否在錄取結果上造成了影響。爲了回答這個問題，我們希望建立一個結果變量是錄取結果 <code>admit</code> ，預測變量是申請人性別 <code>applicant.gender</code> 的邏輯回歸模型。用數學模型可以描述爲：</p>
<p><span class="math display">\[
\begin{aligned}
A_i &amp; \sim \text{Binomial}(N_i, p_i) \\
\text{logit}(p_i) &amp; = \alpha_{\text{GID}[i]} \\
\alpha_j &amp; \sim \text{Normal}(0, 1.5)
\end{aligned}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(N_i\)</span> 是第 <span class="math inline">\(i\)</span> 行數據的申請人數 <code>applications[i]</code></li>
<li><span class="math inline">\(\text{GID}[i]\)</span> 表示申請人的性別，1 是男性，2 是女性</li>
</ul>
<p>我們來把該數學模型描述成代碼：</p>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb916-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-1" tabindex="-1"></a>dat_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb916-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-2" tabindex="-1"></a>  <span class="at">admit =</span> d<span class="sc">$</span>admit, </span>
<span id="cb916-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-3" tabindex="-1"></a>  <span class="at">applications =</span> d<span class="sc">$</span>applications, </span>
<span id="cb916-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-4" tabindex="-1"></a>  <span class="at">gid =</span> <span class="fu">ifelse</span>( d<span class="sc">$</span>applicant.gender <span class="sc">==</span> <span class="st">&quot;male&quot;</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb916-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-5" tabindex="-1"></a>)</span>
<span id="cb916-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-6" tabindex="-1"></a></span>
<span id="cb916-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-7" tabindex="-1"></a>m11<span class="fl">.7</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb916-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-8" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb916-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-9" tabindex="-1"></a>    admit <span class="sc">~</span> <span class="fu">dbinom</span>( applications, p ), </span>
<span id="cb916-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-10" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span>  a[gid], </span>
<span id="cb916-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-11" tabindex="-1"></a>    a[gid] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> )</span>
<span id="cb916-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-12" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb916-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb916-13" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb918-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb918-1" tabindex="-1"></a><span class="fu">precis</span>(m11<span class="fl">.7</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##             mean          sd        5.5%       94.5%     n_eff     Rhat4
## a[1] -0.21799527 0.038609347 -0.27828884 -0.15524484 1329.7855 1.0002221
## a[2] -0.83073316 0.051198072 -0.91216751 -0.74711818 1474.2676 1.0012582</code></pre>
<p>我們可以看到表示男性申請學生的數據 <code>a[1]</code> 是大於女性申請人的 <code>a[2]</code> 的事後概率分佈的。我們還需要計算這兩個羣體之間被錄取的概率差的事後分佈：</p>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb920-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb920-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m11<span class="fl">.7</span>)</span>
<span id="cb920-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb920-2" tabindex="-1"></a>diff_a <span class="ot">&lt;-</span> post<span class="sc">$</span>a[,<span class="dv">1</span>] <span class="sc">-</span> post<span class="sc">$</span>a[,<span class="dv">2</span>]</span>
<span id="cb920-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb920-3" tabindex="-1"></a>diff_p <span class="ot">&lt;-</span> <span class="fu">inv_logit</span>(post<span class="sc">$</span>a[,<span class="dv">1</span>]) <span class="sc">-</span> <span class="fu">inv_logit</span>(post<span class="sc">$</span>a[,<span class="dv">2</span>])</span>
<span id="cb920-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb920-4" tabindex="-1"></a><span class="fu">precis</span>( <span class="fu">list</span>( <span class="at">diff_a =</span> diff_a, <span class="at">diff_p =</span> diff_p ))</span></code></pre></div>
<pre><code>##              mean          sd       5.5%      94.5%  histogram
## diff_a 0.61273789 0.064198934 0.50690328 0.71635773   ▁▁▂▅▇▃▂▁
## diff_p 0.14213727 0.014442389 0.11831688 0.16503298 ▁▁▁▃▅▇▃▂▁▁</code></pre>
<p>可以看到男生平均要比女生被錄取的概率高 12% ~ 16%。在我們開始懷疑是不是有“系統性性別歧視”之前，讓我們先把觀察值和模型推測值繪製成圖來實際觀察到底有沒有男女錄取概率的差別 (圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig08">53.8</a>)：</p>
<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb922-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-1" tabindex="-1"></a><span class="fu">postcheck</span>( m11<span class="fl">.7</span> )</span>
<span id="cb922-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-2" tabindex="-1"></a><span class="co"># draw lines connecting points from same dept </span></span>
<span id="cb922-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-3" tabindex="-1"></a></span>
<span id="cb922-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-4" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span> ) {</span>
<span id="cb922-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-5" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(i <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb922-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-6" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> d<span class="sc">$</span>admit[x] <span class="sc">/</span> d<span class="sc">$</span>applications[x]</span>
<span id="cb922-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-7" tabindex="-1"></a>  y2 <span class="ot">&lt;-</span> d<span class="sc">$</span>admit[x <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">/</span> d<span class="sc">$</span>applications[x <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb922-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-8" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">c</span>(x, x <span class="sc">+</span> <span class="dv">1</span>), <span class="fu">c</span>(y1, y2), <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-9" tabindex="-1"></a>  <span class="fu">text</span>(x <span class="sc">+</span> <span class="fl">0.5</span>, (y1 <span class="sc">+</span> y2)<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.05</span>, </span>
<span id="cb922-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-10" tabindex="-1"></a>       d<span class="sc">$</span>dept[x], <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb922-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb922-11" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig08"></span>
<img src="bookdown_files/figure-html/introBayes13-fig08-1.png" alt="Posterior check for model m11.7. Blue points are observed proportions admitted for each row in the data, with points from the same department connected by a blue line. Open points, the tiny vertical black lines within them, and the crosses are expected proportions, 89% inervals of the expectation, and 89% interval of simulated samples, respectively." width="576" />
<p class="caption">
圖 53.8: Posterior check for model m11.7. Blue points are observed proportions admitted for each row in the data, with points from the same department connected by a blue line. Open points, the tiny vertical black lines within them, and the crosses are expected proportions, 89% inervals of the expectation, and 89% interval of simulated samples, respectively.
</p>
</div>
<p>看圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig08">53.8</a> 中的模型推測錄取率和實際觀察的錄取率之間差別有多大，模型簡直預測能力差到難以置信。在實際觀察的數據中，有且僅有兩個學院（C，E）有女性申請者的被錄取率略低於男性申請人。但是不知道爲什麼模型卻給出了男性申請人錄取率要高於女性申請人這樣歪曲事實的結果。通常情況下，這樣離譜的模型推測結果是由於代碼編寫的錯誤才會造成的。但是真的是這樣嗎？我們用的模型 <code>m11.7</code> 其實是在問，在這個大學裏平均的男性申請者錄取率和女性申請錄取率之差。但事實上我們看男性申請者和女性申請者並不同時申請不同的學院。從 A 學院到 F 學院的男女的錄取率都在遞減。你去看實際申請人數就知道女性申請者中申請A,B學院的實際人數非常地少，女性申請者傾向於申請錄取率特別低（&lt; 10%）的F學院。</p>
<p>所以說，儘管從整所大學的錄取率來說，女性似乎要普遍低於男性，但是你仔細看每個學院各自的錄取率的話就知道這並不是事實。此時我們可能面對的選擇是應該適當地修改我們的研究問題，我們實際上應該提的問題是：“在這個大學的不同學院內，平均地講男性和女性申請人的錄取率有沒有顯著差別？”回答這個問題的模型，應該表達成爲：</p>
<p><span class="math display">\[
\begin{aligned}
A_i &amp; \sim \text{Binomial}(N_i, p_i) \\
\text{logit}(p_i) &amp; = \alpha_{\text{GID}[i]} + \delta_{\text{DEPT}[i]}\\
\alpha_j &amp; \sim \text{Normal}(0, 1.5) \\
\delta_k &amp; \sim \text{Normal}(0, 1.5)
\end{aligned}
\]</span></p>
<p>修改了模型表達之後，我們賦予了每個學院自己各自的平均錄取率的對數比值(log-odds = logit)，<span class="math inline">\(\delta_{\text{DEPT}[i]}\)</span>。修改之後的模型同樣也能推算整個大學的錄取率，只是增加了對不同學院各自錄取傾向的考量。下面的代碼運行修改之後的模型。</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-1" tabindex="-1"></a>dat_list<span class="sc">$</span>dept_id <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">each =</span> <span class="dv">2</span>)</span>
<span id="cb923-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-2" tabindex="-1"></a>m11<span class="fl">.8</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb923-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-3" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb923-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-4" tabindex="-1"></a>    admit <span class="sc">~</span> <span class="fu">dbinom</span>( applications, p ) , </span>
<span id="cb923-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-5" tabindex="-1"></a>    <span class="fu">logit</span>(p) <span class="ot">&lt;-</span> a[gid] <span class="sc">+</span> delta[dept_id] , </span>
<span id="cb923-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-6" tabindex="-1"></a>    a[gid] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> ), </span>
<span id="cb923-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-7" tabindex="-1"></a>    delta[dept_id] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">1.5</span> )</span>
<span id="cb923-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-8" tabindex="-1"></a>  ), <span class="at">data =</span> dat_list, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">iter =</span> <span class="dv">4000</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb923-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb923-9" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb925-1" tabindex="-1"></a><span class="fu">precis</span>( m11<span class="fl">.8</span>, <span class="at">depth =</span> <span class="dv">2</span> )</span></code></pre></div>
<pre><code>##                 mean         sd        5.5%       94.5%     n_eff     Rhat4
## a[1]     -0.55241217 0.53502170 -1.42285985  0.29370854 497.09874 1.0041825
## a[2]     -0.45587536 0.53579666 -1.33097415  0.39548288 498.97989 1.0040298
## delta[1]  1.13369072 0.53717936  0.28470695  2.01043990 510.00362 1.0041563
## delta[2]  1.08904322 0.53999395  0.23450630  1.97474550 502.94401 1.0040980
## delta[3] -0.12601480 0.53721575 -0.98518882  0.75291238 501.31768 1.0040519
## delta[4] -0.16114238 0.53661354 -1.00723155  0.71233847 502.31853 1.0038995
## delta[5] -0.60329272 0.54034012 -1.44947110  0.27341613 501.16575 1.0040989
## delta[6] -2.15898561 0.54957237 -3.03302310 -1.26824285 532.73534 1.0037547</code></pre>
<p>模型 <code>m11.8</code> 的運行結果就矯正了我們之前可能存在的性別歧視的誤解。考慮了不同學院各自的平均錄取率之後，男女申請人之間的平均錄取率的對數比值就變得很接近了。有了模型 <code>m11.8</code> 的事後概率分佈樣本，我們可以簡單的計算男女錄取率的學院調整後之差：</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb927-1" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m11<span class="fl">.8</span>)</span>
<span id="cb927-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb927-2" tabindex="-1"></a>diff_a <span class="ot">&lt;-</span> post<span class="sc">$</span>a[, <span class="dv">1</span>] <span class="sc">-</span> post<span class="sc">$</span>a[, <span class="dv">2</span>]</span>
<span id="cb927-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb927-3" tabindex="-1"></a>diff_p <span class="ot">&lt;-</span> <span class="fu">inv_logit</span>(post<span class="sc">$</span>a[, <span class="dv">1</span>]) <span class="sc">-</span> <span class="fu">inv_logit</span>(post<span class="sc">$</span>a[, <span class="dv">2</span>])</span>
<span id="cb927-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb927-4" tabindex="-1"></a><span class="fu">precis</span>(<span class="fu">list</span>(<span class="at">diff_a =</span> diff_a, <span class="at">diff_p =</span> diff_p))</span></code></pre></div>
<pre><code>##                mean          sd        5.5%        94.5%     histogram
## diff_a -0.096536806 0.081479856 -0.22490943 0.0332588200 ▁▁▁▂▅▇▇▅▂▁▁▁▁
## diff_p -0.021483864 0.018472127 -0.05116369 0.0072051079      ▁▁▂▇▇▂▁▁</code></pre>
<p>所以，當考慮了不同學院各自本身的錄取率差異之後，沒有證據表明在申請人錄取率上有顯著的性別歧視。我們來回到原始數據去看看這個過程實際是怎樣的。簡單歸納一下每個學院各自的實際男女申請人的比例：</p>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb929-1" tabindex="-1"></a>pg <span class="ot">&lt;-</span> <span class="fu">with</span>( dat_list, <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="cf">function</span>(k)</span>
<span id="cb929-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb929-2" tabindex="-1"></a>  applications[dept_id <span class="sc">==</span> k]<span class="sc">/</span><span class="fu">sum</span>(applications[dept_id <span class="sc">==</span> k])))</span>
<span id="cb929-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb929-3" tabindex="-1"></a><span class="fu">rownames</span>(pg) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)</span>
<span id="cb929-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb929-4" tabindex="-1"></a><span class="fu">colnames</span>(pg) <span class="ot">&lt;-</span> <span class="fu">unique</span>(d<span class="sc">$</span>dept)</span>
<span id="cb929-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb929-5" tabindex="-1"></a><span class="fu">round</span>(pg, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##            A     B     C     D     E     F
## male   0.884 0.957 0.354 0.527 0.327 0.522
## female 0.116 0.043 0.646 0.473 0.673 0.478</code></pre>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb931-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb931-1" tabindex="-1"></a><span class="co"># simpler version:</span></span>
<span id="cb931-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb931-2" tabindex="-1"></a></span>
<span id="cb931-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb931-3" tabindex="-1"></a>d <span class="sc">%&gt;%</span> </span>
<span id="cb931-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb931-4" tabindex="-1"></a>  <span class="fu">group_by</span>(dept) <span class="sc">%&gt;%</span> </span>
<span id="cb931-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb931-5" tabindex="-1"></a>  <span class="fu">mutate</span>( <span class="at">rel.freq =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(applications <span class="sc">*</span> <span class="dv">100</span><span class="sc">/</span><span class="fu">sum</span>(applications), <span class="dv">2</span>), <span class="st">&quot;%&quot;</span>))</span></code></pre></div>
<pre><code>## # A tibble: 12 × 6
## # Groups:   dept [6]
##    dept  applicant.gender admit reject applications rel.freq
##    &lt;fct&gt; &lt;fct&gt;            &lt;int&gt;  &lt;int&gt;        &lt;int&gt; &lt;chr&gt;   
##  1 A     male               512    313          825 88.42%  
##  2 A     female              89     19          108 11.58%  
##  3 B     male               353    207          560 95.73%  
##  4 B     female              17      8           25 4.27%   
##  5 C     male               120    205          325 35.4%   
##  6 C     female             202    391          593 64.6%   
##  7 D     male               138    279          417 52.65%  
##  8 D     female             131    244          375 47.35%  
##  9 E     male                53    138          191 32.71%  
## 10 E     female              94    299          393 67.29%  
## 11 F     male                22    351          373 52.24%  
## 12 F     female              24    317          341 47.76%</code></pre>
<p>所以實際男性申請人佔比例在 A 學院達到了 88.4% 以上，像 E 學院的男性申請人的比例則僅僅只有 32.7% 左右。也就從另一個角度解釋了我們觀察到的現象，也就是說，錄取率較低的學院中女性申請人比例相當地高。模型 <code>m11.8</code> 給出的各個學院錄取率的推測值也和實際觀測值十分地接近 (圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig09">53.9</a>)。</p>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb933-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-1" tabindex="-1"></a><span class="fu">postcheck</span>( m11<span class="fl">.8</span> )</span>
<span id="cb933-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-2" tabindex="-1"></a><span class="co"># draw lines connecting points from same dept </span></span>
<span id="cb933-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-3" tabindex="-1"></a></span>
<span id="cb933-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-4" tabindex="-1"></a><span class="cf">for</span>( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span> ) {</span>
<span id="cb933-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-5" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(i <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb933-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-6" tabindex="-1"></a>  y1 <span class="ot">&lt;-</span> d<span class="sc">$</span>admit[x] <span class="sc">/</span> d<span class="sc">$</span>applications[x]</span>
<span id="cb933-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-7" tabindex="-1"></a>  y2 <span class="ot">&lt;-</span> d<span class="sc">$</span>admit[x <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">/</span> d<span class="sc">$</span>applications[x <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb933-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-8" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">c</span>(x, x <span class="sc">+</span> <span class="dv">1</span>), <span class="fu">c</span>(y1, y2), <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb933-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-9" tabindex="-1"></a>  <span class="fu">text</span>(x <span class="sc">+</span> <span class="fl">0.5</span>, (y1 <span class="sc">+</span> y2)<span class="sc">/</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.05</span>, </span>
<span id="cb933-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-10" tabindex="-1"></a>       d<span class="sc">$</span>dept[x], <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb933-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb933-11" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig09"></span>
<img src="bookdown_files/figure-html/introBayes13-fig09-1.png" alt="Posterior check for model m11.8. Blue points are observed proportions admitted for each row in the data, with points from the same department connected by a blue line. Open points, the tiny vertical black lines within them, and the crosses are expected proportions, 89% inervals of the expectation, and 89% interval of simulated samples, respectively." width="576" />
<p class="caption">
圖 53.9: Posterior check for model m11.8. Blue points are observed proportions admitted for each row in the data, with points from the same department connected by a blue line. Open points, the tiny vertical black lines within them, and the crosses are expected proportions, 89% inervals of the expectation, and 89% interval of simulated samples, respectively.
</p>
</div>
</div>
</div>
<div id="泊松回歸模型-poisson-regression" class="section level2 hasAnchor" number="53.2">
<h2><span class="header-section-number">53.2</span> 泊松回歸模型 Poisson regression<a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸模型-poisson-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>假如有某種試驗，成功的概率很低（接近零），當這樣的試驗實施的次數越來越多時，該試驗成功概率的概率分佈就會從二項分佈慢慢變成一個叫做泊松分佈的東西。二項分佈的均值（期望值）是試驗次數和成功概率的乘積 <span class="math inline">\(Np\)</span>，方差是 <span class="math inline">\(Np(1-p)\)</span>。所以，當 <span class="math inline">\(N\)</span> 很大，<span class="math inline">\(p\)</span> 很小的時候，均值和方差其實幾乎可以認爲是相等的。例如一個試驗成功的概率只有 0.001，那麼進行1000次試驗可能也只出現一次成功，這是均值，其方差是 <span class="math inline">\(1000 \times 0.001 \times (1 - 0.001) = 0.999 \approx 1\)</span>。也就是這時候雖然嚴格來說還是一個服從二項分佈的概率分佈，但是它的均值和方差幾乎是相同的。這樣的分佈被命名爲泊松分佈 (Poisson distribution)。</p>
<p><span class="math display">\[
y_i \sim \text{Poisson}(\lambda)
\]</span></p>
<p>其中 <span class="math inline">\(\lambda\)</span> 是結果 <span class="math inline">\(y\)</span> 的期望值，也是結果 <span class="math inline">\(y\)</span> 的方差。一般地，會使用對數函數作爲泊松模型的鏈接方程。</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp; \sim \text{Poisson}(\lambda_i) \\
\log(\lambda_i) &amp; = \alpha + \beta (x_i - \bar{x})
\end{aligned}
\]</span></p>
<p>對數鏈接函數確保了結果全部都是正的。我們始終要記住，當我們使用對數函數作爲鏈接方程的時候，我們默認的是預測變量和結果變量之間的關係是指數型關係。但是事實上我們觀察到的自然界的數據和現象<strong>很少會總是呈現指數型關係</strong>。所以當我們使用它的時候我們需要總是惦記這個指數關係是否成立，而且設定它的先驗概率分佈會更加的棘手。</p>
<div id="泊松回歸實例太平洋島國居民使用的工具" class="section level3 hasAnchor" number="53.2.1">
<h3><span class="header-section-number">53.2.1</span> 泊松回歸實例：太平洋島國居民使用的工具<a href="貝葉斯廣義線性回歸-bayesian-glm.html#泊松回歸實例太平洋島國居民使用的工具" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>太平洋島國的原住民使用的各種不同工具給人類學家提供了非常好的研究人類工具和技術進化的過程。有些理論認爲較大的人口規模會產生較爲複雜精密的工具。於是自然地，太平洋島國的島嶼大小面積各不相同，也就天然地限制了每個島嶼原住民人口規模，可以用來分析上述理論。另外不同族羣之間接觸的頻率也會影響族羣的人口規模，從而和工具的技術進化相關。我們使用這個太平洋島國工具數據來分析這個話題。</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb934-1" tabindex="-1"></a><span class="fu">data</span>(Kline)</span>
<span id="cb934-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb934-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> Kline</span>
<span id="cb934-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb934-3" tabindex="-1"></a>d</span></code></pre></div>
<pre><code>##       culture population contact total_tools mean_TU
## 1    Malekula       1100     low          13     3.2
## 2     Tikopia       1500     low          22     4.7
## 3  Santa Cruz       3600     low          24     4.0
## 4         Yap       4791    high          43     5.0
## 5    Lau Fiji       7400    high          33     5.0
## 6   Trobriand       8000    high          19     4.0
## 7       Chuuk       9200    high          40     3.8
## 8       Manus      13000     low          28     6.6
## 9       Tonga      17500    high          55     5.4
## 10     Hawaii     275000     low          71     6.6</code></pre>
<p>我們思考的研究模型是這樣的：</p>
<ul>
<li>模型的結果變量是 <code>total_tools</code>。我們決定使用泊松回歸模型，用對數函數鏈接方程來分析這個數據。</li>
<li>我們實際上認爲 <code>total_tools</code> 和人口 <code>population</code> 的對數（對數就是指的人口規模, the magnitude of the population）之間是正關係。</li>
<li>使用的工具的種類數量 <code>total_tools</code> 同時被認爲和族羣之間接觸的頻率 <code>contact</code> 應該呈現正關係，因爲多數人認爲增加不同島嶼族羣之間的交流和接觸會顯然增加原住民部落本身獲取更加多種類的生產工具。</li>
<li>另外還有人認爲，人口規模大小 <code>population</code> 還會通過部落族羣之間的交流頻率 <code>contact</code> 作爲媒介影響到結果變量 <code>total_tools</code>。</li>
</ul>
<p>接下來我們給數據中增加幾個需要使用的轉換後的變量：</p>
<div class="sourceCode" id="cb936"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb936-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb936-1" tabindex="-1"></a>d<span class="sc">$</span>P <span class="ot">&lt;-</span> <span class="fu">scale</span>( <span class="fu">log</span>(d<span class="sc">$</span>population) ) <span class="co"># standardize the log(population) into mean = 0, sd = 1</span></span>
<span id="cb936-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb936-2" tabindex="-1"></a>d<span class="sc">$</span>contact_id <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( d<span class="sc">$</span>contact <span class="sc">==</span> <span class="st">&quot;high&quot;</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>我們把符合上述思考和假設的模型描述爲含有交互作用項的數學模型：</p>
<p><span class="math display">\[
\begin{aligned}
T_i &amp; \sim \text{Poisson}(\lambda_i) \\
\log \lambda_i &amp; = \alpha_{\text{CID}[i]} + \beta_{\text{CID}[i]} \log P_i \\
\alpha_i &amp; \sim \text{ to be determined } \\
\beta_j  &amp; \sim \text{ to be determined }
\end{aligned}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(P_i\)</span> 是人口規模，</li>
<li><span class="math inline">\(\text{CID}[i]\)</span> 是 <code>contact_id</code>。</li>
</ul>
<p>接下來我們考慮怎樣爲 <span class="math inline">\(\alpha_i, \beta_j\)</span> 設置合適的先驗概率分佈。和二項分佈數據使用的邏輯回歸模型類似，當我們選擇使用對數鏈接函數把數據進行轉換之後，原先在簡單線性回歸模型中適合使用的平坦分佈會變得不合適。爲了更直觀的說明這個現象，我們先使用最簡單的只有截距的泊松回歸模型，給該截距的先驗概率分佈使用平坦分佈 <span class="math inline">\(\text{Normal}(0,10)\)</span>。</p>
<p><span class="math display">\[
\begin{aligned}
T_i &amp; \sim \text{Poisson}(\lambda_i) \\
\log \lambda_i &amp; = \alpha \\
\alpha &amp; \sim \text{Normal}(0, 10) \\
\end{aligned}
\]</span></p>
<p>當我們給截距設定的先驗概率分佈設定成 <span class="math inline">\(\text{Normal}(0,10)\)</span> 會對時間發生率 <span class="math inline">\(\lambda\)</span> 在它原本的尺度上有怎樣的體現呢？如果截距 <span class="math inline">\(\alpha\)</span> 是服從正（常）態分佈的話，那麼 <span class="math inline">\(\lambda\)</span> 就會服從對數正（常）態分佈。我們來繪製一下這兩個分佈的概率密度分佈：</p>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-1" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dlnorm</span>(x, <span class="dv">0</span>, <span class="dv">10</span>), <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">n =</span> <span class="dv">200</span>, </span>
<span id="cb937-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-2" tabindex="-1"></a>       <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb937-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-3" tabindex="-1"></a>       <span class="at">xlab =</span> <span class="st">&quot;mean numbber of tools (lambda)&quot;</span>, </span>
<span id="cb937-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-4" tabindex="-1"></a>       <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>)</span>
<span id="cb937-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-5" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">20</span>, <span class="fl">0.06</span>, <span class="st">&quot;a ~ dnorm(0, 10)&quot;</span>)</span>
<span id="cb937-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-6" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dlnorm</span>(x, <span class="dv">3</span>, <span class="fl">0.5</span>), <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb937-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-7" tabindex="-1"></a>       <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb937-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb937-8" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">50</span>, <span class="fl">0.03</span>, <span class="st">&quot;a ~ dnorm(3, 0.5)&quot;</span>, <span class="at">col =</span> rangi2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig10"></span>
<img src="bookdown_files/figure-html/introBayes13-fig10-1.png" alt="Prior predictive distribution of the mean lambda of a simple Poisson GLM, considering only the intercept alpha. A flat conventional prior (black) creates absurd expecations on the outcome scale. The mean of this distribution is exp(50) stupidly large. It is easy to do better by shifting prior mass above zero (blue)." width="480" />
<p class="caption">
圖 53.10: Prior predictive distribution of the mean lambda of a simple Poisson GLM, considering only the intercept alpha. A flat conventional prior (black) creates absurd expecations on the outcome scale. The mean of this distribution is exp(50) stupidly large. It is easy to do better by shifting prior mass above zero (blue).
</p>
</div>
<p>圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig10">53.10</a> 顯示，當我們使用 <span class="math inline">\(\alpha \sim \text{Normal}(0, 10)\)</span> 作爲截距的先驗概率分佈時，我們看到結果變量使用工具的數量竟然出現了一個特別接近零的尖峯，這其實意味着我們的先驗概率分佈認爲不論是哪個島嶼哪個部落的居民使用的工具數量基本上是 0，這顯然是不合理的。而且你看它右邊的尾巴特別的長，有多長呢？對數正（常）態分佈的期望值計算公式是 <span class="math inline">\(\exp(\mu + \sigma^2/2)\)</span>，也就是說現在設定的先驗概率分佈 <span class="math inline">\(\alpha \sim \text{Normal}(0, 10)\)</span> 的均值其實達到了 <span class="math inline">\(\exp(50) = 5.185e+21\)</span>。我們隨便模擬一個對數正（常）態分佈看它的均值會是怎樣的不可思議地大：</p>
<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb938-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb938-1" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb938-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb938-2" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">exp</span>(a)</span>
<span id="cb938-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb938-3" tabindex="-1"></a><span class="fu">mean</span>( lambda )</span></code></pre></div>
<pre><code>## [1] 1.5502546e+14</code></pre>
<p>於是我們修改了一下預期，把截距的先驗概率分佈修改成 <span class="math inline">\(\text{Normal}(3, 0.5)\)</span>，展示在圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig10">53.10</a> 中藍色的曲線。此時的新對數正（常）態分佈的均值是 <span class="math inline">\(\exp(3 + 0.5^2/2) \approx 22.8\)</span>，也就是說這個先驗概率認爲在沒有分析數據之前，我們估計平均來說每個部落的族羣平均的生產工具的數量在20個左右。這樣的假設是不是會合理很多？用相似的邏輯我們用來給人口規模 (<span class="math inline">\(\log\)</span> <code>population</code>) 回歸係數 <span class="math inline">\(\beta\)</span> 設定合理的先驗概率分佈，目標是希望把數據限制在合適的範圍內以免採樣效率太低。先用一個我們傳統上認爲的平坦分佈 <span class="math inline">\(\text{Normal}(0,10)\)</span> 來看看它的戲劇性效果。</p>
<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb940-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> </span>
<span id="cb940-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-2" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">3</span>, <span class="fl">0.5</span>)</span>
<span id="cb940-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-3" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb940-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-4" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, </span>
<span id="cb940-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-5" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb940-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-6" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), </span>
<span id="cb940-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-7" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb940-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-8" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;b ~ dnorm(0, 10)&quot;</span>, </span>
<span id="cb940-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-9" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;total tools&quot;</span>, </span>
<span id="cb940-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-10" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;log population (std)&quot;</span>)</span>
<span id="cb940-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb940-11" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="fu">curve</span>(<span class="fu">exp</span>( a[i] <span class="sc">+</span> b[i]<span class="sc">*</span>x), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="fu">grau</span>())</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig11"></span>
<img src="bookdown_files/figure-html/introBayes13-fig11-1.png" alt="Struggling with slope priors in a Poisson GLM. A flat prior produces explosive trends on the outcome scale." width="528" />
<p class="caption">
圖 53.11: Struggling with slope priors in a Poisson GLM. A flat prior produces explosive trends on the outcome scale.
</p>
</div>
<p>圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig11">53.11</a> 就是當截距是合理的先驗概率分佈，但是斜率是常用的“平坦分佈”時給出的人口規模和工具數量之間的可怕的關係。它其實是在說，當我們還沒見到實際數據時，我們認爲在平均人口規模（因爲橫軸的人口規模被標準化了）的部落族羣附近，使用的工具種類數量要麼就是暴增，要麼是暴減。這是非常不合常理的。我們需要不那麼“平坦”的先驗概率分佈，給我們合理的結果。經過多種嘗試，我們認爲 <span class="math inline">\(\beta \sim \text{Normal}(0, 0.2)\)</span> 會是一個理性的選擇（圖<a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig12">53.12</a>）。在實際分析數據之前，我們認爲不論是哪個部落，最多的生產工具種類也不會超過100種之多。</p>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb941-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> </span>
<span id="cb941-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-2" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">3</span>, <span class="fl">0.5</span>)</span>
<span id="cb941-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-3" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb941-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-4" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, </span>
<span id="cb941-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-5" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb941-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-6" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), </span>
<span id="cb941-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-7" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb941-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-8" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;b ~ dnorm(0, 0.2)&quot;</span>, </span>
<span id="cb941-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-9" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;total tools&quot;</span>, </span>
<span id="cb941-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-10" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;log population (std)&quot;</span>)</span>
<span id="cb941-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb941-11" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="fu">curve</span>(<span class="fu">exp</span>( a[i] <span class="sc">+</span> b[i]<span class="sc">*</span>x), <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="fu">grau</span>())</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig12"></span>
<img src="bookdown_files/figure-html/introBayes13-fig12-1.png" alt="Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes." width="528" />
<p class="caption">
圖 53.12: Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes.
</p>
</div>
<p>我們把橫軸修改成爲沒有被標準化的 <code>log population</code> 之後，先驗概率分佈之間的關係如圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig13">53.13</a>。</p>
<div class="sourceCode" id="cb942"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb942-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> </span>
<span id="cb942-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-2" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">3</span>, <span class="fl">0.5</span>)</span>
<span id="cb942-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-3" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb942-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-4" tabindex="-1"></a></span>
<span id="cb942-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-5" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from =</span> <span class="fu">log</span>(<span class="dv">100</span>), <span class="at">to =</span> <span class="fu">log</span>(<span class="dv">200000</span>), <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb942-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-6" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">sapply</span>( x_seq, <span class="cf">function</span>(x) <span class="fu">exp</span>(a <span class="sc">+</span> b<span class="sc">*</span>x))</span>
<span id="cb942-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-7" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>, </span>
<span id="cb942-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-8" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb942-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-9" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">range</span>(x_seq), </span>
<span id="cb942-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-10" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">500</span>),</span>
<span id="cb942-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-11" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;a ~ dnorm(3, 0.5); b ~ dnorm(0, 0.2)&quot;</span>, </span>
<span id="cb942-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-12" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;total tools&quot;</span>, </span>
<span id="cb942-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-13" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;log population (un-std)&quot;</span>)</span>
<span id="cb942-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb942-14" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="fu">lines</span>(x_seq, lambda[i, ], <span class="at">col =</span> <span class="fu">grau</span>(), <span class="at">lwd =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig13"></span>
<img src="bookdown_files/figure-html/introBayes13-fig13-1.png" alt="Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes. Now horizontal axis on unstandardized scale." width="528" />
<p class="caption">
圖 53.13: Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes. Now horizontal axis on unstandardized scale.
</p>
</div>
<p>最後我們再把橫軸的人口重新轉換到最原始的尺度上來，成爲圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig14">53.14</a> 顯示的</p>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb943-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>,  <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb943-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-2" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">range</span>(<span class="fu">exp</span>(x_seq)), </span>
<span id="cb943-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-3" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">500</span>),</span>
<span id="cb943-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-4" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;a ~ dnorm(3, 0.5); b ~ dnorm(0, 0.2)&quot;</span>, </span>
<span id="cb943-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-5" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;total tools&quot;</span>, </span>
<span id="cb943-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-6" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;population (un-std)&quot;</span>)</span>
<span id="cb943-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb943-7" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="fu">lines</span>(<span class="fu">exp</span>(x_seq), lambda[i, ], <span class="at">col =</span> <span class="fu">grau</span>(), <span class="at">lwd =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig14"></span>
<img src="bookdown_files/figure-html/introBayes13-fig14-1.png" alt="Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes. Now horizontal axis on unstandardized original scale for population." width="528" />
<p class="caption">
圖 53.14: Struggling with slope priors in a Poisson GLM. A regularizing prior remains mostly within the space of outcomes. Now horizontal axis on unstandardized original scale for population.
</p>
</div>
<p>可以看到這是泊松回歸模型認爲的真實的預測變量和結果變量之間存在的關係，這是一種對數線性(log-linear)關係。自然地解釋就是，人口數量本身數值的增加，只能對工具種類的增加造成微弱的影響。許多的預測變量，都應該被取了對數之後再放入你的回歸模型中去，因爲這才是真實的關係。接下來終於到了模型本身的運行了：</p>
<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb944-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-1" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb944-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-2" tabindex="-1"></a>  <span class="at">T =</span> d<span class="sc">$</span>total_tools,</span>
<span id="cb944-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-3" tabindex="-1"></a>  <span class="at">P =</span> d<span class="sc">$</span>P,</span>
<span id="cb944-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-4" tabindex="-1"></a>  <span class="at">cid =</span> d<span class="sc">$</span>contact_id</span>
<span id="cb944-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-5" tabindex="-1"></a>)</span>
<span id="cb944-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-6" tabindex="-1"></a></span>
<span id="cb944-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-7" tabindex="-1"></a><span class="co"># intercept only</span></span>
<span id="cb944-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-8" tabindex="-1"></a> m11<span class="fl">.9</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb944-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-9" tabindex="-1"></a>   <span class="fu">alist</span>(</span>
<span id="cb944-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-10" tabindex="-1"></a>     T <span class="sc">~</span> <span class="fu">dpois</span>( lambda ), </span>
<span id="cb944-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-11" tabindex="-1"></a>     <span class="fu">log</span>(lambda) <span class="ot">&lt;-</span> a, </span>
<span id="cb944-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-12" tabindex="-1"></a>     a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">3</span>, <span class="fl">0.5</span> )</span>
<span id="cb944-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-13" tabindex="-1"></a>   ), <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb944-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb944-14" tabindex="-1"></a> )</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb946"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb946-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-1" tabindex="-1"></a><span class="co"># interaction model</span></span>
<span id="cb946-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-2" tabindex="-1"></a>m11<span class="fl">.10</span> <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb946-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-3" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb946-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-4" tabindex="-1"></a>    T <span class="sc">~</span> <span class="fu">dpois</span>( lambda ), </span>
<span id="cb946-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-5" tabindex="-1"></a>    <span class="fu">log</span>(lambda) <span class="ot">&lt;-</span> a[cid] <span class="sc">+</span> b[cid] <span class="sc">*</span> P, </span>
<span id="cb946-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-6" tabindex="-1"></a>    a[cid] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">3</span>, <span class="fl">0.5</span> ), </span>
<span id="cb946-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-7" tabindex="-1"></a>    b[cid] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> )</span>
<span id="cb946-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-8" tabindex="-1"></a>  ), <span class="at">data =</span> dat, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">log_lik =</span> <span class="cn">TRUE</span>, <span class="at">cmdstan =</span> <span class="cn">TRUE</span></span>
<span id="cb946-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb946-9" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Compiling Stan program...</code></pre>
<div class="sourceCode" id="cb948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb948-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb948-1" tabindex="-1"></a><span class="fu">precis</span>(m11<span class="fl">.9</span>)</span></code></pre></div>
<pre><code>##        mean          sd      5.5%     94.5%     n_eff     Rhat4
## a 3.5417773 0.054827606 3.4537819 3.6290206 754.24347 1.0034536</code></pre>
<div class="sourceCode" id="cb950"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb950-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb950-1" tabindex="-1"></a><span class="fu">precis</span>(m11<span class="fl">.10</span>, <span class="at">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##            mean          sd         5.5%      94.5%     n_eff      Rhat4
## a[1] 3.31991004 0.089108961  3.174423050 3.45588055 1770.7538 0.99917200
## a[2] 3.61204930 0.073722794  3.492463400 3.72909585 2220.5610 1.00022684
## b[1] 0.37615682 0.053043988  0.290144160 0.45832048 1724.7594 0.99949672
## b[2] 0.18447760 0.158530213 -0.058991431 0.43852981 1921.9132 0.99937162</code></pre>
<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb952-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb952-1" tabindex="-1"></a><span class="fu">compare</span>(m11<span class="fl">.9</span>, m11<span class="fl">.10</span>, <span class="at">func =</span> PSIS)</span></code></pre></div>
<pre><code>## Some Pareto k values are high (&gt;0.5). Set pointwise=TRUE to inspect individual points.</code></pre>
<pre><code>## Some Pareto k values are very high (&gt;1). Set pointwise=TRUE to inspect individual points.</code></pre>
<pre><code>##              PSIS        SE    dPSIS       dSE     pPSIS        weight
## m11.10  86.077059 13.298851  0.00000        NA 7.2911759 1.0000000e+00
## m11.9  141.446629 33.480083 55.36957 32.228886 8.3639525 9.4765567e-13</code></pre>
<p>我們又一次看見了關於 <code>Pareto k</code> 的警報。這提示我們數據種存在一些對模型結果影響較大的觀察值。具體可以通過繪製PSIS圖來觀察模型的事後概率分佈。</p>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb956-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-1" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">PSIS</span>( m11<span class="fl">.10</span>, <span class="at">pointwise =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>k</span>
<span id="cb956-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-2" tabindex="-1"></a><span class="fu">plot</span>(dat<span class="sc">$</span>P, dat<span class="sc">$</span>T, </span>
<span id="cb956-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-3" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;log population (std)&quot;</span>, </span>
<span id="cb956-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-4" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;total tolls&quot;</span>, </span>
<span id="cb956-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-5" tabindex="-1"></a>     <span class="at">col =</span> rangi2, </span>
<span id="cb956-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-6" tabindex="-1"></a>      <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb956-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-7" tabindex="-1"></a>     <span class="at">pch =</span> <span class="fu">ifelse</span>( dat<span class="sc">$</span>cid <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">16</span>), </span>
<span id="cb956-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-8" tabindex="-1"></a>     <span class="at">lwd =</span> <span class="dv">2</span>, </span>
<span id="cb956-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-9" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">75</span>), </span>
<span id="cb956-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-10" tabindex="-1"></a>     <span class="at">cex =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">normalize</span>(k))</span>
<span id="cb956-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-11" tabindex="-1"></a></span>
<span id="cb956-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-12" tabindex="-1"></a><span class="co"># set up the horizontal axis values to compute predictions at</span></span>
<span id="cb956-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-13" tabindex="-1"></a></span>
<span id="cb956-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-14" tabindex="-1"></a>ns <span class="ot">&lt;-</span> <span class="dv">100</span> </span>
<span id="cb956-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-15" tabindex="-1"></a>P_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from =</span> <span class="sc">-</span><span class="fl">1.4</span>, <span class="at">to =</span> <span class="dv">3</span>, <span class="at">length.out =</span> ns)</span>
<span id="cb956-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-16" tabindex="-1"></a></span>
<span id="cb956-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-17" tabindex="-1"></a><span class="co"># Predictions for cid = 1 (low contact)</span></span>
<span id="cb956-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-18" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">link</span>( m11<span class="fl">.10</span>, <span class="at">data =</span> <span class="fu">data.frame</span>( <span class="at">P =</span> P_seq, <span class="at">cid =</span> <span class="dv">1</span> ) )</span>
<span id="cb956-19"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-19" tabindex="-1"></a>lmu <span class="ot">&lt;-</span> <span class="fu">apply</span>(lambda, <span class="dv">2</span>, mean) </span>
<span id="cb956-20"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-20" tabindex="-1"></a>lci <span class="ot">&lt;-</span> <span class="fu">apply</span>(lambda, <span class="dv">2</span>, PI)</span>
<span id="cb956-21"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-21" tabindex="-1"></a><span class="fu">lines</span>( P_seq, lmu, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>)</span>
<span id="cb956-22"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-22" tabindex="-1"></a><span class="fu">shade</span>(lci, P_seq, <span class="at">xpd =</span> <span class="cn">FALSE</span>)</span>
<span id="cb956-23"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-23" tabindex="-1"></a></span>
<span id="cb956-24"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-24" tabindex="-1"></a><span class="co"># Predictions for cid = 2 (high contact)</span></span>
<span id="cb956-25"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-25" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">link</span>( m11<span class="fl">.10</span>, <span class="at">data =</span> <span class="fu">data.frame</span>( <span class="at">P =</span> P_seq, <span class="at">cid =</span> <span class="dv">2</span> ))</span>
<span id="cb956-26"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-26" tabindex="-1"></a>lmu <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, mean)</span>
<span id="cb956-27"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-27" tabindex="-1"></a>lci <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, PI)</span>
<span id="cb956-28"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-28" tabindex="-1"></a><span class="fu">lines</span>( P_seq, lmu, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>)</span>
<span id="cb956-29"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-29" tabindex="-1"></a><span class="fu">shade</span>( lci, P_seq, <span class="at">xpd =</span> <span class="cn">FALSE</span></span>
<span id="cb956-30"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb956-30" tabindex="-1"></a>       )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig15"></span>
<img src="bookdown_files/figure-html/introBayes13-fig15-1.png" alt="Posterior predictions for the Oceanic tools model. Filled points are societies with historically high contact. Open points are those with low contact. Point size is scaled by relative PSIS Pareto's k values. Larger points are more influential. The solid curve is the posterior mean for high contact societies. The dashed curve is the same for low contact societies. 89% compatibility intervals are shown by the shaded regions. (Standardized log population scale, as in the model code)" width="528" />
<p class="caption">
圖 53.15: Posterior predictions for the Oceanic tools model. Filled points are societies with historically high contact. Open points are those with low contact. Point size is scaled by relative PSIS Pareto’s k values. Larger points are more influential. The solid curve is the posterior mean for high contact societies. The dashed curve is the same for low contact societies. 89% compatibility intervals are shown by the shaded regions. (Standardized log population scale, as in the model code)
</p>
</div>
<p>圖 <a href="貝葉斯廣義線性回歸-bayesian-glm.html#fig:introBayes13-fig15">53.15</a> 中空心的點表示與其他族羣部落交流較少的島嶼，實心點是與其他族羣部落交流較頻繁的島嶼。點的大小個 Pareto K 值成正比例。下面的代碼把橫軸人口還原到原始的尺度上。</p>
<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb957-1"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-1" tabindex="-1"></a><span class="fu">plot</span>( d<span class="sc">$</span>population, d<span class="sc">$</span>total_tools, </span>
<span id="cb957-2"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-2" tabindex="-1"></a>            <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, </span>
<span id="cb957-3"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-3" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;population&quot;</span>, </span>
<span id="cb957-4"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-4" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;total tools&quot;</span>, </span>
<span id="cb957-5"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-5" tabindex="-1"></a>      <span class="at">col =</span> rangi2, <span class="at">pch =</span> <span class="fu">ifelse</span>( dat<span class="sc">$</span>cid <span class="sc">==</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">16</span>), <span class="at">lwd =</span> <span class="dv">2</span>, </span>
<span id="cb957-6"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-6" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">75</span>), <span class="at">cex =</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">normalize</span>(k))</span>
<span id="cb957-7"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-7" tabindex="-1"></a></span>
<span id="cb957-8"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-8" tabindex="-1"></a>ns <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb957-9"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-9" tabindex="-1"></a></span>
<span id="cb957-10"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-10" tabindex="-1"></a>P_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">3</span>, <span class="at">length.out =</span> ns )</span>
<span id="cb957-11"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-11" tabindex="-1"></a><span class="co"># 1.53 is sd of log(population)</span></span>
<span id="cb957-12"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-12" tabindex="-1"></a><span class="co"># 9 is mean of log(population)</span></span>
<span id="cb957-13"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-13" tabindex="-1"></a></span>
<span id="cb957-14"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-14" tabindex="-1"></a>pop_seq <span class="ot">&lt;-</span> <span class="fu">exp</span>( P_seq<span class="sc">*</span><span class="fl">1.53</span> <span class="sc">+</span> <span class="dv">9</span> )</span>
<span id="cb957-15"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-15" tabindex="-1"></a></span>
<span id="cb957-16"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-16" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">link</span>( m11<span class="fl">.10</span>, <span class="at">data =</span> <span class="fu">data.frame</span>( <span class="at">P =</span> P_seq, <span class="at">cid =</span> <span class="dv">1</span> ))</span>
<span id="cb957-17"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-17" tabindex="-1"></a>lmu <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, mean)</span>
<span id="cb957-18"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-18" tabindex="-1"></a>lci <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, PI)</span>
<span id="cb957-19"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-19" tabindex="-1"></a></span>
<span id="cb957-20"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-20" tabindex="-1"></a><span class="fu">lines</span>( pop_seq, lmu, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="fl">1.5</span> )</span>
<span id="cb957-21"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-21" tabindex="-1"></a><span class="fu">shade</span>( lci, pop_seq, <span class="at">xpd =</span> <span class="cn">FALSE</span> )</span>
<span id="cb957-22"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-22" tabindex="-1"></a></span>
<span id="cb957-23"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-23" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">link</span>( m11<span class="fl">.10</span>, <span class="at">data =</span> <span class="fu">data.frame</span>( <span class="at">P =</span> P_seq, <span class="at">cid =</span> <span class="dv">2</span> ))</span>
<span id="cb957-24"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-24" tabindex="-1"></a>lmu <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, mean )</span>
<span id="cb957-25"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-25" tabindex="-1"></a>lci <span class="ot">&lt;-</span> <span class="fu">apply</span>( lambda, <span class="dv">2</span>, PI )</span>
<span id="cb957-26"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-26" tabindex="-1"></a><span class="fu">lines</span>( pop_seq, lmu, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="fl">1.5</span> )</span>
<span id="cb957-27"><a href="貝葉斯廣義線性回歸-bayesian-glm.html#cb957-27" tabindex="-1"></a><span class="fu">shade</span>( lci, pop_seq, <span class="at">xpd =</span> <span class="cn">FALSE</span> )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:introBayes13-fig1"></span>
<img src="bookdown_files/figure-html/introBayes13-fig1-1.png" alt="Posterior predictions for the Oceanic tools model. Filled points are societies with historically high contact. Open points are those with low contact. Point size is scaled by relative PSIS Pareto's k values. Larger points are more influential. The solid curve is the posterior mean for high contact societies. The dashed curve is the same for low contact societies. 89% compatibility intervals are shown by the shaded regions. (Same predictions on the natural population scale.)" width="528" />
<p class="caption">
圖 53.16: Posterior predictions for the Oceanic tools model. Filled points are societies with historically high contact. Open points are those with low contact. Point size is scaled by relative PSIS Pareto’s k values. Larger points are more influential. The solid curve is the posterior mean for high contact societies. The dashed curve is the same for low contact societies. 89% compatibility intervals are shown by the shaded regions. (Same predictions on the natural population scale.)
</p>
</div>
<p>檢查 k 值我們發現，夏威夷 (k = 1.01) 是對模型結果影響最大的點。夏威夷擁有最多的人口，和種類數量最多的生產工具。</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-silk2005chimpanzees" class="csl-entry">
Silk, Joan B, Sarah F Brosnan, Jennifer Vonk, Joseph Henrich, Daniel J Povinelli, Amanda S Richardson, Susan P Lambeth, Jenny Mascaro, and Steven J Schapiro. 2005. <span>“Chimpanzees Are Indifferent to the Welfare of Unrelated Group Members.”</span> <em>Nature</em> 437 (7063): 1357–59.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="馬可夫鏈蒙地卡羅-mcmc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="貝葉斯廣義線性回歸模型的擴展-continuous-mixture-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/08-Intro-to-Bayes.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
